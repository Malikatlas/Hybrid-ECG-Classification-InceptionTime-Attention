{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13828194,"sourceType":"datasetVersion","datasetId":8806716}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wfdb protobuf==3.20.3 --quiet\n\nimport os\nimport numpy as np\nimport pandas as pd\n\nimport wfdb\nfrom scipy import signal\nfrom scipy.fft import rfft\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom collections import Counter\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers, callbacks\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-23T09:41:04.844132Z","iopub.execute_input":"2025-11-23T09:41:04.844683Z","iopub.status.idle":"2025-11-23T09:41:08.979974Z","shell.execute_reply.started":"2025-11-23T09:41:04.844656Z","shell.execute_reply":"2025-11-23T09:41:08.979177Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\n\nbase_path = \"/kaggle/input/dl-dataset\"\nprint(os.listdir(base_path))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T09:39:02.208053Z","iopub.execute_input":"2025-11-23T09:39:02.208541Z","iopub.status.idle":"2025-11-23T09:39:02.215167Z","shell.execute_reply.started":"2025-11-23T09:39:02.208494Z","shell.execute_reply":"2025-11-23T09:39:02.214453Z"}},"outputs":[{"name":"stdout","text":"['ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\n\nBASE_PATH = \"/kaggle/input/dl-dataset\"\nROOT = os.path.join(BASE_PATH, \"ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3\")\n\nprint(\"Inside BASE_PATH:\", os.listdir(BASE_PATH))\nprint(\"\\nInside ROOT:\", os.listdir(ROOT))\n\nDATA_DIR = ROOT   # <--- FIXED\nprint(\"\\nInside DATA_DIR:\", os.listdir(DATA_DIR))\n\nRECORDS100 = os.path.join(DATA_DIR, \"records100\")\nprint(\"\\nFirst few folders in records100:\", os.listdir(RECORDS100)[:5])\n\nSAMPLE_REC_00000 = os.path.join(RECORDS100, \"00000\")\nprint(\"\\nFiles in records100/00000:\", os.listdir(SAMPLE_REC_00000))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T09:49:37.362984Z","iopub.execute_input":"2025-11-23T09:49:37.363674Z","iopub.status.idle":"2025-11-23T09:49:37.396717Z","shell.execute_reply.started":"2025-11-23T09:49:37.363644Z","shell.execute_reply":"2025-11-23T09:49:37.396137Z"}},"outputs":[{"name":"stdout","text":"Inside BASE_PATH: ['ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3']\n\nInside ROOT: ['records500', 'SHA256SUMS.txt', 'RECORDS', 'example_physionet.py', 'ptbxl_v103_changelog.txt', 'scp_statements.csv', 'ptbxl_database.csv', 'LICENSE.txt', 'ptbxl_v102_changelog.txt', 'records100']\n\nInside DATA_DIR: ['records500', 'SHA256SUMS.txt', 'RECORDS', 'example_physionet.py', 'ptbxl_v103_changelog.txt', 'scp_statements.csv', 'ptbxl_database.csv', 'LICENSE.txt', 'ptbxl_v102_changelog.txt', 'records100']\n\nFirst few folders in records100: ['21000', '15000', '18000', '14000', '19000']\n\nFiles in records100/00000: ['00775_lr.dat', '00103_lr.dat', '00989_lr.hea', '00452_lr.dat', '00940_lr.hea', '00054_lr.hea', '00707_lr.hea', '00988_lr.dat', '00875_lr.hea', '00429_lr.dat', '00821_lr.hea', '00313_lr.dat', '00039_lr.hea', '00555_lr.dat', '00556_lr.hea', '00203_lr.hea', '00698_lr.dat', '00315_lr.hea', '00179_lr.hea', '00967_lr.hea', '00159_lr.hea', '00318_lr.hea', '00297_lr.hea', '00723_lr.hea', '00597_lr.hea', '00381_lr.hea', '00155_lr.hea', '00175_lr.dat', '00312_lr.hea', '00691_lr.hea', '00634_lr.dat', '00532_lr.dat', '00647_lr.dat', '00926_lr.dat', '00085_lr.dat', '00992_lr.hea', '00862_lr.hea', '00135_lr.dat', '00537_lr.dat', '00740_lr.dat', '00247_lr.hea', '00230_lr.hea', '00898_lr.dat', '00344_lr.dat', '00433_lr.hea', '00997_lr.dat', '00396_lr.hea', '00622_lr.hea', '00386_lr.dat', '00719_lr.hea', '00861_lr.hea', '00977_lr.hea', '00227_lr.hea', '00993_lr.hea', '00718_lr.hea', '00802_lr.hea', '00675_lr.dat', '00266_lr.hea', '00829_lr.dat', '00806_lr.dat', '00076_lr.dat', '00936_lr.dat', '00239_lr.hea', '00131_lr.dat', '00424_lr.dat', '00644_lr.hea', '00605_lr.hea', '00939_lr.dat', '00345_lr.hea', '00998_lr.hea', '00565_lr.hea', '00387_lr.hea', '00417_lr.hea', '00049_lr.hea', '00406_lr.dat', '00536_lr.dat', '00615_lr.hea', '00463_lr.hea', '00187_lr.hea', '00693_lr.dat', '00816_lr.hea', '00144_lr.dat', '00538_lr.hea', '00046_lr.dat', '00115_lr.hea', '00925_lr.hea', '00159_lr.dat', '00430_lr.dat', '00113_lr.dat', '00982_lr.dat', '00047_lr.dat', '00978_lr.hea', '00955_lr.hea', '00053_lr.hea', '00245_lr.dat', '00204_lr.dat', '00911_lr.hea', '00948_lr.dat', '00666_lr.dat', '00893_lr.dat', '00570_lr.hea', '00966_lr.hea', '00981_lr.dat', '00164_lr.dat', '00533_lr.dat', '00007_lr.hea', '00787_lr.dat', '00036_lr.hea', '00904_lr.hea', '00812_lr.hea', '00650_lr.hea', '00417_lr.dat', '00542_lr.dat', '00094_lr.hea', '00110_lr.dat', '00529_lr.hea', '00253_lr.dat', '00029_lr.hea', '00497_lr.dat', '00531_lr.hea', '00185_lr.dat', '00636_lr.hea', '00564_lr.dat', '00369_lr.dat', '00628_lr.dat', '00984_lr.hea', '00383_lr.dat', '00107_lr.dat', '00607_lr.hea', '00802_lr.dat', '00246_lr.dat', '00574_lr.hea', '00851_lr.hea', '00858_lr.dat', '00744_lr.dat', '00823_lr.hea', '00447_lr.hea', '00196_lr.dat', '00344_lr.hea', '00908_lr.hea', '00079_lr.hea', '00711_lr.dat', '00373_lr.dat', '00873_lr.hea', '00148_lr.hea', '00729_lr.dat', '00347_lr.hea', '00288_lr.dat', '00819_lr.dat', '00206_lr.dat', '00269_lr.hea', '00700_lr.dat', '00059_lr.hea', '00838_lr.dat', '00511_lr.hea', '00339_lr.dat', '00013_lr.hea', '00604_lr.dat', '00400_lr.hea', '00389_lr.hea', '00451_lr.hea', '00590_lr.dat', '00319_lr.dat', '00184_lr.dat', '00820_lr.dat', '00527_lr.hea', '00360_lr.dat', '00138_lr.hea', '00410_lr.dat', '00781_lr.dat', '00331_lr.hea', '00231_lr.hea', '00337_lr.dat', '00713_lr.hea', '00519_lr.dat', '00599_lr.hea', '00242_lr.hea', '00704_lr.hea', '00568_lr.dat', '00385_lr.dat', '00281_lr.hea', '00649_lr.dat', '00726_lr.hea', '00581_lr.hea', '00515_lr.hea', '00743_lr.hea', '00349_lr.dat', '00780_lr.dat', '00828_lr.hea', '00948_lr.hea', '00365_lr.dat', '00025_lr.hea', '00184_lr.hea', '00932_lr.dat', '00017_lr.hea', '00443_lr.dat', '00644_lr.dat', '00464_lr.hea', '00430_lr.hea', '00995_lr.hea', '00529_lr.dat', '00493_lr.dat', '00277_lr.dat', '00737_lr.hea', '00231_lr.dat', '00476_lr.hea', '00132_lr.dat', '00688_lr.dat', '00478_lr.dat', '00128_lr.dat', '00933_lr.dat', '00108_lr.hea', '00539_lr.dat', '00714_lr.hea', '00629_lr.hea', '00747_lr.hea', '00573_lr.hea', '00916_lr.hea', '00330_lr.dat', '00811_lr.dat', '00603_lr.hea', '00870_lr.hea', '00352_lr.dat', '00340_lr.hea', '00351_lr.dat', '00264_lr.hea', '00084_lr.hea', '00267_lr.hea', '00846_lr.hea', '00170_lr.dat', '00055_lr.hea', '00052_lr.dat', '00274_lr.dat', '00575_lr.hea', '00600_lr.hea', '00891_lr.hea', '00323_lr.hea', '00377_lr.dat', '00842_lr.hea', '00938_lr.hea', '00354_lr.dat', '00701_lr.dat', '00364_lr.hea', '00684_lr.hea', '00687_lr.dat', '00635_lr.hea', '00561_lr.dat', '00583_lr.dat', '00897_lr.dat', '00025_lr.dat', '00153_lr.dat', '00060_lr.dat', '00194_lr.dat', '00951_lr.hea', '00853_lr.hea', '00442_lr.dat', '00937_lr.dat', '00030_lr.dat', '00268_lr.dat', '00478_lr.hea', '00138_lr.dat', '00878_lr.hea', '00911_lr.dat', '00922_lr.hea', '00021_lr.dat', '00293_lr.dat', '00324_lr.dat', '00033_lr.hea', '00778_lr.hea', '00135_lr.hea', '00061_lr.hea', '00066_lr.hea', '00533_lr.hea', '00405_lr.dat', '00639_lr.hea', '00408_lr.dat', '00865_lr.hea', '00009_lr.dat', '00027_lr.hea', '00480_lr.dat', '00240_lr.hea', '00620_lr.dat', '00172_lr.dat', '00043_lr.hea', '00992_lr.dat', '00986_lr.hea', '00766_lr.hea', '00582_lr.dat', '00192_lr.dat', '00351_lr.hea', '00633_lr.dat', '00859_lr.hea', '00528_lr.dat', '00364_lr.dat', '00762_lr.hea', '00557_lr.hea', '00895_lr.dat', '00680_lr.dat', '00767_lr.hea', '00871_lr.dat', '00174_lr.hea', '00588_lr.hea', '00150_lr.dat', '00436_lr.dat', '00331_lr.dat', '00008_lr.hea', '00290_lr.hea', '00010_lr.hea', '00974_lr.hea', '00471_lr.hea', '00133_lr.hea', '00385_lr.hea', '00876_lr.dat', '00905_lr.hea', '00481_lr.dat', '00979_lr.hea', '00596_lr.hea', '00637_lr.dat', '00521_lr.dat', '00509_lr.dat', '00403_lr.hea', '00149_lr.dat', '00333_lr.dat', '00193_lr.dat', '00414_lr.hea', '00525_lr.dat', '00040_lr.hea', '00839_lr.dat', '00337_lr.hea', '00804_lr.hea', '00618_lr.hea', '00431_lr.hea', '00525_lr.hea', '00973_lr.dat', '00449_lr.dat', '00188_lr.hea', '00477_lr.hea', '00673_lr.hea', '00549_lr.hea', '00451_lr.dat', '00491_lr.hea', '00823_lr.dat', '00296_lr.hea', '00317_lr.hea', '00759_lr.dat', '00756_lr.hea', '00326_lr.dat', '00423_lr.dat', '00432_lr.hea', '00317_lr.dat', '00100_lr.dat', '00918_lr.dat', '00768_lr.dat', '00790_lr.hea', '00248_lr.dat', '00018_lr.dat', '00290_lr.dat', '00173_lr.hea', '00890_lr.dat', '00064_lr.dat', '00306_lr.hea', '00516_lr.dat', '00152_lr.hea', '00560_lr.dat', '00057_lr.dat', '00817_lr.dat', '00363_lr.dat', '00594_lr.hea', '00356_lr.dat', '00659_lr.hea', '00061_lr.dat', '00467_lr.hea', '00196_lr.hea', '00902_lr.hea', '00647_lr.hea', '00483_lr.dat', '00040_lr.dat', '00817_lr.hea', '00954_lr.dat', '00539_lr.hea', '00636_lr.dat', '00909_lr.dat', '00490_lr.dat', '00362_lr.dat', '00702_lr.dat', '00602_lr.hea', '00846_lr.dat', '00603_lr.dat', '00008_lr.dat', '00969_lr.hea', '00570_lr.dat', '00900_lr.dat', '00257_lr.hea', '00965_lr.dat', '00037_lr.dat', '00450_lr.hea', '00754_lr.hea', '00892_lr.dat', '00978_lr.dat', '00980_lr.dat', '00606_lr.dat', '00831_lr.dat', '00745_lr.dat', '00334_lr.dat', '00288_lr.hea', '00769_lr.dat', '00124_lr.dat', '00001_lr.dat', '00328_lr.hea', '00905_lr.dat', '00211_lr.hea', '00709_lr.hea', '00623_lr.hea', '00441_lr.hea', '00017_lr.dat', '00379_lr.dat', '00878_lr.dat', '00083_lr.hea', '00024_lr.dat', '00198_lr.hea', '00095_lr.hea', '00227_lr.dat', '00745_lr.hea', '00997_lr.hea', '00854_lr.hea', '00723_lr.dat', '00504_lr.hea', '00756_lr.dat', '00924_lr.dat', '00566_lr.dat', '00803_lr.hea', '00894_lr.dat', '00301_lr.dat', '00849_lr.hea', '00535_lr.dat', '00610_lr.hea', '00759_lr.hea', '00975_lr.hea', '00919_lr.hea', '00808_lr.hea', '00676_lr.hea', '00751_lr.hea', '00571_lr.hea', '00616_lr.dat', '00386_lr.hea', '00230_lr.dat', '00642_lr.dat', '00281_lr.dat', '00964_lr.hea', '00191_lr.dat', '00748_lr.hea', '00136_lr.hea', '00828_lr.dat', '00721_lr.hea', '00421_lr.dat', '00420_lr.dat', '00928_lr.hea', '00586_lr.hea', '00951_lr.dat', '00418_lr.hea', '00861_lr.dat', '00609_lr.hea', '00923_lr.dat', '00282_lr.hea', '00080_lr.hea', '00588_lr.dat', '00454_lr.dat', '00912_lr.dat', '00935_lr.dat', '00772_lr.hea', '00784_lr.hea', '00656_lr.hea', '00593_lr.hea', '00444_lr.hea', '00789_lr.hea', '00013_lr.dat', '00764_lr.dat', '00628_lr.hea', '00667_lr.dat', '00005_lr.hea', '00657_lr.hea', '00595_lr.dat', '00669_lr.hea', '00857_lr.hea', '00648_lr.hea', '00376_lr.hea', '00637_lr.hea', '00393_lr.dat', '00336_lr.hea', '00410_lr.hea', '00732_lr.dat', '00907_lr.dat', '00193_lr.hea', '00504_lr.dat', '00977_lr.dat', '00579_lr.dat', '00567_lr.hea', '00657_lr.dat', '00660_lr.dat', '00894_lr.hea', '00655_lr.dat', '00292_lr.hea', '00794_lr.dat', '00903_lr.hea', '00327_lr.dat', '00114_lr.hea', '00661_lr.hea', '00299_lr.dat', '00305_lr.dat', '00420_lr.hea', '00825_lr.dat', '00345_lr.dat', '00517_lr.hea', '00983_lr.hea', '00929_lr.dat', '00761_lr.hea', '00749_lr.hea', '00118_lr.hea', '00488_lr.hea', '00469_lr.dat', '00921_lr.hea', '00199_lr.dat', '00407_lr.hea', '00495_lr.hea', '00127_lr.hea', '00434_lr.hea', '00546_lr.dat', '00735_lr.hea', '00758_lr.dat', '00680_lr.hea', '00070_lr.dat', '00748_lr.dat', '00050_lr.dat', '00578_lr.hea', '00350_lr.hea', '00419_lr.dat', '00284_lr.hea', '00505_lr.dat', '00791_lr.dat', '00531_lr.dat', '00104_lr.hea', '00840_lr.hea', '00260_lr.dat', '00512_lr.dat', '00876_lr.hea', '00917_lr.hea', '00515_lr.dat', '00532_lr.hea', '00513_lr.hea', '00228_lr.hea', '00964_lr.dat', '00941_lr.hea', '00202_lr.dat', '00384_lr.hea', '00976_lr.hea', '00666_lr.hea', '00678_lr.dat', '00495_lr.dat', '00473_lr.hea', '00408_lr.hea', '00665_lr.hea', '00909_lr.hea', '00546_lr.hea', '00875_lr.dat', '00835_lr.hea', '00086_lr.dat', '00945_lr.hea', '00519_lr.hea', '00168_lr.dat', '00952_lr.hea', '00294_lr.hea', '00083_lr.dat', '00491_lr.dat', '00720_lr.hea', '00677_lr.hea', '00466_lr.hea', '00427_lr.dat', '00382_lr.hea', '00599_lr.dat', '00287_lr.dat', '00356_lr.hea', '00301_lr.hea', '00614_lr.dat', '00002_lr.dat', '00626_lr.hea', '00989_lr.dat', '00523_lr.dat', '00869_lr.hea', '00608_lr.dat', '00663_lr.hea', '00276_lr.dat', '00523_lr.hea', '00221_lr.hea', '00181_lr.dat', '00095_lr.dat', '00023_lr.dat', '00475_lr.dat', '00084_lr.dat', '00962_lr.hea', '00703_lr.dat', '00068_lr.dat', '00548_lr.dat', '00389_lr.dat', '00250_lr.dat', '00089_lr.hea', '00630_lr.hea', '00115_lr.dat', '00530_lr.hea', '00375_lr.dat', '00072_lr.hea', '00801_lr.hea', '00925_lr.dat', '00832_lr.dat', '00508_lr.dat', '00059_lr.dat', '00710_lr.dat', '00753_lr.dat', '00371_lr.hea', '00074_lr.dat', '00182_lr.dat', '00738_lr.hea', '00446_lr.hea', '00088_lr.hea', '00501_lr.hea', '00793_lr.hea', '00594_lr.dat', '00499_lr.dat', '00918_lr.hea', '00968_lr.hea', '00676_lr.dat', '00947_lr.dat', '00158_lr.dat', '00742_lr.dat', '00402_lr.hea', '00302_lr.hea', '00160_lr.dat', '00374_lr.dat', '00257_lr.dat', '00439_lr.dat', '00500_lr.dat', '00799_lr.hea', '00942_lr.dat', '00987_lr.dat', '00868_lr.hea', '00014_lr.hea', '00960_lr.dat', '00322_lr.dat', '00194_lr.hea', '00568_lr.hea', '00585_lr.dat', '00400_lr.dat', '00548_lr.hea', '00781_lr.hea', '00597_lr.dat', '00714_lr.dat', '00993_lr.dat', '00950_lr.hea', '00996_lr.hea', '00254_lr.dat', '00775_lr.hea', '00381_lr.dat', '00003_lr.hea', '00682_lr.hea', '00432_lr.dat', '00090_lr.hea', '00882_lr.dat', '00552_lr.hea', '00244_lr.dat', '00089_lr.dat', '00360_lr.hea', '00280_lr.dat', '00335_lr.dat', '00121_lr.dat', '00251_lr.hea', '00776_lr.dat', '00972_lr.dat', '00105_lr.dat', '00818_lr.hea', '00367_lr.hea', '00601_lr.hea', '00844_lr.dat', '00183_lr.dat', '00105_lr.hea', '00889_lr.hea', '00767_lr.dat', '00050_lr.hea', '00372_lr.hea', '00512_lr.hea', '00505_lr.hea', '00096_lr.hea', '00916_lr.dat', '00348_lr.dat', '00111_lr.dat', '00154_lr.hea', '00739_lr.dat', '00600_lr.dat', '00772_lr.dat', '00731_lr.hea', '00338_lr.dat', '00743_lr.dat', '00498_lr.dat', '00739_lr.hea', '00022_lr.hea', '00448_lr.dat', '00874_lr.dat', '00392_lr.dat', '00492_lr.hea', '00218_lr.dat', '00151_lr.dat', '00913_lr.hea', '00214_lr.dat', '00749_lr.dat', '00124_lr.hea', '00452_lr.hea', '00696_lr.dat', '00241_lr.hea', '00866_lr.dat', '00404_lr.hea', '00388_lr.dat', '00605_lr.dat', '00101_lr.dat', '00782_lr.dat', '00075_lr.hea', '00425_lr.hea', '00347_lr.dat', '00049_lr.dat', '00658_lr.hea', '00018_lr.hea', '00032_lr.dat', '00260_lr.hea', '00413_lr.dat', '00192_lr.hea', '00319_lr.hea', '00208_lr.hea', '00865_lr.dat', '00120_lr.hea', '00019_lr.dat', '00069_lr.hea', '00287_lr.hea', '00899_lr.dat', '00611_lr.dat', '00755_lr.hea', '00493_lr.hea', '00579_lr.hea', '00592_lr.dat', '00033_lr.dat', '00893_lr.hea', '00031_lr.dat', '00179_lr.dat', '00371_lr.dat', '00321_lr.dat', '00877_lr.dat', '00209_lr.dat', '00046_lr.hea', '00102_lr.dat', '00675_lr.hea', '00670_lr.hea', '00016_lr.dat', '00776_lr.hea', '00953_lr.dat', '00507_lr.hea', '00498_lr.hea', '00097_lr.hea', '00633_lr.hea', '00900_lr.hea', '00583_lr.hea', '00873_lr.dat', '00622_lr.dat', '00316_lr.dat', '00931_lr.hea', '00902_lr.dat', '00185_lr.hea', '00330_lr.hea', '00589_lr.hea', '00805_lr.hea', '00950_lr.dat', '00850_lr.dat', '00758_lr.hea', '00961_lr.dat', '00620_lr.hea', '00606_lr.hea', '00809_lr.hea', '00438_lr.hea', '00201_lr.hea', '00346_lr.dat', '00405_lr.hea', '00829_lr.hea', '00843_lr.hea', '00497_lr.hea', '00602_lr.dat', '00682_lr.dat', '00937_lr.hea', '00200_lr.hea', '00586_lr.dat', '00047_lr.hea', '00177_lr.dat', '00482_lr.hea', '00872_lr.hea', '00553_lr.dat', '00398_lr.hea', '00062_lr.dat', '00154_lr.dat', '00769_lr.hea', '00499_lr.hea', '00170_lr.hea', '00222_lr.dat', '00826_lr.hea', '00004_lr.dat', '00437_lr.dat', '00366_lr.dat', '00558_lr.hea', '00212_lr.dat', '00044_lr.hea', '00999_lr.hea', '00207_lr.dat', '00445_lr.hea', '00352_lr.hea', '00632_lr.hea', '00688_lr.hea', '00935_lr.hea', '00216_lr.dat', '00295_lr.hea', '00391_lr.dat', '00384_lr.dat', '00921_lr.dat', '00685_lr.dat', '00534_lr.dat', '00286_lr.hea', '00001_lr.hea', '00753_lr.hea', '00791_lr.hea', '00831_lr.hea', '00299_lr.hea', '00510_lr.dat', '00318_lr.dat', '00361_lr.hea', '00689_lr.hea', '00958_lr.hea', '00837_lr.hea', '00440_lr.hea', '00528_lr.hea', '00859_lr.dat', '00922_lr.dat', '00186_lr.hea', '00901_lr.dat', '00496_lr.hea', '00715_lr.dat', '00269_lr.dat', '00838_lr.hea', '00807_lr.hea', '00980_lr.hea', '00757_lr.dat', '00624_lr.hea', '00730_lr.dat', '00382_lr.dat', '00063_lr.dat', '00210_lr.dat', '00285_lr.hea', '00551_lr.hea', '00763_lr.hea', '00041_lr.dat', '00122_lr.hea', '00449_lr.hea', '00850_lr.hea', '00747_lr.dat', '00871_lr.hea', '00567_lr.dat', '00283_lr.dat', '00938_lr.dat', '00190_lr.hea', '00931_lr.dat', '00392_lr.hea', '00551_lr.dat', '00726_lr.dat', '00617_lr.dat', '00887_lr.hea', '00056_lr.dat', '00677_lr.dat', '00554_lr.hea', '00165_lr.hea', '00357_lr.hea', '00394_lr.dat', '00990_lr.dat', '00224_lr.dat', '00308_lr.dat', '00847_lr.dat', '00879_lr.hea', '00058_lr.dat', '00631_lr.dat', '00390_lr.hea', '00526_lr.hea', '00862_lr.dat', '00815_lr.dat', '00695_lr.hea', '00208_lr.dat', '00048_lr.hea', '00917_lr.dat', '00780_lr.hea', '00051_lr.hea', '00093_lr.dat', '00520_lr.hea', '00242_lr.dat', '00810_lr.hea', '00630_lr.dat', '00694_lr.dat', '00176_lr.dat', '00694_lr.hea', '00212_lr.hea', '00746_lr.dat', '00323_lr.dat', '00398_lr.dat', '00409_lr.hea', '00492_lr.dat', '00777_lr.dat', '00619_lr.dat', '00963_lr.dat', '00343_lr.dat', '00225_lr.hea', '00965_lr.hea', '00368_lr.dat', '00860_lr.dat', '00489_lr.hea', '00613_lr.hea', '00308_lr.hea', '00377_lr.hea', '00852_lr.hea', '00465_lr.hea', '00725_lr.hea', '00762_lr.dat', '00591_lr.hea', '00437_lr.hea', '00148_lr.dat', '00310_lr.hea', '00321_lr.hea', '00560_lr.hea', '00851_lr.dat', '00207_lr.hea', '00263_lr.hea', '00093_lr.hea', '00771_lr.hea', '00527_lr.dat', '00920_lr.hea', '00687_lr.hea', '00147_lr.dat', '00646_lr.dat', '00233_lr.hea', '00012_lr.dat', '00782_lr.hea', '00004_lr.hea', '00077_lr.hea', '00996_lr.dat', '00621_lr.hea', '00547_lr.hea', '00810_lr.dat', '00764_lr.hea', '00754_lr.dat', '00638_lr.dat', '00991_lr.hea', '00563_lr.dat', '00844_lr.hea', '00195_lr.dat', '00580_lr.hea', '00800_lr.hea', '00472_lr.hea', '00153_lr.hea', '00981_lr.hea', '00162_lr.hea', '00470_lr.hea', '00060_lr.hea', '00342_lr.dat', '00021_lr.hea', '00237_lr.hea', '00080_lr.dat', '00164_lr.hea', '00577_lr.dat', '00375_lr.hea', '00243_lr.hea', '00562_lr.hea', '00645_lr.dat', '00812_lr.dat', '00073_lr.dat', '00638_lr.hea', '00289_lr.hea', '00886_lr.dat', '00970_lr.dat', '00796_lr.dat', '00028_lr.hea', '00522_lr.hea', '00643_lr.dat', '00741_lr.dat', '00898_lr.hea', '00056_lr.hea', '00167_lr.hea', '00576_lr.hea', '00750_lr.hea', '00066_lr.dat', '00339_lr.hea', '00928_lr.dat', '00983_lr.dat', '00300_lr.dat', '00217_lr.dat', '00701_lr.hea', '00892_lr.hea', '00266_lr.dat', '00906_lr.hea', '00078_lr.hea', '00359_lr.dat', '00485_lr.dat', '00540_lr.hea', '00109_lr.dat', '00399_lr.hea', '00289_lr.dat', '00511_lr.dat', '00340_lr.dat', '00252_lr.hea', '00863_lr.dat', '00731_lr.dat', '00584_lr.dat', '00327_lr.hea', '00778_lr.dat', '00128_lr.hea', '00448_lr.hea', '00591_lr.dat', '00053_lr.dat', '00728_lr.dat', '00895_lr.hea', '00659_lr.dat', '00813_lr.dat', '00149_lr.hea', '00750_lr.dat', '00278_lr.hea', '00863_lr.hea', '00263_lr.dat', '00779_lr.hea', '00428_lr.hea', '00957_lr.hea', '00797_lr.dat', '00683_lr.dat', '00322_lr.hea', '00544_lr.hea', '00190_lr.dat', '00852_lr.dat', '00684_lr.dat', '00934_lr.dat', '00827_lr.dat', '00856_lr.hea', '00720_lr.dat', '00819_lr.hea', '00370_lr.dat', '00343_lr.hea', '00362_lr.hea', '00843_lr.dat', '00815_lr.hea', '00113_lr.hea', '00092_lr.hea', '00467_lr.dat', '00258_lr.hea', '00011_lr.dat', '00888_lr.dat', '00253_lr.hea', '00350_lr.dat', '00444_lr.dat', '00406_lr.hea', '00034_lr.dat', '00291_lr.dat', '00075_lr.dat', '00214_lr.hea', '00653_lr.dat', '00914_lr.dat', '00177_lr.hea', '00788_lr.dat', '00679_lr.hea', '00827_lr.hea', '00914_lr.hea', '00543_lr.hea', '00117_lr.dat', '00662_lr.dat', '00314_lr.hea', '00502_lr.dat', '00645_lr.hea', '00125_lr.hea', '00366_lr.hea', '00338_lr.hea', '00450_lr.dat', '00133_lr.dat', '00501_lr.dat', '00712_lr.hea', '00790_lr.dat', '00500_lr.hea', '00711_lr.hea', '00020_lr.dat', '00585_lr.hea', '00554_lr.dat', '00944_lr.dat', '00975_lr.dat', '00412_lr.dat', '00719_lr.dat', '00752_lr.hea', '00418_lr.dat', '00651_lr.dat', '00427_lr.hea', '00273_lr.dat', '00885_lr.hea', '00468_lr.hea', '00514_lr.dat', '00954_lr.hea', '00883_lr.hea', '00065_lr.hea', '00370_lr.hea', '00236_lr.dat', '00795_lr.dat', '00172_lr.hea', '00582_lr.hea', '00640_lr.hea', '00373_lr.hea', '00974_lr.dat', '00270_lr.hea', '00774_lr.hea', '00664_lr.hea', '00888_lr.hea', '00884_lr.dat', '00024_lr.hea', '00601_lr.dat', '00045_lr.dat', '00465_lr.dat', '00293_lr.hea', '00394_lr.hea', '00215_lr.hea', '00779_lr.dat', '00991_lr.dat', '00144_lr.hea', '00470_lr.dat', '00972_lr.hea', '00744_lr.hea', '00963_lr.hea', '00526_lr.dat', '00166_lr.hea', '00736_lr.hea', '00171_lr.dat', '00155_lr.dat', '00936_lr.hea', '00653_lr.hea', '00558_lr.dat', '00167_lr.dat', '00147_lr.hea', '00765_lr.dat', '00189_lr.dat', '00707_lr.dat', '00303_lr.dat', '00855_lr.hea', '00692_lr.hea', '00654_lr.dat', '00734_lr.hea', '00359_lr.hea', '00481_lr.hea', '00735_lr.dat', '00934_lr.hea', '00020_lr.hea', '00129_lr.dat', '00822_lr.hea', '00286_lr.dat', '00472_lr.dat', '00324_lr.hea', '00114_lr.dat', '00219_lr.dat', '00718_lr.dat', '00416_lr.hea', '00198_lr.dat', '00632_lr.dat', '00265_lr.hea', '00486_lr.hea', '00252_lr.dat', '00426_lr.hea', '00634_lr.hea', '00006_lr.dat', '00156_lr.dat', '00460_lr.hea', '00524_lr.dat', '00773_lr.hea', '00672_lr.hea', '00836_lr.dat', '00226_lr.dat', '00488_lr.dat', '00117_lr.hea', '00943_lr.dat', '00182_lr.hea', '00077_lr.dat', '00201_lr.dat', '00401_lr.hea', '00081_lr.dat', '00298_lr.dat', '00369_lr.hea', '00716_lr.dat', '00160_lr.hea', '00326_lr.hea', '00116_lr.dat', '00547_lr.dat', '00761_lr.dat', '00877_lr.hea', '00278_lr.dat', '00446_lr.dat', '00119_lr.hea', '00081_lr.hea', '00440_lr.dat', '00946_lr.hea', '00886_lr.hea', '00026_lr.hea', '00129_lr.hea', '00226_lr.hea', '00502_lr.hea', '00484_lr.dat', '00125_lr.dat', '00222_lr.hea', '00734_lr.dat', '00296_lr.dat', '00536_lr.hea', '00120_lr.dat', '00455_lr.hea', '00742_lr.hea', '00805_lr.dat', '00783_lr.dat', '00572_lr.dat', '00612_lr.dat', '00516_lr.hea', '00106_lr.hea', '00837_lr.dat', '00320_lr.hea', '00503_lr.dat', '00785_lr.hea', '00235_lr.hea', '00907_lr.hea', '00254_lr.hea', '00920_lr.dat', '00404_lr.dat', '00256_lr.hea', '00540_lr.dat', '00524_lr.hea', '00924_lr.hea', '00202_lr.hea', '00224_lr.hea', '00316_lr.hea', '00219_lr.hea', '00163_lr.dat', '00787_lr.hea', '00248_lr.hea', '00187_lr.dat', '00280_lr.hea', '00146_lr.dat', '00672_lr.dat', '00151_lr.hea', '00353_lr.hea', '00268_lr.hea', '00697_lr.dat', '00847_lr.hea', '00085_lr.hea', '00272_lr.hea', '00246_lr.hea', '00388_lr.hea', '00668_lr.hea', '00476_lr.dat', '00234_lr.hea', '00716_lr.hea', '00460_lr.dat', '00468_lr.dat', '00086_lr.hea', '00325_lr.dat', '00475_lr.hea', '00342_lr.hea', '00949_lr.hea', '00055_lr.dat', '00697_lr.hea', '00897_lr.hea', '00995_lr.dat', '00969_lr.dat', '00473_lr.dat', '00732_lr.hea', '00213_lr.hea', '00509_lr.hea', '00715_lr.hea', '00839_lr.hea', '00667_lr.hea', '00955_lr.dat', '00799_lr.dat', '00195_lr.hea', '00580_lr.dat', '00607_lr.dat', '00295_lr.dat', '00309_lr.hea', '00012_lr.hea', '00961_lr.hea', '00485_lr.hea', '00494_lr.hea', '00099_lr.dat', '00944_lr.hea', '00814_lr.hea', '00383_lr.hea', '00396_lr.dat', '00466_lr.dat', '00957_lr.dat', '00690_lr.dat', '00538_lr.dat', '00413_lr.hea', '00109_lr.hea', '00453_lr.hea', '00849_lr.dat', '00678_lr.hea', '00696_lr.hea', '00952_lr.dat', '00789_lr.dat', '00032_lr.hea', '00517_lr.dat', '00890_lr.hea', '00933_lr.hea', '00986_lr.dat', '00853_lr.dat', '00786_lr.dat', '00168_lr.hea', '00368_lr.hea', '00880_lr.hea', '00641_lr.hea', '00848_lr.dat', '00052_lr.hea', '00555_lr.hea', '00796_lr.hea', '00102_lr.hea', '00508_lr.hea', '00565_lr.dat', '00101_lr.hea', '00217_lr.hea', '00912_lr.hea', '00589_lr.dat', '00712_lr.dat', '00664_lr.dat', '00655_lr.hea', '00840_lr.dat', '00216_lr.hea', '00328_lr.dat', '00111_lr.hea', '00097_lr.dat', '00757_lr.hea', '00727_lr.dat', '00361_lr.dat', '00648_lr.dat', '00429_lr.hea', '00979_lr.dat', '00885_lr.dat', '00074_lr.hea', '00229_lr.hea', '00834_lr.hea', '00703_lr.hea', '00724_lr.dat', '00867_lr.dat', '00487_lr.hea', '00355_lr.dat', '00239_lr.dat', '00953_lr.hea', '00042_lr.hea', '00039_lr.dat', '00215_lr.dat', '00038_lr.hea', '00542_lr.hea', '00275_lr.hea', '00765_lr.hea', '00200_lr.dat', '00146_lr.hea', '00106_lr.dat', '00178_lr.dat', '00650_lr.dat', '00988_lr.hea', '00009_lr.hea', '00700_lr.hea', '00706_lr.dat', '00411_lr.dat', '00380_lr.hea', '00123_lr.hea', '00136_lr.dat', '00774_lr.dat', '00770_lr.dat', '00480_lr.hea', '00811_lr.hea', '00079_lr.dat', '00973_lr.hea', '00294_lr.dat', '00054_lr.dat', '00722_lr.dat', '00166_lr.dat', '00477_lr.dat', '00271_lr.hea', '00199_lr.hea', '00104_lr.dat', '00285_lr.dat', '00126_lr.hea', '00598_lr.dat', '00304_lr.dat', '00913_lr.dat', '00401_lr.dat', '00717_lr.dat', '00833_lr.hea', '00191_lr.hea', '00541_lr.dat', '00984_lr.dat', '00402_lr.dat', '00487_lr.dat', '00771_lr.dat', '00518_lr.hea', '00808_lr.dat', '00067_lr.dat', '00985_lr.dat', '00614_lr.hea', '00496_lr.dat', '00279_lr.dat', '00022_lr.dat', '00809_lr.dat', '00725_lr.dat', '00845_lr.dat', '00092_lr.dat', '00307_lr.dat', '00346_lr.hea', '00836_lr.hea', '00169_lr.dat', '00695_lr.dat', '00507_lr.dat', '00223_lr.dat', '00869_lr.dat', '00474_lr.hea', '00069_lr.dat', '00506_lr.dat', '00587_lr.hea', '00685_lr.hea', '00262_lr.hea', '00998_lr.dat', '00272_lr.dat', '00571_lr.dat', '00629_lr.dat', '00671_lr.hea', '00971_lr.hea', '00205_lr.dat', '00627_lr.hea', '00150_lr.hea', '00609_lr.dat', '00845_lr.hea', '00029_lr.dat', '00305_lr.hea', '00010_lr.dat', '00887_lr.dat', '00976_lr.dat', '00942_lr.hea', '00930_lr.dat', '00469_lr.hea', '00031_lr.hea', '00994_lr.dat', '00174_lr.dat', '00834_lr.dat', '00479_lr.hea', '00967_lr.dat', '00522_lr.dat', '00681_lr.hea', '00204_lr.hea', '00569_lr.dat', '00689_lr.dat', '00332_lr.hea', '00661_lr.dat', '00439_lr.hea', '00956_lr.hea', '00284_lr.dat', '00671_lr.dat', '00329_lr.dat', '00545_lr.dat', '00087_lr.hea', '00051_lr.dat', '00425_lr.dat', '00265_lr.dat', '00625_lr.hea', '00798_lr.hea', '00233_lr.dat', '00899_lr.hea', '00773_lr.dat', '00181_lr.hea', '00353_lr.dat', '00397_lr.dat', '00180_lr.hea', '00311_lr.dat', '00057_lr.hea', '00708_lr.hea', '00234_lr.dat', '00247_lr.dat', '00169_lr.hea', '00652_lr.hea', '00423_lr.hea', '00123_lr.dat', '00800_lr.dat', '00833_lr.dat', '00127_lr.dat', '00616_lr.hea', '00575_lr.dat', '00241_lr.dat', '00197_lr.dat', '00434_lr.dat', '00043_lr.dat', '00550_lr.dat', '00341_lr.hea', '00116_lr.hea', '00005_lr.dat', '00261_lr.hea', '00543_lr.dat', '00733_lr.hea', '00474_lr.dat', '00209_lr.hea', '00363_lr.hea', '00411_lr.hea', '00121_lr.hea', '00108_lr.dat', '00966_lr.dat', '00656_lr.dat', '00624_lr.dat', '00311_lr.hea', '00130_lr.hea', '00098_lr.hea', '00816_lr.dat', '00302_lr.dat', '00768_lr.hea', '00760_lr.hea', '00842_lr.dat', '00152_lr.dat', '00763_lr.dat', '00883_lr.dat', '00615_lr.dat', '00232_lr.dat', '00489_lr.dat', '00422_lr.hea', '00577_lr.hea', '00576_lr.dat', '00559_lr.hea', '00292_lr.dat', '00457_lr.dat', '00447_lr.dat', '00881_lr.hea', '00173_lr.dat', '00611_lr.hea', '00617_lr.hea', '00023_lr.hea', '00395_lr.dat', '00165_lr.dat', '00994_lr.hea', '00820_lr.hea', '00157_lr.dat', '00879_lr.dat', '00860_lr.hea', '00438_lr.dat', '00203_lr.dat', '00178_lr.hea', '00087_lr.dat', '00112_lr.hea', '00880_lr.dat', '00881_lr.dat', '00755_lr.dat', '00785_lr.dat', '00082_lr.dat', '00896_lr.dat', '00433_lr.dat', '00999_lr.dat', '00660_lr.hea', '00814_lr.dat', '00737_lr.dat', '00704_lr.dat', '00544_lr.dat', '00910_lr.dat', '00722_lr.hea', '00259_lr.hea', '00927_lr.dat', '00968_lr.dat', '00541_lr.hea', '00797_lr.hea', '00119_lr.dat', '00412_lr.hea', '00072_lr.dat', '00484_lr.hea', '00945_lr.dat', '00520_lr.dat', '00180_lr.dat', '00391_lr.hea', '00355_lr.hea', '00710_lr.hea', '00702_lr.hea', '00830_lr.dat', '00262_lr.dat', '00818_lr.dat', '00197_lr.hea', '00556_lr.dat', '00987_lr.hea', '00908_lr.dat', '00593_lr.dat', '00358_lr.hea', '00727_lr.hea', '00915_lr.dat', '00134_lr.hea', '00235_lr.dat', '00939_lr.hea', '00642_lr.hea', '00126_lr.dat', '00658_lr.dat', '00553_lr.hea', '00091_lr.hea', '00613_lr.dat', '00335_lr.hea', '00770_lr.hea', '00303_lr.hea', '00930_lr.hea', '00482_lr.dat', '00162_lr.dat', '00514_lr.hea', '00419_lr.hea', '00534_lr.hea', '00872_lr.dat', '00623_lr.dat', '00236_lr.hea', '00595_lr.hea', '00832_lr.hea', '00806_lr.hea', '00132_lr.hea', '00513_lr.dat', '00455_lr.dat', '00730_lr.hea', '00158_lr.hea', '00048_lr.dat', '00673_lr.dat', '00065_lr.dat', '00041_lr.hea', '00436_lr.hea', '00428_lr.dat', '00019_lr.hea', '00027_lr.dat', '00738_lr.dat', '00026_lr.dat', '00841_lr.hea', '00705_lr.dat', '00691_lr.dat', '00298_lr.hea', '00643_lr.hea', '00856_lr.dat', '00279_lr.hea', '00985_lr.hea', '00243_lr.dat', '00947_lr.hea', '00310_lr.dat', '00559_lr.dat', '00275_lr.dat', '00578_lr.dat', '00291_lr.hea', '00824_lr.dat', '00729_lr.hea', '00006_lr.hea', '00709_lr.dat', '00229_lr.dat', '00134_lr.dat', '00692_lr.dat', '00240_lr.dat', '00705_lr.hea', '00094_lr.dat', '00464_lr.dat', '00592_lr.hea', '00813_lr.hea', '00550_lr.hea', '00663_lr.dat', '00649_lr.hea', '00635_lr.dat', '00255_lr.dat', '00251_lr.dat', '00421_lr.hea', '00076_lr.hea', '00306_lr.dat', '00274_lr.hea', '00741_lr.hea', '00651_lr.hea', '00884_lr.hea', '00683_lr.hea', '00071_lr.hea', '00103_lr.hea', '00099_lr.hea', '00627_lr.dat', '00063_lr.hea', '00309_lr.dat', '00826_lr.dat', '00264_lr.dat', '00943_lr.hea', '00510_lr.hea', '00674_lr.dat', '00320_lr.dat', '00618_lr.dat', '00830_lr.hea', '00574_lr.dat', '00329_lr.hea', '00258_lr.dat', '00403_lr.dat', '00038_lr.dat', '00245_lr.hea', '00792_lr.hea', '00463_lr.dat', '00378_lr.hea', '00035_lr.hea', '00441_lr.dat', '00760_lr.dat', '00225_lr.dat', '00211_lr.dat', '00713_lr.dat', '00333_lr.hea', '00188_lr.dat', '00044_lr.dat', '00171_lr.hea', '00250_lr.hea', '00304_lr.hea', '00341_lr.dat', '00016_lr.hea', '00610_lr.dat', '00395_lr.hea', '00506_lr.hea', '00990_lr.hea', '00822_lr.dat', '00002_lr.hea', '00277_lr.hea', '00365_lr.hea', '00414_lr.dat', '00795_lr.hea', '00946_lr.dat', '00521_lr.hea', '00270_lr.dat', '00062_lr.hea', '00641_lr.dat', '00435_lr.dat', '00424_lr.hea', '00960_lr.hea', '00372_lr.dat', '00788_lr.hea', '00490_lr.hea', '00503_lr.hea', '00841_lr.dat', '00783_lr.hea', '00674_lr.hea', '00693_lr.hea', '00161_lr.dat', '00670_lr.dat', '00858_lr.hea', '00091_lr.dat', '00256_lr.dat', '00378_lr.dat', '00374_lr.hea', '00619_lr.hea', '00794_lr.hea', '00545_lr.hea', '00261_lr.dat', '00982_lr.hea', '00923_lr.hea', '00941_lr.dat', '00393_lr.hea', '00864_lr.hea', '00668_lr.dat', '00959_lr.dat', '00426_lr.dat', '00486_lr.dat', '00035_lr.dat', '00183_lr.hea', '00766_lr.dat', '00435_lr.hea', '00454_lr.hea', '00751_lr.dat', '00186_lr.dat', '00130_lr.dat', '00717_lr.hea', '00042_lr.dat', '00631_lr.hea', '00357_lr.dat', '00176_lr.hea', '00336_lr.dat', '00956_lr.dat', '00728_lr.hea', '00267_lr.dat', '00867_lr.hea', '00122_lr.dat', '00784_lr.dat', '00358_lr.dat', '00801_lr.dat', '00608_lr.hea', '00699_lr.hea', '00896_lr.hea', '00807_lr.dat', '00015_lr.hea', '00457_lr.hea', '00471_lr.dat', '00313_lr.hea', '00007_lr.dat', '00098_lr.dat', '00889_lr.dat', '00237_lr.dat', '00415_lr.dat', '00112_lr.dat', '00221_lr.dat', '00821_lr.dat', '00175_lr.hea', '00882_lr.hea', '00259_lr.dat', '00537_lr.hea', '00479_lr.dat', '00189_lr.hea', '00443_lr.hea', '00387_lr.dat', '00552_lr.dat', '00067_lr.hea', '00205_lr.hea', '00422_lr.dat', '00397_lr.hea', '00929_lr.hea', '00698_lr.hea', '00416_lr.dat', '00407_lr.dat', '00665_lr.dat', '00654_lr.hea', '00334_lr.hea', '00276_lr.hea', '00904_lr.dat', '00662_lr.hea', '00804_lr.dat', '00220_lr.dat', '00777_lr.hea', '00926_lr.hea', '00073_lr.hea', '00625_lr.dat', '00626_lr.dat', '00367_lr.dat', '00494_lr.dat', '00854_lr.dat', '00431_lr.dat', '00314_lr.dat', '00646_lr.hea', '00030_lr.hea', '00218_lr.hea', '00300_lr.hea', '00640_lr.dat', '00156_lr.hea', '00612_lr.hea', '00919_lr.dat', '00690_lr.hea', '00557_lr.dat', '00015_lr.dat', '00090_lr.dat', '00581_lr.dat', '00835_lr.dat', '00572_lr.hea', '00803_lr.dat', '00906_lr.dat', '00970_lr.hea', '00118_lr.dat', '00746_lr.hea', '00927_lr.hea', '00866_lr.hea', '00699_lr.dat', '00273_lr.hea', '00445_lr.dat', '00453_lr.dat', '00958_lr.dat', '00232_lr.hea', '00569_lr.hea', '00870_lr.dat', '00082_lr.hea', '00669_lr.dat', '00037_lr.hea', '00244_lr.hea', '00390_lr.dat', '00415_lr.hea', '00332_lr.dat', '00903_lr.dat', '00283_lr.hea', '00014_lr.dat', '00163_lr.hea', '00971_lr.dat', '00409_lr.dat', '00078_lr.dat', '00584_lr.hea', '00107_lr.hea', '00379_lr.hea', '00011_lr.hea', '00561_lr.hea', '00223_lr.hea', '00071_lr.dat', '00003_lr.dat', '00068_lr.hea', '00096_lr.dat', '00399_lr.dat', '00910_lr.hea', '00686_lr.dat', '00315_lr.dat', '00752_lr.dat', '00733_lr.dat', '00962_lr.dat', '00348_lr.hea', '00238_lr.hea', '00380_lr.dat', '00058_lr.hea', '00110_lr.hea', '00792_lr.dat', '00940_lr.dat', '00045_lr.hea', '00161_lr.hea', '00036_lr.dat', '00213_lr.dat', '00483_lr.hea', '00848_lr.hea', '00255_lr.hea', '00786_lr.hea', '00706_lr.hea', '00249_lr.hea', '00530_lr.dat', '00131_lr.hea', '00563_lr.hea', '00070_lr.hea', '00740_lr.hea', '00621_lr.dat', '00282_lr.dat', '00271_lr.dat', '00376_lr.dat', '00518_lr.dat', '00325_lr.hea', '00915_lr.hea', '00562_lr.dat', '00724_lr.hea', '00639_lr.dat', '00564_lr.hea', '00793_lr.dat', '00864_lr.dat', '00442_lr.hea', '00297_lr.dat', '00312_lr.dat', '00604_lr.hea', '00587_lr.dat', '00959_lr.hea', '00157_lr.hea', '00652_lr.dat', '00891_lr.dat', '00354_lr.hea', '00798_lr.dat', '00825_lr.hea', '00238_lr.dat', '00855_lr.dat', '00573_lr.dat', '00210_lr.hea', '00307_lr.hea', '00932_lr.hea', '00901_lr.hea', '00857_lr.dat', '00228_lr.dat', '00708_lr.dat', '00028_lr.dat', '00249_lr.dat', '00590_lr.hea', '00721_lr.dat', '00686_lr.hea', '00598_lr.hea', '00535_lr.hea', '00949_lr.dat', '00679_lr.dat', '00349_lr.hea', '00874_lr.hea', '00100_lr.hea', '00088_lr.dat', '00868_lr.dat', '00034_lr.hea', '00736_lr.dat', '00824_lr.hea', '00206_lr.hea', '00566_lr.hea', '00220_lr.hea', '00549_lr.dat', '00681_lr.dat', '00064_lr.hea', '00596_lr.dat']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nimport os\n\nDATA_DIR = \"/kaggle/input/dl-dataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3\"\n\nmeta = pd.read_csv(os.path.join(DATA_DIR, \"ptbxl_database.csv\"))\nscp_df = pd.read_csv(os.path.join(DATA_DIR, \"scp_statements.csv\"), index_col=0)\n\nprint(\"meta shape:\", meta.shape)\nprint(\"scp_df shape:\", scp_df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T09:50:02.341482Z","iopub.execute_input":"2025-11-23T09:50:02.342090Z","iopub.status.idle":"2025-11-23T09:50:02.532873Z","shell.execute_reply.started":"2025-11-23T09:50:02.342067Z","shell.execute_reply":"2025-11-23T09:50:02.531985Z"}},"outputs":[{"name":"stdout","text":"meta shape: (21799, 28)\nscp_df shape: (71, 12)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"scp_df = scp_df[scp_df['diagnostic'] == 1]\n\nSUPERCLASS_MAP = {\n    'NORM': 0,\n    'MI': 1,\n    'STTC': 2,\n    'HYP': 3,\n    'CD': 4\n}\n\ndef get_superclass(code):\n    try:\n        diag = scp_df.loc[code, 'diagnostic_class']\n        return SUPERCLASS_MAP.get(diag, None)\n    except:\n        return None\n\ndef extract_label(row):\n    s = row['scp_codes']\n    try:\n        d = eval(s)\n    except:\n        return None\n    labels = []\n    for k in d.keys():\n        cls = get_superclass(k)\n        if cls is not None:\n            labels.append(cls)\n    if len(labels)==0:\n        return None\n    return labels[0]   \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T09:57:39.155325Z","iopub.execute_input":"2025-11-23T09:57:39.156103Z","iopub.status.idle":"2025-11-23T09:57:39.162390Z","shell.execute_reply.started":"2025-11-23T09:57:39.156079Z","shell.execute_reply":"2025-11-23T09:57:39.161599Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"TARGET_FS = 250\nWINDOW_SEC = 5\nWINDOW_SAMPLES = TARGET_FS * WINDOW_SEC\nOVERLAP = 0.5\n\ndef resample(sig, orig_fs):\n    if orig_fs == TARGET_FS:\n        return sig\n    new_len = int(len(sig) * TARGET_FS / orig_fs)\n    return signal.resample(sig, new_len)\n\ndef highpass(sig):\n    b,a = signal.butter(2, 0.5/(TARGET_FS/2), 'high')\n    return signal.filtfilt(b,a,sig)\n\ndef bandpass(sig):\n    b,a = signal.butter(4, [0.5/(TARGET_FS/2), 40/(TARGET_FS/2)], 'band')\n    return signal.filtfilt(b,a,sig)\n\ndef notch(sig, f0=50):\n    w0 = f0/(TARGET_FS/2)\n    b,a = signal.iirnotch(w0, 30)\n    return signal.filtfilt(b,a,sig)\n\ndef normalize(sig):\n    return (sig - np.mean(sig)) / (np.std(sig) + 1e-8)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T09:57:41.844611Z","iopub.execute_input":"2025-11-23T09:57:41.845130Z","iopub.status.idle":"2025-11-23T09:57:41.851385Z","shell.execute_reply.started":"2025-11-23T09:57:41.845106Z","shell.execute_reply":"2025-11-23T09:57:41.850538Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def extract_windows_fft(row):\n    file_path = os.path.join(DATA_DIR, row['filename_hr'])\n    file_path = file_path.replace(\".dat\", \"\")\n\n    try:\n        rec = wfdb.rdrecord(file_path)\n    except:\n        return None, None\n\n\n    sig = rec.p_signal          # shape: (T, 12)\n    fs = rec.fs\n\n    # 1) Resample\n    if fs != TARGET_FS:\n        sig = np.array([resample(sig[:,i], fs) for i in range(sig.shape[1])]).T\n\n    # 2) Filters\n    for i in range(12):\n        sig[:, i] = highpass(sig[:, i])\n        sig[:, i] = bandpass(sig[:, i])\n        sig[:, i] = notch(sig[:, i])\n        sig[:, i] = normalize(sig[:, i])\n\n    # 3) Windowing\n    hop = int(WINDOW_SAMPLES*(1-OVERLAP))\n    windows = []\n    for start in range(0, len(sig)-WINDOW_SAMPLES, hop):\n        w = sig[start:start+WINDOW_SAMPLES]        # shape: (1250, 12)\n\n        # 4) FFT for each lead (base paper)\n        fft_win = []\n        for lead in range(12):\n            f = np.abs(rfft(w[:, lead]))[:600]     # keep first 600 freq bins\n            fft_win.append(f)\n\n        fft_win = np.array(fft_win).T              # shape: (600, 12)\n        windows.append(fft_win.astype(np.float32))\n\n    return windows, extract_label(row)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T09:57:58.998315Z","iopub.execute_input":"2025-11-23T09:57:58.999081Z","iopub.status.idle":"2025-11-23T09:57:59.005768Z","shell.execute_reply.started":"2025-11-23T09:57:58.999055Z","shell.execute_reply":"2025-11-23T09:57:59.005012Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"X, Y = [], []\n\nfor i, row in meta.iterrows():\n    label = extract_label(row)\n    if label is None:\n        continue\n\n    win, lab = extract_windows_fft(row)\n    if win is None:\n        continue\n\n    for w in win:\n        X.append(w)\n        Y.append(lab)\n\nX = np.array(X)\nY = np.array(Y)\n\nprint(\"Final dataset shape:\", X.shape, Y.shape)\nprint(\"Class distribution:\", Counter(Y)) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T09:58:01.850321Z","iopub.execute_input":"2025-11-23T09:58:01.850904Z","iopub.status.idle":"2025-11-23T10:07:20.718010Z","shell.execute_reply.started":"2025-11-23T09:58:01.850880Z","shell.execute_reply":"2025-11-23T10:07:20.717203Z"}},"outputs":[{"name":"stdout","text":"Final dataset shape: (42776, 600, 12) (42776,)\nClass distribution: Counter({0: 19028, 1: 10848, 2: 5634, 4: 4650, 3: 2616})\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from sklearn.utils import resample\nimport numpy as np\n\ndef balance_dataset(X, Y):\n    X_bal = []\n    Y_bal = []\n    classes = np.unique(Y)\n\n    # find max count\n    max_count = max([np.sum(Y == c) for c in classes])\n\n    for c in classes:\n        X_cls = X[Y == c]\n        Y_cls = Y[Y == c]\n\n        # oversample minority classes\n        X_res, Y_res = resample(\n            X_cls, Y_cls,\n            replace=True,\n            n_samples=max_count,\n            random_state=42\n        )\n\n        X_bal.append(X_res)\n        Y_bal.append(Y_res)\n\n    Xb = np.concatenate(X_bal)\n    Yb = np.concatenate(Y_bal)\n\n    # shuffle\n    idx = np.random.permutation(len(Yb))\n    return Xb[idx], Yb[idx]\n\n# APPLY HERE\nX, Y = balance_dataset(X, Y)\n\nprint(\"Balanced shape:\", X.shape)\nprint(\"Balanced class distribution:\", Counter(Y))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:08:03.478318Z","iopub.execute_input":"2025-11-23T10:08:03.479029Z","iopub.status.idle":"2025-11-23T10:08:06.393001Z","shell.execute_reply.started":"2025-11-23T10:08:03.479006Z","shell.execute_reply":"2025-11-23T10:08:06.392292Z"}},"outputs":[{"name":"stdout","text":"Balanced shape: (95140, 600, 12)\nBalanced class distribution: Counter({0: 19028, 2: 19028, 1: 19028, 4: 19028, 3: 19028})\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, Y,\n    test_size=0.2,\n    random_state=42,\n    stratify=Y\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:08:25.017187Z","iopub.execute_input":"2025-11-23T10:08:25.017462Z","iopub.status.idle":"2025-11-23T10:08:25.833199Z","shell.execute_reply.started":"2025-11-23T10:08:25.017444Z","shell.execute_reply":"2025-11-23T10:08:25.832592Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import tensorflow as tf\n\ndef focal_loss(gamma=2.0, alpha=0.25):\n    def loss(y_true, y_pred):\n        y_true = tf.cast(y_true, tf.int32)\n        y_true_one_hot = tf.one_hot(y_true, depth=y_pred.shape[-1])\n\n        ce = tf.keras.losses.categorical_crossentropy(y_true_one_hot, y_pred)\n        pt = tf.reduce_sum(y_true_one_hot * y_pred, axis=-1)\n        fl = (1 - pt) ** gamma\n\n        return alpha * fl * ce\n\n    return loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:08:36.614163Z","iopub.execute_input":"2025-11-23T10:08:36.614464Z","iopub.status.idle":"2025-11-23T10:08:36.619280Z","shell.execute_reply.started":"2025-11-23T10:08:36.614442Z","shell.execute_reply":"2025-11-23T10:08:36.618592Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from tensorflow.keras import layers, models\n\ndef build_cnn_lstm(input_shape=(600, 12), num_classes=5):\n\n    inp = layers.Input(shape=input_shape)\n\n    x = layers.Conv1D(32, 7, activation='relu', padding='same')(inp)\n    x = layers.Conv1D(64, 5, activation='relu', padding='same')(x)\n    x = layers.Conv1D(128, 3, activation='relu', padding='same')(x)\n    x = layers.Conv1D(128, 3, activation='relu', padding='same')(x)\n    x = layers.Conv1D(256, 3, activation='relu', padding='same')(x)\n\n    x = layers.LSTM(200, return_sequences=False)(x)\n\n    x = layers.Dense(64, activation='relu')(x)\n    x = layers.Dropout(0.5)(x)\n\n    out = layers.Dense(num_classes, activation='softmax')(x)\n\n    model = models.Model(inp, out)\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:08:46.881111Z","iopub.execute_input":"2025-11-23T10:08:46.881842Z","iopub.status.idle":"2025-11-23T10:08:46.887182Z","shell.execute_reply.started":"2025-11-23T10:08:46.881818Z","shell.execute_reply":"2025-11-23T10:08:46.886400Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"model = build_cnn_lstm()\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-4),\n    loss=focal_loss(gamma=2.0, alpha=0.25),   # ← FOCAL LOSS HERE\n    metrics=[\"accuracy\"]\n)\n\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:08:57.032928Z","iopub.execute_input":"2025-11-23T10:08:57.033395Z","iopub.status.idle":"2025-11-23T10:08:59.298749Z","shell.execute_reply.started":"2025-11-23T10:08:57.033371Z","shell.execute_reply":"2025-11-23T10:08:59.298187Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1763892537.895955      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1763892537.896588      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m2,720\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m10,304\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m49,280\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m98,560\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m365,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m12,864\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,720</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">365,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,864</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m564,357\u001b[0m (2.15 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">564,357</span> (2.15 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m564,357\u001b[0m (2.15 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">564,357</span> (2.15 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"early = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=6,\n    restore_best_weights=True\n)\nreduceLR = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    patience=3,\n    factor=0.5\n)\nhistory = model.fit(\n    X_train, y_train,\n    steps_per_epoch=600,\n    epochs=30,\n    validation_data=(X_val, y_val),\n    callbacks=[early, reduceLR],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:09:17.325934Z","iopub.execute_input":"2025-11-23T10:09:17.326515Z","iopub.status.idle":"2025-11-23T10:54:11.185947Z","shell.execute_reply.started":"2025-11-23T10:09:17.326482Z","shell.execute_reply":"2025-11-23T10:54:11.185119Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1763892565.752271     145 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 140ms/step - accuracy: 0.2403 - loss: 0.2531 - val_accuracy: 0.2992 - val_loss: 0.2367 - learning_rate: 1.0000e-04\nEpoch 2/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 151ms/step - accuracy: 0.3106 - loss: 0.2347 - val_accuracy: 0.3238 - val_loss: 0.2282 - learning_rate: 1.0000e-04\nEpoch 3/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 150ms/step - accuracy: 0.3241 - loss: 0.2293 - val_accuracy: 0.3415 - val_loss: 0.2242 - learning_rate: 1.0000e-04\nEpoch 4/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 150ms/step - accuracy: 0.3334 - loss: 0.2249 - val_accuracy: 0.3478 - val_loss: 0.2232 - learning_rate: 1.0000e-04\nEpoch 5/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 150ms/step - accuracy: 0.3427 - loss: 0.2229 - val_accuracy: 0.3536 - val_loss: 0.2208 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 150ms/step - accuracy: 0.3526 - loss: 0.2197 - val_accuracy: 0.3559 - val_loss: 0.2175 - learning_rate: 1.0000e-04\nEpoch 7/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.3589 - loss: 0.2167 - val_accuracy: 0.3735 - val_loss: 0.2148 - learning_rate: 1.0000e-04\nEpoch 8/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.3634 - loss: 0.2139 - val_accuracy: 0.3712 - val_loss: 0.2116 - learning_rate: 1.0000e-04\nEpoch 9/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.3749 - loss: 0.2103 - val_accuracy: 0.3710 - val_loss: 0.2109 - learning_rate: 1.0000e-04\nEpoch 10/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.3828 - loss: 0.2080 - val_accuracy: 0.3794 - val_loss: 0.2078 - learning_rate: 1.0000e-04\nEpoch 11/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.3943 - loss: 0.2038 - val_accuracy: 0.3974 - val_loss: 0.2025 - learning_rate: 1.0000e-04\nEpoch 12/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.3992 - loss: 0.2010 - val_accuracy: 0.4005 - val_loss: 0.2033 - learning_rate: 1.0000e-04\nEpoch 13/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.4105 - loss: 0.1971 - val_accuracy: 0.4097 - val_loss: 0.1980 - learning_rate: 1.0000e-04\nEpoch 14/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 149ms/step - accuracy: 0.4174 - loss: 0.1933 - val_accuracy: 0.4094 - val_loss: 0.1988 - learning_rate: 1.0000e-04\nEpoch 15/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.4247 - loss: 0.1898 - val_accuracy: 0.4199 - val_loss: 0.1922 - learning_rate: 1.0000e-04\nEpoch 16/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 149ms/step - accuracy: 0.4347 - loss: 0.1864 - val_accuracy: 0.4255 - val_loss: 0.1903 - learning_rate: 1.0000e-04\nEpoch 17/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 149ms/step - accuracy: 0.4489 - loss: 0.1814 - val_accuracy: 0.4338 - val_loss: 0.1864 - learning_rate: 1.0000e-04\nEpoch 18/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 149ms/step - accuracy: 0.4518 - loss: 0.1786 - val_accuracy: 0.4430 - val_loss: 0.1822 - learning_rate: 1.0000e-04\nEpoch 19/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 149ms/step - accuracy: 0.4674 - loss: 0.1719 - val_accuracy: 0.4448 - val_loss: 0.1809 - learning_rate: 1.0000e-04\nEpoch 20/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.4676 - loss: 0.1732 - val_accuracy: 0.4552 - val_loss: 0.1768 - learning_rate: 1.0000e-04\nEpoch 21/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.4791 - loss: 0.1668 - val_accuracy: 0.4656 - val_loss: 0.1729 - learning_rate: 1.0000e-04\nEpoch 22/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 149ms/step - accuracy: 0.4845 - loss: 0.1628 - val_accuracy: 0.4760 - val_loss: 0.1709 - learning_rate: 1.0000e-04\nEpoch 23/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 149ms/step - accuracy: 0.4942 - loss: 0.1596 - val_accuracy: 0.4723 - val_loss: 0.1741 - learning_rate: 1.0000e-04\nEpoch 24/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.4974 - loss: 0.1577 - val_accuracy: 0.4803 - val_loss: 0.1671 - learning_rate: 1.0000e-04\nEpoch 25/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.5048 - loss: 0.1543 - val_accuracy: 0.4837 - val_loss: 0.1674 - learning_rate: 1.0000e-04\nEpoch 26/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.5088 - loss: 0.1531 - val_accuracy: 0.4889 - val_loss: 0.1649 - learning_rate: 1.0000e-04\nEpoch 27/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.5189 - loss: 0.1479 - val_accuracy: 0.4921 - val_loss: 0.1634 - learning_rate: 1.0000e-04\nEpoch 28/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.5261 - loss: 0.1447 - val_accuracy: 0.4964 - val_loss: 0.1634 - learning_rate: 1.0000e-04\nEpoch 29/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 149ms/step - accuracy: 0.5303 - loss: 0.1420 - val_accuracy: 0.4978 - val_loss: 0.1598 - learning_rate: 1.0000e-04\nEpoch 30/30\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 149ms/step - accuracy: 0.5315 - loss: 0.1417 - val_accuracy: 0.5081 - val_loss: 0.1550 - learning_rate: 1.0000e-04\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"early = tf.keras.callbacks.EarlyStopping(\n    patience=8,                  # increased patience\n    restore_best_weights=True\n)\n\nreduceLR = tf.keras.callbacks.ReduceLROnPlateau(\n    factor=0.3,                  # stronger LR reduction\n    patience=4,                  # wait 4 epochs before reducing LR\n    min_lr=1e-7,                 # don't reduce below this\n    verbose=1\n)\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=60,                   # more epochs for better learning\n    batch_size=128,              # faster + smoother gradients\n    shuffle=True,\n    callbacks=[early, reduceLR],\n    verbose=1\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:54:30.045028Z","iopub.execute_input":"2025-11-23T10:54:30.045321Z","iopub.status.idle":"2025-11-23T12:19:41.831890Z","shell.execute_reply.started":"2025-11-23T10:54:30.045299Z","shell.execute_reply":"2025-11-23T12:19:41.831284Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 147ms/step - accuracy: 0.5378 - loss: 0.1373 - val_accuracy: 0.5193 - val_loss: 0.1490 - learning_rate: 1.0000e-04\nEpoch 2/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 144ms/step - accuracy: 0.5540 - loss: 0.1324 - val_accuracy: 0.5272 - val_loss: 0.1470 - learning_rate: 1.0000e-04\nEpoch 3/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.5531 - loss: 0.1310 - val_accuracy: 0.5299 - val_loss: 0.1439 - learning_rate: 1.0000e-04\nEpoch 4/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.5570 - loss: 0.1284 - val_accuracy: 0.5305 - val_loss: 0.1427 - learning_rate: 1.0000e-04\nEpoch 5/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.5572 - loss: 0.1283 - val_accuracy: 0.5327 - val_loss: 0.1417 - learning_rate: 1.0000e-04\nEpoch 6/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.5624 - loss: 0.1246 - val_accuracy: 0.5369 - val_loss: 0.1411 - learning_rate: 1.0000e-04\nEpoch 7/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.5673 - loss: 0.1241 - val_accuracy: 0.5328 - val_loss: 0.1437 - learning_rate: 1.0000e-04\nEpoch 8/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.5686 - loss: 0.1230 - val_accuracy: 0.5327 - val_loss: 0.1459 - learning_rate: 1.0000e-04\nEpoch 9/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.5761 - loss: 0.1199 - val_accuracy: 0.5361 - val_loss: 0.1398 - learning_rate: 1.0000e-04\nEpoch 10/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.5803 - loss: 0.1174 - val_accuracy: 0.5519 - val_loss: 0.1344 - learning_rate: 1.0000e-04\nEpoch 11/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.5793 - loss: 0.1171 - val_accuracy: 0.5557 - val_loss: 0.1354 - learning_rate: 1.0000e-04\nEpoch 12/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.5894 - loss: 0.1123 - val_accuracy: 0.5637 - val_loss: 0.1322 - learning_rate: 1.0000e-04\nEpoch 13/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.5899 - loss: 0.1122 - val_accuracy: 0.5611 - val_loss: 0.1300 - learning_rate: 1.0000e-04\nEpoch 14/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.5920 - loss: 0.1105 - val_accuracy: 0.5687 - val_loss: 0.1282 - learning_rate: 1.0000e-04\nEpoch 15/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6024 - loss: 0.1083 - val_accuracy: 0.5749 - val_loss: 0.1275 - learning_rate: 1.0000e-04\nEpoch 16/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.5960 - loss: 0.1096 - val_accuracy: 0.5705 - val_loss: 0.1299 - learning_rate: 1.0000e-04\nEpoch 17/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6051 - loss: 0.1061 - val_accuracy: 0.5854 - val_loss: 0.1235 - learning_rate: 1.0000e-04\nEpoch 18/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6041 - loss: 0.1063 - val_accuracy: 0.5748 - val_loss: 0.1255 - learning_rate: 1.0000e-04\nEpoch 19/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6112 - loss: 0.1020 - val_accuracy: 0.5921 - val_loss: 0.1208 - learning_rate: 1.0000e-04\nEpoch 20/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6142 - loss: 0.1008 - val_accuracy: 0.5883 - val_loss: 0.1225 - learning_rate: 1.0000e-04\nEpoch 21/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6176 - loss: 0.1018 - val_accuracy: 0.5816 - val_loss: 0.1253 - learning_rate: 1.0000e-04\nEpoch 22/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6140 - loss: 0.1007 - val_accuracy: 0.5527 - val_loss: 0.1377 - learning_rate: 1.0000e-04\nEpoch 23/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6152 - loss: 0.1014 - val_accuracy: 0.6006 - val_loss: 0.1171 - learning_rate: 1.0000e-04\nEpoch 24/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6325 - loss: 0.0932 - val_accuracy: 0.5970 - val_loss: 0.1169 - learning_rate: 1.0000e-04\nEpoch 25/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6258 - loss: 0.0974 - val_accuracy: 0.6003 - val_loss: 0.1184 - learning_rate: 1.0000e-04\nEpoch 26/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6323 - loss: 0.0950 - val_accuracy: 0.6003 - val_loss: 0.1190 - learning_rate: 1.0000e-04\nEpoch 27/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6411 - loss: 0.0916 - val_accuracy: 0.5949 - val_loss: 0.1207 - learning_rate: 1.0000e-04\nEpoch 28/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6330 - loss: 0.0929 - val_accuracy: 0.6161 - val_loss: 0.1129 - learning_rate: 1.0000e-04\nEpoch 29/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6378 - loss: 0.0913 - val_accuracy: 0.6025 - val_loss: 0.1195 - learning_rate: 1.0000e-04\nEpoch 30/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6435 - loss: 0.0902 - val_accuracy: 0.6050 - val_loss: 0.1147 - learning_rate: 1.0000e-04\nEpoch 31/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6488 - loss: 0.0867 - val_accuracy: 0.6103 - val_loss: 0.1167 - learning_rate: 1.0000e-04\nEpoch 32/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.6459 - loss: 0.0887\nEpoch 32: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6459 - loss: 0.0887 - val_accuracy: 0.6047 - val_loss: 0.1177 - learning_rate: 1.0000e-04\nEpoch 33/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6768 - loss: 0.0755 - val_accuracy: 0.6588 - val_loss: 0.0987 - learning_rate: 3.0000e-05\nEpoch 34/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6994 - loss: 0.0672 - val_accuracy: 0.6577 - val_loss: 0.0993 - learning_rate: 3.0000e-05\nEpoch 35/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.6998 - loss: 0.0671 - val_accuracy: 0.6632 - val_loss: 0.0994 - learning_rate: 3.0000e-05\nEpoch 36/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7025 - loss: 0.0663 - val_accuracy: 0.6703 - val_loss: 0.0979 - learning_rate: 3.0000e-05\nEpoch 37/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7051 - loss: 0.0655 - val_accuracy: 0.6464 - val_loss: 0.1065 - learning_rate: 3.0000e-05\nEpoch 38/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7090 - loss: 0.0645 - val_accuracy: 0.6738 - val_loss: 0.0981 - learning_rate: 3.0000e-05\nEpoch 39/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7067 - loss: 0.0646 - val_accuracy: 0.6779 - val_loss: 0.0970 - learning_rate: 3.0000e-05\nEpoch 40/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7188 - loss: 0.0612 - val_accuracy: 0.6767 - val_loss: 0.0968 - learning_rate: 3.0000e-05\nEpoch 41/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7210 - loss: 0.0609 - val_accuracy: 0.6798 - val_loss: 0.0966 - learning_rate: 3.0000e-05\nEpoch 42/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7240 - loss: 0.0599 - val_accuracy: 0.6772 - val_loss: 0.1002 - learning_rate: 3.0000e-05\nEpoch 43/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7189 - loss: 0.0608 - val_accuracy: 0.6794 - val_loss: 0.1003 - learning_rate: 3.0000e-05\nEpoch 44/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 144ms/step - accuracy: 0.7244 - loss: 0.0597 - val_accuracy: 0.6906 - val_loss: 0.0937 - learning_rate: 3.0000e-05\nEpoch 45/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7270 - loss: 0.0593 - val_accuracy: 0.6901 - val_loss: 0.0957 - learning_rate: 3.0000e-05\nEpoch 46/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7284 - loss: 0.0580 - val_accuracy: 0.6600 - val_loss: 0.1063 - learning_rate: 3.0000e-05\nEpoch 47/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 144ms/step - accuracy: 0.7272 - loss: 0.0590 - val_accuracy: 0.6970 - val_loss: 0.0936 - learning_rate: 3.0000e-05\nEpoch 48/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7401 - loss: 0.0556 - val_accuracy: 0.6908 - val_loss: 0.0970 - learning_rate: 3.0000e-05\nEpoch 49/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7380 - loss: 0.0556 - val_accuracy: 0.6996 - val_loss: 0.0952 - learning_rate: 3.0000e-05\nEpoch 50/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7368 - loss: 0.0556 - val_accuracy: 0.6845 - val_loss: 0.0981 - learning_rate: 3.0000e-05\nEpoch 51/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7401 - loss: 0.0552\nEpoch 51: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7401 - loss: 0.0552 - val_accuracy: 0.6988 - val_loss: 0.0948 - learning_rate: 3.0000e-05\nEpoch 52/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7581 - loss: 0.0496 - val_accuracy: 0.7189 - val_loss: 0.0919 - learning_rate: 9.0000e-06\nEpoch 53/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7658 - loss: 0.0479 - val_accuracy: 0.7200 - val_loss: 0.0914 - learning_rate: 9.0000e-06\nEpoch 54/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7668 - loss: 0.0475 - val_accuracy: 0.7134 - val_loss: 0.0938 - learning_rate: 9.0000e-06\nEpoch 55/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7691 - loss: 0.0461 - val_accuracy: 0.7229 - val_loss: 0.0921 - learning_rate: 9.0000e-06\nEpoch 56/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7708 - loss: 0.0462 - val_accuracy: 0.7220 - val_loss: 0.0926 - learning_rate: 9.0000e-06\nEpoch 57/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7736 - loss: 0.0455\nEpoch 57: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7736 - loss: 0.0455 - val_accuracy: 0.7277 - val_loss: 0.0930 - learning_rate: 9.0000e-06\nEpoch 58/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7766 - loss: 0.0446 - val_accuracy: 0.7320 - val_loss: 0.0927 - learning_rate: 2.7000e-06\nEpoch 59/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7813 - loss: 0.0439 - val_accuracy: 0.7334 - val_loss: 0.0924 - learning_rate: 2.7000e-06\nEpoch 60/60\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7839 - loss: 0.0434 - val_accuracy: 0.7353 - val_loss: 0.0930 - learning_rate: 2.7000e-06\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    \"best_model.h5\",\n    monitor=\"val_loss\",\n    save_best_only=True,\n    mode=\"min\",\n    verbose=1\n)\n\nearly = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=12,                 # more patience for long training\n    restore_best_weights=True\n)\n\nreduceLR = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.3,                  # strong LR drop\n    patience=5,                  # wait 5 epochs\n    min_lr=1e-7,                 # don't reduce below this\n    verbose=1\n)\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=100,                  # continue to 100 total\n    batch_size=128,\n    shuffle=True,\n    callbacks=[early, reduceLR, checkpoint],\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T12:22:08.971498Z","iopub.execute_input":"2025-11-23T12:22:08.972247Z","iopub.status.idle":"2025-11-23T12:40:43.481536Z","shell.execute_reply.started":"2025-11-23T12:22:08.972203Z","shell.execute_reply":"2025-11-23T12:40:43.480696Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7697 - loss: 0.0463\nEpoch 1: val_loss improved from inf to 0.09130, saving model to best_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 147ms/step - accuracy: 0.7697 - loss: 0.0463 - val_accuracy: 0.7251 - val_loss: 0.0913 - learning_rate: 2.7000e-06\nEpoch 2/100\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7720 - loss: 0.0455\nEpoch 2: val_loss did not improve from 0.09130\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7720 - loss: 0.0455 - val_accuracy: 0.7248 - val_loss: 0.0917 - learning_rate: 2.7000e-06\nEpoch 3/100\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7736 - loss: 0.0454\nEpoch 3: val_loss did not improve from 0.09130\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7736 - loss: 0.0454 - val_accuracy: 0.7253 - val_loss: 0.0920 - learning_rate: 2.7000e-06\nEpoch 4/100\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7756 - loss: 0.0451\nEpoch 4: val_loss did not improve from 0.09130\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7756 - loss: 0.0451 - val_accuracy: 0.7280 - val_loss: 0.0920 - learning_rate: 2.7000e-06\nEpoch 5/100\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7766 - loss: 0.0444\nEpoch 5: val_loss did not improve from 0.09130\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7766 - loss: 0.0444 - val_accuracy: 0.7287 - val_loss: 0.0922 - learning_rate: 2.7000e-06\nEpoch 6/100\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7778 - loss: 0.0444\nEpoch 6: ReduceLROnPlateau reducing learning rate to 8.099999604382901e-07.\n\nEpoch 6: val_loss did not improve from 0.09130\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7778 - loss: 0.0444 - val_accuracy: 0.7319 - val_loss: 0.0925 - learning_rate: 2.7000e-06\nEpoch 7/100\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7818 - loss: 0.0440\nEpoch 7: val_loss did not improve from 0.09130\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7818 - loss: 0.0440 - val_accuracy: 0.7313 - val_loss: 0.0927 - learning_rate: 8.1000e-07\nEpoch 8/100\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7805 - loss: 0.0440\nEpoch 8: val_loss did not improve from 0.09130\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7805 - loss: 0.0440 - val_accuracy: 0.7310 - val_loss: 0.0928 - learning_rate: 8.1000e-07\nEpoch 9/100\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7819 - loss: 0.0440\nEpoch 9: val_loss did not improve from 0.09130\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7818 - loss: 0.0440 - val_accuracy: 0.7327 - val_loss: 0.0926 - learning_rate: 8.1000e-07\nEpoch 10/100\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7812 - loss: 0.0437\nEpoch 10: val_loss did not improve from 0.09130\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7812 - loss: 0.0437 - val_accuracy: 0.7329 - val_loss: 0.0927 - learning_rate: 8.1000e-07\nEpoch 11/100\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7828 - loss: 0.0436\nEpoch 11: ReduceLROnPlateau reducing learning rate to 2.4299998813148704e-07.\n\nEpoch 11: val_loss did not improve from 0.09130\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7828 - loss: 0.0436 - val_accuracy: 0.7323 - val_loss: 0.0928 - learning_rate: 8.1000e-07\nEpoch 12/100\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7828 - loss: 0.0445\nEpoch 12: val_loss did not improve from 0.09130\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7828 - loss: 0.0445 - val_accuracy: 0.7332 - val_loss: 0.0928 - learning_rate: 2.4300e-07\nEpoch 13/100\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7864 - loss: 0.0429\nEpoch 13: val_loss did not improve from 0.09130\n\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 143ms/step - accuracy: 0.7864 - loss: 0.0429 - val_accuracy: 0.7331 - val_loss: 0.0928 - learning_rate: 2.4300e-07\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"pred = np.argmax(model.predict(X_val), axis=1)\n\nprint(classification_report(y_val, pred))\nprint(confusion_matrix(y_val, pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T12:43:49.454482Z","iopub.execute_input":"2025-11-23T12:43:49.455012Z","iopub.status.idle":"2025-11-23T12:44:02.919285Z","shell.execute_reply.started":"2025-11-23T12:43:49.454988Z","shell.execute_reply":"2025-11-23T12:44:02.918661Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step\n              precision    recall  f1-score   support\n\n           0       0.67      0.47      0.55      3806\n           1       0.67      0.40      0.50      3805\n           2       0.63      0.83      0.71      3806\n           3       0.91      0.99      0.95      3806\n           4       0.73      0.93      0.82      3805\n\n    accuracy                           0.73     19028\n   macro avg       0.72      0.73      0.71     19028\nweighted avg       0.72      0.73      0.71     19028\n\n[[1800  431  990  281  304]\n [ 419 1508  866   55  957]\n [ 371  193 3156   23   63]\n [  15    4    0 3782    5]\n [  95  110   33   15 3552]]\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"###########################################################\n#  HYBRID PTB-XL PIPELINE (TIME-DOMAIN + FFT)\n#  FULLY CORRECTED — SINGLE RUNNABLE CELL FOR KAGGLE\n###########################################################\n\nimport os\nimport numpy as np\nimport wfdb\nfrom scipy import signal\nfrom scipy.fft import rfft\nfrom sklearn.utils import class_weight\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks, regularizers\n\nprint(\"Starting Hybrid PTB-XL Pipeline...\")\n\n###########################################################\n# 1. CONFIG\n###########################################################\n\nDATA_DIR = \"/kaggle/input/dl-dataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3\"\n\nTARGET_FS = 250\nWINDOW_SEC = 5\nWINDOW_SAMPLES = TARGET_FS * WINDOW_SEC\nOVERLAP = 0.5\n\n\n###########################################################\n# 2. FILTERS + PREPROCESSING\n###########################################################\n\ndef resample(sig, orig_fs):\n    if orig_fs == TARGET_FS:\n        return sig\n    new_len = int(len(sig) * TARGET_FS / orig_fs)\n    return signal.resample(sig, new_len)\n\ndef highpass(sig):\n    b,a = signal.butter(2, 0.5/(TARGET_FS/2), 'high')\n    return signal.filtfilt(b,a,sig)\n\ndef bandpass(sig):\n    b,a = signal.butter(4, [0.5/(TARGET_FS/2), 40/(TARGET_FS/2)], 'band')\n    return signal.filtfilt(b,a,sig)\n\ndef notch(sig, f0=50):\n    w0 = f0/(TARGET_FS/2)\n    b,a = signal.iirnotch(w0, 30)\n    return signal.filtfilt(b,a,sig)\n\ndef normalize(sig):\n    return (sig - np.mean(sig)) / (np.std(sig) + 1e-8)\n\n\n###########################################################\n# 3. LABEL EXTRACTION\n###########################################################\n\nimport pandas as pd\n\nmeta = pd.read_csv(os.path.join(DATA_DIR, \"ptbxl_database.csv\"))\nscp_df = pd.read_csv(os.path.join(DATA_DIR, \"scp_statements.csv\"), index_col=0)\n\nscp_df = scp_df[scp_df['diagnostic'] == 1]\n\nSUPERCLASS_MAP = {\n    'NORM': 0,\n    'MI':   1,\n    'STTC': 2,\n    'HYP':  3,\n    'CD':   4\n}\n\ndef get_superclass(code):\n    try:\n        diag = scp_df.loc[code, 'diagnostic_class']\n        return SUPERCLASS_MAP.get(diag, None)\n    except:\n        return None\n\ndef extract_label(row):\n    try:\n        d = eval(row['scp_codes'])\n    except:\n        return None\n    labels = []\n    for k in d.keys():\n        cls = get_superclass(k)\n        if cls is not None:\n            labels.append(cls)\n    return labels[0] if len(labels) else None\n\n\n###########################################################\n# 4. HYBRID WINDOW EXTRACTOR (RAW + FFT)\n###########################################################\n\ndef extract_windows_hybrid(row):\n\n    file_path = os.path.join(DATA_DIR, row['filename_hr']).replace(\".dat\", \"\")\n\n    try:\n        rec = wfdb.rdrecord(file_path)\n    except:\n        return None, None, None\n\n    sig = rec.p_signal          # (T, 12)\n    fs = rec.fs\n\n    if fs != TARGET_FS:\n        sig = np.array([resample(sig[:,i], fs) for i in range(sig.shape[1])]).T\n\n    for i in range(12):\n        sig[:, i] = highpass(sig[:, i])\n        sig[:, i] = bandpass(sig[:, i])\n        sig[:, i] = notch(sig[:, i])\n        sig[:, i] = normalize(sig[:, i])\n\n    hop = int(WINDOW_SAMPLES*(1-OVERLAP))\n    raw_windows, fft_windows = [], []\n\n    for start in range(0, len(sig)-WINDOW_SAMPLES, hop):\n\n        w = sig[start:start+WINDOW_SAMPLES]           # (1250,12)\n        raw_windows.append(w.astype(np.float32))\n\n        fft_win = []\n        for lead in range(12):\n            f = np.abs(rfft(w[:, lead]))[:600]\n            fft_win.append(f)\n        fft_win = np.array(fft_win).T                 # (600,12)\n        fft_windows.append(fft_win.astype(np.float32))\n\n    return raw_windows, fft_windows, extract_label(row)\n\n\n###########################################################\n# 5. BUILD FULL DATASET\n###########################################################\n\nX_time = []\nX_fft = []\nY = []\n\nprint(\"Extracting windows...\")\nfor _, row in meta.iterrows():\n\n    raw_wins, fft_wins, lab = extract_windows_hybrid(row)\n    if raw_wins is None or lab is None:\n        continue\n\n    for r, f in zip(raw_wins, fft_wins):\n        X_time.append(r)\n        X_fft.append(f)\n        Y.append(lab)\n\nX_time = np.array(X_time)\nX_fft = np.array(X_fft)\nY = np.array(Y)\n\nprint(\"Shapes:\")\nprint(\"X_time:\", X_time.shape)\nprint(\"X_fft:\", X_fft.shape)\nprint(\"Y:\", Y.shape)\n\n\n###########################################################\n# 6. SPLIT TRAIN / VAL\n###########################################################\n\nX_time_train, X_time_val, X_fft_train, X_fft_val, y_train, y_val = train_test_split(\n    X_time, X_fft, Y, test_size=0.2, stratify=Y, random_state=42\n)\n\n\n###########################################################\n# 7. FOCAL LOSS\n###########################################################\n\ndef focal_loss(gamma=2.0, alpha=0.25):\n    def loss(y_true, y_pred):\n        y_true = tf.cast(y_true, tf.int32)\n        y_true = tf.one_hot(y_true, depth=5)\n        ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n        pt = tf.exp(-ce)\n        focal = alpha * (1 - pt) ** gamma * ce\n        return tf.reduce_mean(focal)\n    return loss\n\n\n###########################################################\n# 8. HYBRID MODEL (CNN + BiLSTM + FFT)\n###########################################################\n\n# TIME BRANCH\ninp_time = layers.Input(shape=(1250,12))\nx = layers.Conv1D(64,7,padding='same',activation='relu')(inp_time)\nx = layers.MaxPooling1D(2)(x)\nx = layers.Conv1D(128,5,padding='same',activation='relu')(x)\nx = layers.MaxPooling1D(2)(x)\nx = layers.Conv1D(256,5,padding='same',activation='relu')(x)\nx = layers.MaxPooling1D(2)(x)\nx = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\nx = layers.Bidirectional(layers.LSTM(64))(x)\n\n# FFT BRANCH\ninp_fft = layers.Input(shape=(600,12))\ny = layers.Conv1D(64,7,padding='same',activation='relu')(inp_fft)\ny = layers.MaxPooling1D(2)(y)\ny = layers.Conv1D(128,5,padding='same',activation='relu')(y)\ny = layers.MaxPooling1D(2)(y)\ny = layers.Flatten()(y)\ny = layers.Dense(256, activation='relu')(y)\ny = layers.Dropout(0.3)(y)\n\n# MERGE\ncombined = layers.concatenate([x, y])\nz = layers.BatchNormalization()(combined)\nz = layers.Dense(256, activation='relu')(z)\nz = layers.Dropout(0.3)(z)\nz = layers.Dense(128, activation='relu')(z)\nz = layers.Dropout(0.2)(z)\nout = layers.Dense(5, activation='softmax')(z)\n\nmodel = models.Model([inp_time, inp_fft], out)\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-4),\n    loss=focal_loss(),\n    metrics=['accuracy']\n)\n\nmodel.summary()\n\n\n###########################################################\n# 9. CLASS WEIGHTS\n###########################################################\n\ncw = class_weight.compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(Y),\n    y=Y\n)\ncw = dict(enumerate(cw))\n\n\n###########################################################\n# 10. TRAIN MODEL\n###########################################################\n\ncheckpoint = callbacks.ModelCheckpoint(\n    \"best_model.keras\",\n    monitor=\"val_loss\",\n    save_best_only=True,\n    mode=\"min\"\n)\n\nearly = callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=12,\n    restore_best_weights=True\n)\n\nreduceLR = callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.3,\n    patience=5,\n    min_lr=1e-7,\n    verbose=1\n)\n\nhistory = model.fit(\n    [X_time_train, X_fft_train], y_train,\n    validation_data=([X_time_val, X_fft_val], y_val),\n    epochs=100,\n    batch_size=128,\n    callbacks=[checkpoint, early, reduceLR],\n    class_weight=cw,\n    verbose=1\n)\n\nprint(\"Training Completed.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T12:59:33.276835Z","iopub.execute_input":"2025-11-23T12:59:33.277136Z","iopub.status.idle":"2025-11-23T13:27:32.386849Z","shell.execute_reply.started":"2025-11-23T12:59:33.277114Z","shell.execute_reply":"2025-11-23T13:27:32.386166Z"}},"outputs":[{"name":"stdout","text":"Starting Hybrid PTB-XL Pipeline...\nExtracting windows...\nShapes:\nX_time: (42776, 1250, 12)\nX_fft: (42776, 600, 12)\nY: (42776,)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m12\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m5,440\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m12\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m5,440\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m41,088\u001b[0m │ max_pooling1d_5[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m41,088\u001b[0m │ max_pooling1d_8[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │    \u001b[38;5;34m164,096\u001b[0m │ max_pooling1d_6[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19200\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_9[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m164,352\u001b[0m │ max_pooling1d_7[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │  \u001b[38;5;34m4,915,456\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m98,816\u001b[0m │ bidirectional_2[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_3[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m1,536\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m98,560\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m645\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,440</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,440</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ max_pooling1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ max_pooling1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">164,096</span> │ max_pooling1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19200</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │ max_pooling1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,915,456</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,569,413\u001b[0m (21.25 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,569,413</span> (21.25 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,568,645\u001b[0m (21.24 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,568,645</span> (21.24 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 106ms/step - accuracy: 0.4715 - loss: 0.2159 - val_accuracy: 0.6440 - val_loss: 0.1502 - learning_rate: 1.0000e-04\nEpoch 2/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 96ms/step - accuracy: 0.6540 - loss: 0.1298 - val_accuracy: 0.7004 - val_loss: 0.1051 - learning_rate: 1.0000e-04\nEpoch 3/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 92ms/step - accuracy: 0.6976 - loss: 0.1101 - val_accuracy: 0.7202 - val_loss: 0.0997 - learning_rate: 1.0000e-04\nEpoch 4/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 92ms/step - accuracy: 0.7183 - loss: 0.1010 - val_accuracy: 0.7278 - val_loss: 0.0982 - learning_rate: 1.0000e-04\nEpoch 5/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 92ms/step - accuracy: 0.7315 - loss: 0.0920 - val_accuracy: 0.7035 - val_loss: 0.1065 - learning_rate: 1.0000e-04\nEpoch 6/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 92ms/step - accuracy: 0.7425 - loss: 0.0871 - val_accuracy: 0.7208 - val_loss: 0.1086 - learning_rate: 1.0000e-04\nEpoch 7/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.7441 - loss: 0.0841 - val_accuracy: 0.7222 - val_loss: 0.1049 - learning_rate: 1.0000e-04\nEpoch 8/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.7537 - loss: 0.0804 - val_accuracy: 0.5249 - val_loss: 0.1691 - learning_rate: 1.0000e-04\nEpoch 9/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7514 - loss: 0.0780\nEpoch 9: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 92ms/step - accuracy: 0.7514 - loss: 0.0780 - val_accuracy: 0.6958 - val_loss: 0.1136 - learning_rate: 1.0000e-04\nEpoch 10/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 93ms/step - accuracy: 0.7720 - loss: 0.0697 - val_accuracy: 0.7661 - val_loss: 0.0802 - learning_rate: 3.0000e-05\nEpoch 11/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 92ms/step - accuracy: 0.7767 - loss: 0.0675 - val_accuracy: 0.7738 - val_loss: 0.0744 - learning_rate: 3.0000e-05\nEpoch 12/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.7785 - loss: 0.0671 - val_accuracy: 0.7336 - val_loss: 0.0964 - learning_rate: 3.0000e-05\nEpoch 13/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.7796 - loss: 0.0635 - val_accuracy: 0.7602 - val_loss: 0.0810 - learning_rate: 3.0000e-05\nEpoch 14/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.7859 - loss: 0.0620 - val_accuracy: 0.7572 - val_loss: 0.0830 - learning_rate: 3.0000e-05\nEpoch 15/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.7927 - loss: 0.0597 - val_accuracy: 0.7579 - val_loss: 0.0824 - learning_rate: 3.0000e-05\nEpoch 16/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7936 - loss: 0.0571\nEpoch 16: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 91ms/step - accuracy: 0.7936 - loss: 0.0571 - val_accuracy: 0.7384 - val_loss: 0.0838 - learning_rate: 3.0000e-05\nEpoch 17/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.7953 - loss: 0.0552 - val_accuracy: 0.7682 - val_loss: 0.0758 - learning_rate: 9.0000e-06\nEpoch 18/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 93ms/step - accuracy: 0.7981 - loss: 0.0529 - val_accuracy: 0.7727 - val_loss: 0.0734 - learning_rate: 9.0000e-06\nEpoch 19/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.8005 - loss: 0.0533 - val_accuracy: 0.7508 - val_loss: 0.0792 - learning_rate: 9.0000e-06\nEpoch 20/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.8038 - loss: 0.0514 - val_accuracy: 0.7719 - val_loss: 0.0735 - learning_rate: 9.0000e-06\nEpoch 21/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.8081 - loss: 0.0501 - val_accuracy: 0.7688 - val_loss: 0.0769 - learning_rate: 9.0000e-06\nEpoch 22/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.8094 - loss: 0.0502 - val_accuracy: 0.7429 - val_loss: 0.0816 - learning_rate: 9.0000e-06\nEpoch 23/100\n\u001b[1m267/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8044 - loss: 0.0497\nEpoch 23: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.8044 - loss: 0.0497 - val_accuracy: 0.7734 - val_loss: 0.0743 - learning_rate: 9.0000e-06\nEpoch 24/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 92ms/step - accuracy: 0.8098 - loss: 0.0487 - val_accuracy: 0.7744 - val_loss: 0.0721 - learning_rate: 2.7000e-06\nEpoch 25/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.8131 - loss: 0.0470 - val_accuracy: 0.7772 - val_loss: 0.0733 - learning_rate: 2.7000e-06\nEpoch 26/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.8071 - loss: 0.0480 - val_accuracy: 0.7595 - val_loss: 0.0771 - learning_rate: 2.7000e-06\nEpoch 27/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.8089 - loss: 0.0480 - val_accuracy: 0.7777 - val_loss: 0.0726 - learning_rate: 2.7000e-06\nEpoch 28/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.8167 - loss: 0.0464 - val_accuracy: 0.7747 - val_loss: 0.0724 - learning_rate: 2.7000e-06\nEpoch 29/100\n\u001b[1m267/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8108 - loss: 0.0477\nEpoch 29: ReduceLROnPlateau reducing learning rate to 8.099999604382901e-07.\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.8108 - loss: 0.0477 - val_accuracy: 0.7772 - val_loss: 0.0741 - learning_rate: 2.7000e-06\nEpoch 30/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.8102 - loss: 0.0480 - val_accuracy: 0.7776 - val_loss: 0.0721 - learning_rate: 8.1000e-07\nEpoch 31/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.8119 - loss: 0.0466 - val_accuracy: 0.7740 - val_loss: 0.0728 - learning_rate: 8.1000e-07\nEpoch 32/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 90ms/step - accuracy: 0.8097 - loss: 0.0479 - val_accuracy: 0.7776 - val_loss: 0.0721 - learning_rate: 8.1000e-07\nEpoch 33/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 90ms/step - accuracy: 0.8149 - loss: 0.0468 - val_accuracy: 0.7749 - val_loss: 0.0721 - learning_rate: 8.1000e-07\nEpoch 34/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8114 - loss: 0.0467\nEpoch 34: ReduceLROnPlateau reducing learning rate to 2.4299998813148704e-07.\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 90ms/step - accuracy: 0.8114 - loss: 0.0467 - val_accuracy: 0.7741 - val_loss: 0.0721 - learning_rate: 8.1000e-07\nEpoch 35/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.8156 - loss: 0.0459 - val_accuracy: 0.7759 - val_loss: 0.0721 - learning_rate: 2.4300e-07\nEpoch 36/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.8124 - loss: 0.0461 - val_accuracy: 0.7775 - val_loss: 0.0721 - learning_rate: 2.4300e-07\nEpoch 37/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 91ms/step - accuracy: 0.8169 - loss: 0.0460 - val_accuracy: 0.7772 - val_loss: 0.0720 - learning_rate: 2.4300e-07\nEpoch 38/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.8164 - loss: 0.0457 - val_accuracy: 0.7781 - val_loss: 0.0720 - learning_rate: 2.4300e-07\nEpoch 39/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.8070 - loss: 0.0464 - val_accuracy: 0.7777 - val_loss: 0.0721 - learning_rate: 2.4300e-07\nEpoch 40/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.8123 - loss: 0.0465 - val_accuracy: 0.7770 - val_loss: 0.0721 - learning_rate: 2.4300e-07\nEpoch 41/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.8142 - loss: 0.0458 - val_accuracy: 0.7783 - val_loss: 0.0721 - learning_rate: 2.4300e-07\nEpoch 42/100\n\u001b[1m267/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8167 - loss: 0.0458\nEpoch 42: ReduceLROnPlateau reducing learning rate to 1e-07.\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.8167 - loss: 0.0458 - val_accuracy: 0.7762 - val_loss: 0.0721 - learning_rate: 2.4300e-07\nEpoch 43/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.8168 - loss: 0.0462 - val_accuracy: 0.7762 - val_loss: 0.0721 - learning_rate: 1.0000e-07\nEpoch 44/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.8137 - loss: 0.0466 - val_accuracy: 0.7768 - val_loss: 0.0721 - learning_rate: 1.0000e-07\nEpoch 45/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.8154 - loss: 0.0452 - val_accuracy: 0.7762 - val_loss: 0.0721 - learning_rate: 1.0000e-07\nEpoch 46/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.8115 - loss: 0.0466 - val_accuracy: 0.7763 - val_loss: 0.0721 - learning_rate: 1.0000e-07\nEpoch 47/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.8139 - loss: 0.0463 - val_accuracy: 0.7766 - val_loss: 0.0721 - learning_rate: 1.0000e-07\nEpoch 48/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 89ms/step - accuracy: 0.8168 - loss: 0.0465 - val_accuracy: 0.7771 - val_loss: 0.0721 - learning_rate: 1.0000e-07\nEpoch 49/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 90ms/step - accuracy: 0.8161 - loss: 0.0457 - val_accuracy: 0.7770 - val_loss: 0.0721 - learning_rate: 1.0000e-07\nTraining Completed.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# -----------------------------\n# 1) Get predictions\n# -----------------------------\ny_pred = model.predict([X_time_val, X_fft_val])\ny_pred = np.argmax(y_pred, axis=1)\n\n# -----------------------------\n# 2) Classification report\n# -----------------------------\nprint(classification_report(y_val, y_pred))\n\n# -----------------------------\n# 3) Confusion Matrix\n# -----------------------------\ncm = confusion_matrix(y_val, y_pred)\n\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['NORM','MI','STTC','HYP','CD'],\n            yticklabels=['NORM','MI','STTC','HYP','CD'])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:30:33.939456Z","iopub.execute_input":"2025-11-23T13:30:33.946836Z","iopub.status.idle":"2025-11-23T13:30:41.829794Z","shell.execute_reply.started":"2025-11-23T13:30:33.946807Z","shell.execute_reply":"2025-11-23T13:30:41.829244Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n              precision    recall  f1-score   support\n\n           0       0.85      0.90      0.87      3806\n           1       0.77      0.80      0.78      2170\n           2       0.62      0.61      0.62      1127\n           3       0.55      0.34      0.42       523\n           4       0.73      0.68      0.71       930\n\n    accuracy                           0.78      8556\n   macro avg       0.71      0.66      0.68      8556\nweighted avg       0.77      0.78      0.77      8556\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\n\n# -----------------------------\n# Inputs\n# -----------------------------\ninp_time = Input(shape=(1250, 12))\ninp_fft  = Input(shape=(600, 12))\n\n# -----------------------------\n# Time-domain branch (CNN + BiLSTM)\n# -----------------------------\nx = Conv1D(64, 5, activation='relu', padding='same')(inp_time)\nx = BatchNormalization()(x)\nx = MaxPooling1D(2)(x)\n\nx = Conv1D(128, 5, activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPooling1D(2)(x)\n\nx = Bidirectional(LSTM(128, return_sequences=True))(x)\n\n# Attention\nattention = Dense(1, activation='tanh')(x)\nattention = Flatten()(attention)\nattention = Activation('softmax')(attention)\nattention = RepeatVector(256)(attention)\nattention = Permute([2,1])(attention)\n\nx = Multiply()([x, attention])\nx = GlobalAveragePooling1D()(x)\n\n# -----------------------------\n# Frequency-domain branch (FFT CNN)\n# -----------------------------\nf = Conv1D(64, 5, activation='relu', padding='same')(inp_fft)\nf = BatchNormalization()(f)\nf = MaxPooling1D(2)(f)\n\nf = Conv1D(128, 5, activation='relu', padding='same')(f)\nf = BatchNormalization()(f)\nf = MaxPooling1D(2)(f)\n\nf = GlobalAveragePooling1D()(f)\n\n# -----------------------------\n# Fusion\n# -----------------------------\ncombined = Concatenate()([x, f])\n\ncombined = Dense(256, activation='relu')(combined)\ncombined = Dropout(0.4)(combined)\n\ncombined = Dense(128, activation='relu')(combined)\ncombined = Dropout(0.3)(combined)\n\nout = Dense(5, activation='softmax')(combined)\n\nmodel2 = Model(inputs=[inp_time, inp_fft], outputs=out)\n\nmodel2.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-4),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel2.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:35:23.278507Z","iopub.execute_input":"2025-11-23T13:35:23.279546Z","iopub.status.idle":"2025-11-23T13:35:23.765304Z","shell.execute_reply.started":"2025-11-23T13:35:23.279519Z","shell.execute_reply":"2025-11-23T13:35:23.764763Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m12\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m3,904\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ conv1d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_16 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m41,088\u001b[0m │ max_pooling1d_10… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv1d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │    \u001b[38;5;34m263,168\u001b[0m │ max_pooling1d_11… │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m12\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │        \u001b[38;5;34m257\u001b[0m │ bidirectional_4[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_17 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m3,904\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ repeat_vector       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m312\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_18 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m41,088\u001b[0m │ max_pooling1d_12… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ permute (\u001b[38;5;33mPermute\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ repeat_vector[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv1d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bidirectional_4[\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ permute[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_13… │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m98,560\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m645\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,904</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ max_pooling1d_10… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ max_pooling1d_11… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ bidirectional_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,904</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ repeat_vector       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ max_pooling1d_12… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ permute (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ permute[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_13… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m487,046\u001b[0m (1.86 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">487,046</span> (1.86 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m486,278\u001b[0m (1.86 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">486,278</span> (1.86 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n</pre>\n"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"early = tf.keras.callbacks.EarlyStopping(\n    patience=12,\n    restore_best_weights=True\n)\n\nreduceLR = tf.keras.callbacks.ReduceLROnPlateau(\n    patience=4,\n    factor=0.3,\n    min_lr=1e-7\n)\n\nhistory = model2.fit(\n    [X_time_train, X_fft_train], y_train,\n    validation_data=([X_time_val, X_fft_val], y_val),\n    epochs=100,\n    batch_size=128,\n    callbacks=[early, reduceLR]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:35:43.790309Z","iopub.execute_input":"2025-11-23T13:35:43.790582Z","iopub.status.idle":"2025-11-23T13:57:04.922095Z","shell.execute_reply.started":"2025-11-23T13:35:43.790562Z","shell.execute_reply":"2025-11-23T13:57:04.921296Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 121ms/step - accuracy: 0.4681 - loss: 1.3853 - val_accuracy: 0.5926 - val_loss: 1.1562 - learning_rate: 1.0000e-04\nEpoch 2/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 110ms/step - accuracy: 0.5912 - loss: 1.1149 - val_accuracy: 0.6463 - val_loss: 0.9902 - learning_rate: 1.0000e-04\nEpoch 3/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 108ms/step - accuracy: 0.6387 - loss: 1.0147 - val_accuracy: 0.6657 - val_loss: 0.9349 - learning_rate: 1.0000e-04\nEpoch 4/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.6550 - loss: 0.9571 - val_accuracy: 0.6704 - val_loss: 0.9148 - learning_rate: 1.0000e-04\nEpoch 5/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.6654 - loss: 0.9342 - val_accuracy: 0.6732 - val_loss: 0.9002 - learning_rate: 1.0000e-04\nEpoch 6/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.6784 - loss: 0.9003 - val_accuracy: 0.6793 - val_loss: 0.8723 - learning_rate: 1.0000e-04\nEpoch 7/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.6863 - loss: 0.8763 - val_accuracy: 0.6878 - val_loss: 0.8571 - learning_rate: 1.0000e-04\nEpoch 8/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.6950 - loss: 0.8538 - val_accuracy: 0.7040 - val_loss: 0.8223 - learning_rate: 1.0000e-04\nEpoch 9/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7065 - loss: 0.8271 - val_accuracy: 0.7112 - val_loss: 0.8093 - learning_rate: 1.0000e-04\nEpoch 10/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7104 - loss: 0.8171 - val_accuracy: 0.7223 - val_loss: 0.7802 - learning_rate: 1.0000e-04\nEpoch 11/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7240 - loss: 0.7852 - val_accuracy: 0.7214 - val_loss: 0.7789 - learning_rate: 1.0000e-04\nEpoch 12/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7313 - loss: 0.7603 - val_accuracy: 0.7250 - val_loss: 0.7756 - learning_rate: 1.0000e-04\nEpoch 13/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7378 - loss: 0.7411 - val_accuracy: 0.7312 - val_loss: 0.7510 - learning_rate: 1.0000e-04\nEpoch 14/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7463 - loss: 0.7234 - val_accuracy: 0.7431 - val_loss: 0.7304 - learning_rate: 1.0000e-04\nEpoch 15/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7511 - loss: 0.7038 - val_accuracy: 0.7454 - val_loss: 0.7228 - learning_rate: 1.0000e-04\nEpoch 16/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7568 - loss: 0.6909 - val_accuracy: 0.7475 - val_loss: 0.7265 - learning_rate: 1.0000e-04\nEpoch 17/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7626 - loss: 0.6807 - val_accuracy: 0.7512 - val_loss: 0.7019 - learning_rate: 1.0000e-04\nEpoch 18/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7670 - loss: 0.6645 - val_accuracy: 0.7554 - val_loss: 0.7081 - learning_rate: 1.0000e-04\nEpoch 19/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7700 - loss: 0.6523 - val_accuracy: 0.7525 - val_loss: 0.7012 - learning_rate: 1.0000e-04\nEpoch 20/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7754 - loss: 0.6434 - val_accuracy: 0.7539 - val_loss: 0.6986 - learning_rate: 1.0000e-04\nEpoch 21/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7754 - loss: 0.6378 - val_accuracy: 0.7597 - val_loss: 0.7044 - learning_rate: 1.0000e-04\nEpoch 22/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7809 - loss: 0.6254 - val_accuracy: 0.7543 - val_loss: 0.6988 - learning_rate: 1.0000e-04\nEpoch 23/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7867 - loss: 0.6155 - val_accuracy: 0.7542 - val_loss: 0.6996 - learning_rate: 1.0000e-04\nEpoch 24/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.7944 - loss: 0.5871 - val_accuracy: 0.7493 - val_loss: 0.7188 - learning_rate: 1.0000e-04\nEpoch 25/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8035 - loss: 0.5702 - val_accuracy: 0.7674 - val_loss: 0.6712 - learning_rate: 3.0000e-05\nEpoch 26/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8040 - loss: 0.5656 - val_accuracy: 0.7672 - val_loss: 0.6721 - learning_rate: 3.0000e-05\nEpoch 27/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8026 - loss: 0.5691 - val_accuracy: 0.7647 - val_loss: 0.6753 - learning_rate: 3.0000e-05\nEpoch 28/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8088 - loss: 0.5502 - val_accuracy: 0.7640 - val_loss: 0.6771 - learning_rate: 3.0000e-05\nEpoch 29/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8140 - loss: 0.5476 - val_accuracy: 0.7633 - val_loss: 0.6789 - learning_rate: 3.0000e-05\nEpoch 30/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8138 - loss: 0.5411 - val_accuracy: 0.7674 - val_loss: 0.6682 - learning_rate: 9.0000e-06\nEpoch 31/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8119 - loss: 0.5422 - val_accuracy: 0.7659 - val_loss: 0.6679 - learning_rate: 9.0000e-06\nEpoch 32/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 109ms/step - accuracy: 0.8164 - loss: 0.5317 - val_accuracy: 0.7679 - val_loss: 0.6685 - learning_rate: 9.0000e-06\nEpoch 33/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8193 - loss: 0.5299 - val_accuracy: 0.7655 - val_loss: 0.6720 - learning_rate: 9.0000e-06\nEpoch 34/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8215 - loss: 0.5227 - val_accuracy: 0.7692 - val_loss: 0.6681 - learning_rate: 9.0000e-06\nEpoch 35/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8195 - loss: 0.5287 - val_accuracy: 0.7713 - val_loss: 0.6686 - learning_rate: 9.0000e-06\nEpoch 36/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8228 - loss: 0.5249 - val_accuracy: 0.7693 - val_loss: 0.6682 - learning_rate: 2.7000e-06\nEpoch 37/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8237 - loss: 0.5195 - val_accuracy: 0.7682 - val_loss: 0.6688 - learning_rate: 2.7000e-06\nEpoch 38/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8207 - loss: 0.5266 - val_accuracy: 0.7692 - val_loss: 0.6695 - learning_rate: 2.7000e-06\nEpoch 39/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8193 - loss: 0.5303 - val_accuracy: 0.7701 - val_loss: 0.6684 - learning_rate: 2.7000e-06\nEpoch 40/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8265 - loss: 0.5108 - val_accuracy: 0.7700 - val_loss: 0.6688 - learning_rate: 8.1000e-07\nEpoch 41/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8201 - loss: 0.5178 - val_accuracy: 0.7698 - val_loss: 0.6690 - learning_rate: 8.1000e-07\nEpoch 42/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8292 - loss: 0.5089 - val_accuracy: 0.7703 - val_loss: 0.6688 - learning_rate: 8.1000e-07\nEpoch 43/100\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 110ms/step - accuracy: 0.8221 - loss: 0.5200 - val_accuracy: 0.7699 - val_loss: 0.6690 - learning_rate: 8.1000e-07\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"print(\"Starting SOTA Training...\")\n\n# -------------------------------------------------------------\n# 1) TRAIN-TEST SPLIT\n# -------------------------------------------------------------\nfrom sklearn.model_selection import train_test_split\nX_time_train, X_time_val, X_fft_train, X_fft_val, y_train, y_val = train_test_split(\n    X_time, X_fft, Y, test_size=0.2, random_state=42, stratify=Y\n)\n\nprint(\"Train shape:\", X_time_train.shape, X_fft_train.shape)\nprint(\"Val shape:\", X_time_val.shape, X_fft_val.shape)\n\n# -------------------------------------------------------------\n# 2) CLASS WEIGHTS (for imbalance improvement)\n# -------------------------------------------------------------\nfrom sklearn.utils.class_weight import compute_class_weight\ncw = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weights = {i: cw[i] for i in range(len(cw))}\nprint(\"Class weights:\", class_weights)\n\n# -------------------------------------------------------------\n# 3) MODEL ARCHITECTURE\n# -------------------------------------------------------------\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\n\n# ---------------- Residual Block ----------------\ndef residual_block(x, filters, kernel_size=7):\n    shortcut = x\n\n    # Match channel dimensions if needed\n    if x.shape[-1] != filters:\n        shortcut = Conv1D(filters, 1, padding='same')(shortcut)\n\n    # Main path\n    x = Conv1D(filters, kernel_size, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv1D(filters, kernel_size, padding='same')(x)\n    x = BatchNormalization()(x)\n\n    # Add skip connection\n    x = Add()([shortcut, x])\n    x = Activation('relu')(x)\n    return x\n\n# ---------------- Attention Block ----------------\ndef attention_block(inputs):\n    attn_output = MultiHeadAttention(num_heads=4, key_dim=32)(inputs, inputs)\n    attn_output = Dropout(0.2)(attn_output)\n    out = LayerNormalization()(inputs + attn_output)\n    return out\n\n# ---------------- TIME DOMAIN BRANCH ----------------\ninp_time = Input(shape=(1250, 12))\n\nt = Conv1D(64, 9, activation='relu', padding='same')(inp_time)\nt = MaxPooling1D(2)(t)\n\n# 3 Residual blocks\nfor f in [64, 128, 128]:\n    t = residual_block(t, f)\n\nt = MaxPooling1D(2)(t)\nt = Bidirectional(LSTM(64, return_sequences=True))(t)\nt = attention_block(t)\nt = GlobalAveragePooling1D()(t)\n\n# ---------------- FFT DOMAIN BRANCH ----------------\ninp_fft = Input(shape=(600, 12))\n\nf = Conv1D(64, 7, activation='relu', padding='same')(inp_fft)\nf = MaxPooling1D(2)(f)\n\nf = Conv1D(128, 5, activation='relu', padding='same')(f)\nf = MaxPooling1D(2)(f)\n\nf = Bidirectional(LSTM(64, return_sequences=True))(f)\nf = attention_block(f)\nf = GlobalAveragePooling1D()(f)\n\n# ---------------- FUSION ----------------\ncombined = Concatenate()([t, f])\ncombined = BatchNormalization()(combined)\ncombined = Dense(256, activation='relu')(combined)\ncombined = Dropout(0.3)(combined)\ncombined = Dense(128, activation='relu')(combined)\ncombined = Dropout(0.3)(combined)\n\noutput = Dense(5, activation='softmax')(combined)\n\nmodel = Model(inputs=[inp_time, inp_fft], outputs=output)\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-4),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()\n\n# -------------------------------------------------------------\n# 4) TRAINING CALLBACKS\n# -------------------------------------------------------------\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n    \"best_sota_model.h5\",\n    monitor=\"val_loss\",\n    save_best_only=True,\n    verbose=1,\n    mode=\"min\"\n)\n\nearly = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    patience=15,\n    restore_best_weights=True\n)\n\nreduceLR = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    patience=5,\n    factor=0.3,\n    verbose=1\n)\n\n# -------------------------------------------------------------\n# 5) MODEL TRAINING\n# -------------------------------------------------------------\nhistory = model.fit(\n    [X_time_train, X_fft_train],\n    y_train,\n    validation_data=([X_time_val, X_fft_val], y_val),\n    epochs=100,\n    batch_size=64,\n    class_weight=class_weights,\n    callbacks=[checkpoint, early, reduceLR],\n    verbose=1\n)\n\nprint(\"Training Completed.\")\n\n# -------------------------------------------------------------\n# 6) CONFUSION MATRIX\n# -------------------------------------------------------------\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\npreds = model.predict([X_time_val, X_fft_val])\npreds = np.argmax(preds, axis=1)\n\ncm = confusion_matrix(y_val, preds)\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.show()\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_val, preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:37:10.519519Z","iopub.execute_input":"2025-11-23T14:37:10.520159Z","iopub.status.idle":"2025-11-23T15:18:42.404150Z","shell.execute_reply.started":"2025-11-23T14:37:10.520134Z","shell.execute_reply":"2025-11-23T15:18:42.403418Z"}},"outputs":[{"name":"stdout","text":"Starting SOTA Training...\nTrain shape: (34220, 1250, 12) (34220, 600, 12)\nVal shape: (8556, 1250, 12) (8556, 600, 12)\nClass weights: {0: 0.4496124031007752, 1: 0.7886609817930399, 2: 1.5185267361881518, 3: 3.269947443860487, 4: 1.8397849462365592}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_4\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m12\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m6,976\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m28,736\u001b[0m │ max_pooling1d_15… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m28,736\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_15… │\n│                     │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_28 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m57,472\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv1d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_29 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m114,816\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │      \u001b[38;5;34m8,320\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv1d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_30 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m114,816\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv1d_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_31 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m114,816\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m12\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv1d_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_32 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m5,440\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_33 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m41,088\u001b[0m │ max_pooling1d_17… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_18    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m98,816\u001b[0m │ max_pooling1d_16… │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m98,816\u001b[0m │ max_pooling1d_18… │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m66,048\u001b[0m │ bidirectional_5[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ bidirectional_5[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m66,048\u001b[0m │ bidirectional_6[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ bidirectional_6[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bidirectional_5[\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bidirectional_6[\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_15 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m645\u001b[0m │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,976</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,736</span> │ max_pooling1d_15… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,736</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_15… │\n│                     │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">57,472</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">114,816</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">114,816</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">114,816</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,440</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ max_pooling1d_17… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_18    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ max_pooling1d_16… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ max_pooling1d_18… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ bidirectional_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ bidirectional_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ bidirectional_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ bidirectional_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m954,373\u001b[0m (3.64 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">954,373</span> (3.64 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m952,581\u001b[0m (3.63 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">952,581</span> (3.63 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.4921 - loss: 1.3554\nEpoch 1: val_loss improved from inf to 0.89107, saving model to best_sota_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 159ms/step - accuracy: 0.4922 - loss: 1.3551 - val_accuracy: 0.6657 - val_loss: 0.8911 - learning_rate: 1.0000e-04\nEpoch 2/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.6493 - loss: 0.9845\nEpoch 2: val_loss did not improve from 0.89107\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 152ms/step - accuracy: 0.6493 - loss: 0.9845 - val_accuracy: 0.6663 - val_loss: 0.8913 - learning_rate: 1.0000e-04\nEpoch 3/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.6906 - loss: 0.8818\nEpoch 3: val_loss improved from 0.89107 to 0.80451, saving model to best_sota_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.6906 - loss: 0.8818 - val_accuracy: 0.6870 - val_loss: 0.8045 - learning_rate: 1.0000e-04\nEpoch 4/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7138 - loss: 0.8224\nEpoch 4: val_loss improved from 0.80451 to 0.70218, saving model to best_sota_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 154ms/step - accuracy: 0.7138 - loss: 0.8224 - val_accuracy: 0.7425 - val_loss: 0.7022 - learning_rate: 1.0000e-04\nEpoch 5/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7226 - loss: 0.7580\nEpoch 5: val_loss did not improve from 0.70218\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.7226 - loss: 0.7580 - val_accuracy: 0.6273 - val_loss: 0.9323 - learning_rate: 1.0000e-04\nEpoch 6/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7378 - loss: 0.7081\nEpoch 6: val_loss did not improve from 0.70218\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.7378 - loss: 0.7081 - val_accuracy: 0.6328 - val_loss: 0.9358 - learning_rate: 1.0000e-04\nEpoch 7/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7530 - loss: 0.6537\nEpoch 7: val_loss did not improve from 0.70218\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.7530 - loss: 0.6537 - val_accuracy: 0.7415 - val_loss: 0.7125 - learning_rate: 1.0000e-04\nEpoch 8/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7701 - loss: 0.5981\nEpoch 8: val_loss improved from 0.70218 to 0.65793, saving model to best_sota_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.7701 - loss: 0.5981 - val_accuracy: 0.7529 - val_loss: 0.6579 - learning_rate: 1.0000e-04\nEpoch 9/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7938 - loss: 0.5363\nEpoch 9: val_loss improved from 0.65793 to 0.58980, saving model to best_sota_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.7938 - loss: 0.5363 - val_accuracy: 0.7851 - val_loss: 0.5898 - learning_rate: 1.0000e-04\nEpoch 10/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8102 - loss: 0.4823\nEpoch 10: val_loss did not improve from 0.58980\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.8102 - loss: 0.4823 - val_accuracy: 0.7292 - val_loss: 0.7315 - learning_rate: 1.0000e-04\nEpoch 11/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8201 - loss: 0.4332\nEpoch 11: val_loss did not improve from 0.58980\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.8201 - loss: 0.4332 - val_accuracy: 0.7937 - val_loss: 0.6018 - learning_rate: 1.0000e-04\nEpoch 12/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8449 - loss: 0.3720\nEpoch 12: val_loss did not improve from 0.58980\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.8449 - loss: 0.3721 - val_accuracy: 0.7763 - val_loss: 0.6416 - learning_rate: 1.0000e-04\nEpoch 13/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8555 - loss: 0.3392\nEpoch 13: val_loss did not improve from 0.58980\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.8555 - loss: 0.3392 - val_accuracy: 0.7772 - val_loss: 0.6585 - learning_rate: 1.0000e-04\nEpoch 14/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8647 - loss: 0.3057\nEpoch 14: val_loss did not improve from 0.58980\n\nEpoch 14: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.8647 - loss: 0.3057 - val_accuracy: 0.7394 - val_loss: 0.7506 - learning_rate: 1.0000e-04\nEpoch 15/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8999 - loss: 0.2091\nEpoch 15: val_loss improved from 0.58980 to 0.48179, saving model to best_sota_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.8999 - loss: 0.2091 - val_accuracy: 0.8463 - val_loss: 0.4818 - learning_rate: 3.0000e-05\nEpoch 16/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9373 - loss: 0.1267\nEpoch 16: val_loss did not improve from 0.48179\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9373 - loss: 0.1267 - val_accuracy: 0.8581 - val_loss: 0.4963 - learning_rate: 3.0000e-05\nEpoch 17/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9455 - loss: 0.1074\nEpoch 17: val_loss did not improve from 0.48179\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9455 - loss: 0.1074 - val_accuracy: 0.8541 - val_loss: 0.5204 - learning_rate: 3.0000e-05\nEpoch 18/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9518 - loss: 0.0919\nEpoch 18: val_loss did not improve from 0.48179\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9518 - loss: 0.0919 - val_accuracy: 0.8507 - val_loss: 0.5779 - learning_rate: 3.0000e-05\nEpoch 19/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9538 - loss: 0.0905\nEpoch 19: val_loss did not improve from 0.48179\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9538 - loss: 0.0905 - val_accuracy: 0.8689 - val_loss: 0.5380 - learning_rate: 3.0000e-05\nEpoch 20/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9632 - loss: 0.0731\nEpoch 20: val_loss did not improve from 0.48179\n\nEpoch 20: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9632 - loss: 0.0731 - val_accuracy: 0.8675 - val_loss: 0.5511 - learning_rate: 3.0000e-05\nEpoch 21/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9722 - loss: 0.0557\nEpoch 21: val_loss did not improve from 0.48179\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9722 - loss: 0.0557 - val_accuracy: 0.8784 - val_loss: 0.5041 - learning_rate: 9.0000e-06\nEpoch 22/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9777 - loss: 0.0432\nEpoch 22: val_loss did not improve from 0.48179\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9777 - loss: 0.0432 - val_accuracy: 0.8836 - val_loss: 0.5264 - learning_rate: 9.0000e-06\nEpoch 23/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9775 - loss: 0.0406\nEpoch 23: val_loss did not improve from 0.48179\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9775 - loss: 0.0406 - val_accuracy: 0.8834 - val_loss: 0.5340 - learning_rate: 9.0000e-06\nEpoch 24/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9802 - loss: 0.0381\nEpoch 24: val_loss did not improve from 0.48179\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9802 - loss: 0.0381 - val_accuracy: 0.8862 - val_loss: 0.5395 - learning_rate: 9.0000e-06\nEpoch 25/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9820 - loss: 0.0335\nEpoch 25: val_loss did not improve from 0.48179\n\nEpoch 25: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9820 - loss: 0.0335 - val_accuracy: 0.8888 - val_loss: 0.5445 - learning_rate: 9.0000e-06\nEpoch 26/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9856 - loss: 0.0271\nEpoch 26: val_loss did not improve from 0.48179\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9856 - loss: 0.0271 - val_accuracy: 0.8892 - val_loss: 0.5395 - learning_rate: 2.7000e-06\nEpoch 27/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9866 - loss: 0.0264\nEpoch 27: val_loss did not improve from 0.48179\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9866 - loss: 0.0264 - val_accuracy: 0.8891 - val_loss: 0.5437 - learning_rate: 2.7000e-06\nEpoch 28/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9865 - loss: 0.0242\nEpoch 28: val_loss did not improve from 0.48179\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9865 - loss: 0.0242 - val_accuracy: 0.8894 - val_loss: 0.5428 - learning_rate: 2.7000e-06\nEpoch 29/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9866 - loss: 0.0261\nEpoch 29: val_loss did not improve from 0.48179\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9866 - loss: 0.0261 - val_accuracy: 0.8912 - val_loss: 0.5475 - learning_rate: 2.7000e-06\nEpoch 30/100\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9891 - loss: 0.0212\nEpoch 30: val_loss did not improve from 0.48179\n\nEpoch 30: ReduceLROnPlateau reducing learning rate to 8.099999604382901e-07.\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - accuracy: 0.9891 - loss: 0.0212 - val_accuracy: 0.8914 - val_loss: 0.5497 - learning_rate: 2.7000e-06\nTraining Completed.\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.91      0.88      0.90      3806\n           1       0.89      0.81      0.85      2170\n           2       0.71      0.79      0.75      1127\n           3       0.65      0.83      0.73       523\n           4       0.82      0.87      0.84       930\n\n    accuracy                           0.85      8556\n   macro avg       0.80      0.84      0.81      8556\nweighted avg       0.85      0.85      0.85      8556\n\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.regularizers import l2\nimport numpy as np\n\nprint(\"Using shapes:\")\nprint(\"Train:\", X_time_train.shape, X_fft_train.shape)\nprint(\"Val:\", X_time_val.shape, X_fft_val.shape)\n\n# ====================================================================================\n# 1. INCEPTIONTIME BLOCK\n# ====================================================================================\n\ndef inception_module(x, nb_filters):\n    # 3 parallel conv paths\n    conv1 = Conv1D(nb_filters, 9, padding='same', activation='relu')(x)\n    conv2 = Conv1D(nb_filters, 19, padding='same', activation='relu')(x)\n    conv3 = Conv1D(nb_filters, 39, padding='same', activation='relu')(x)\n\n    x = Concatenate()([conv1, conv2, conv3])\n    x = BatchNormalization()(x)\n    return x\n\n\ndef residual_inception_block(x, filters):\n    shortcut = Conv1D(filters * 3, 1, padding='same')(x)\n\n    x = inception_module(x, filters)\n    x = inception_module(x, filters)\n    x = Add()([x, shortcut])\n    x = Activation('relu')(x)\n    return x\n\n\n# ====================================================================================\n# 2. TIME DOMAIN BRANCH  (InceptionTime)\n# ====================================================================================\n\ninput_time = Input(shape=(1250, 12))\n\nt = Conv1D(64, 1, padding='same')(input_time)\nt = BatchNormalization()(t)\nt = Activation('relu')(t)\n\n# 3 residual inception blocks\nfor f in [64, 96, 128]:\n    t = residual_inception_block(t, f)\n    t = MaxPooling1D(2)(t)\n\n# Attention\nt = MultiHeadAttention(num_heads=4, key_dim=64)(t, t)\nt = LayerNormalization()(t)\nt = GlobalAveragePooling1D()(t)\n\n# ====================================================================================\n# 3. FFT BRANCH (simpler CNN + attention)\n# ====================================================================================\n\ninput_fft = Input(shape=(600, 12))\n\nf = Conv1D(64, 5, padding='same', activation='relu')(input_fft)\nf = MaxPooling1D(2)(f)\nf = Conv1D(128, 5, padding='same', activation='relu')(f)\nf = MaxPooling1D(2)(f)\n\nf = MultiHeadAttention(num_heads=4, key_dim=64)(f, f)\nf = LayerNormalization()(f)\nf = GlobalAveragePooling1D()(f)\n\n# ====================================================================================\n# 4. FUSION\n# ====================================================================================\n\ncombined = Concatenate()([t, f])\ncombined = BatchNormalization()(combined)\n\ncombined = Dense(256, activation='relu')(combined)\ncombined = Dropout(0.4)(combined)\ncombined = Dense(128, activation='relu')(combined)\ncombined = Dropout(0.3)(combined)\n\noutput = Dense(5, activation='softmax')(combined)\n\n# ====================================================================================\n# 5. BUILD MODEL\n# ====================================================================================\n\nmodel = Model([input_time, input_fft], output)\nmodel.compile(\n    optimizer=Adam(1e-4),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()\n\n# ====================================================================================\n# 6. CALLBACKS\n# ====================================================================================\n\ncallbacks = [\n    ModelCheckpoint(\"best_inception_model.h5\", save_best_only=True, monitor=\"val_loss\", verbose=1),\n    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3, patience=5, verbose=1),\n    EarlyStopping(monitor=\"val_loss\", patience=12, restore_best_weights=True, verbose=1)\n]\n\n# ====================================================================================\n# 7. TRAIN\n# ====================================================================================\n\nprint(\"Starting InceptionTime Training...\")\n\nhistory = model.fit(\n    [X_time_train, X_fft_train],\n    y_train,\n    validation_data=([X_time_val, X_fft_val], y_val),\n    epochs=30,\n    batch_size=64,\n    class_weight=class_weights,\n    callbacks=callbacks,\n    verbose=1\n)\n\nprint(\"Training completed!\")\n\n# ============================================================\n# 8) FINAL EVALUATION (AUTO-RUN AFTER TRAINING)\n# ============================================================\n\nprint(\"\\nEvaluating model...\")\n\n# Predict\ny_pred = np.argmax(model.predict([X_time_val, X_fft_val]), axis=1)\n\n# Classification report\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_val, y_pred))\n\n# Confusion Matrix\ncm = confusion_matrix(y_val, y_pred)\n\nplt.figure(figsize=(7,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.show()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T18:59:52.394174Z","iopub.execute_input":"2025-11-23T18:59:52.394874Z","iopub.status.idle":"2025-11-23T21:36:28.589366Z","shell.execute_reply.started":"2025-11-23T18:59:52.394849Z","shell.execute_reply":"2025-11-23T21:36:28.588563Z"}},"outputs":[{"name":"stdout","text":"Using shapes:\nTrain: (34220, 1250, 12) (34220, 600, 12)\nVal: (8556, 1250, 12) (8556, 600, 12)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_8\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_16      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m12\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_106 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m832\u001b[0m │ input_layer_16[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ conv1d_106[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_17       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_108 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m36,928\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_109 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m77,888\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_110 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │    \u001b[38;5;34m159,808\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_25      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv1d_108[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_109[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                     │                   │            │ conv1d_110[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ concatenate_25[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_111 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │    \u001b[38;5;34m110,656\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_112 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │    \u001b[38;5;34m233,536\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_113 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │    \u001b[38;5;34m479,296\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_26      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv1d_111[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_112[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                     │                   │            │ conv1d_113[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ concatenate_26[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_107 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m12,480\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_16 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│                     │                   │            │ conv1d_107[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_18       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_34    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m192\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ activation_18[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_115 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │    \u001b[38;5;34m165,984\u001b[0m │ max_pooling1d_34… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_116 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │    \u001b[38;5;34m350,304\u001b[0m │ max_pooling1d_34… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_117 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │    \u001b[38;5;34m718,944\u001b[0m │ max_pooling1d_34… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_27      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m288\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_115[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_116[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                     │                   │            │ conv1d_117[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m288\u001b[0m)  │      \u001b[38;5;34m1,152\u001b[0m │ concatenate_27[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_118 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │    \u001b[38;5;34m248,928\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_119 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │    \u001b[38;5;34m525,408\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_120 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │  \u001b[38;5;34m1,078,368\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_28      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m288\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_118[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_119[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                     │                   │            │ conv1d_120[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m288\u001b[0m)  │      \u001b[38;5;34m1,152\u001b[0m │ concatenate_28[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_114 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m288\u001b[0m)  │     \u001b[38;5;34m55,584\u001b[0m │ max_pooling1d_34… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_17 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m288\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│                     │                   │            │ conv1d_114[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_19       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m, \u001b[38;5;34m288\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ add_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_35    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m288\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ activation_19[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_122 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m331,904\u001b[0m │ max_pooling1d_35… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_123 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m700,544\u001b[0m │ max_pooling1d_35… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_124 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m1,437,824\u001b[0m │ max_pooling1d_35… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_29      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m384\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_122[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_123[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                     │                   │            │ conv1d_124[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m384\u001b[0m)  │      \u001b[38;5;34m1,536\u001b[0m │ concatenate_29[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_125 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m442,496\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_126 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m934,016\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_127 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m1,917,056\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_30      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m384\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_125[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_126[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                     │                   │            │ conv1d_127[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_17      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m12\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m384\u001b[0m)  │      \u001b[38;5;34m1,536\u001b[0m │ concatenate_30[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_121 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m384\u001b[0m)  │    \u001b[38;5;34m110,976\u001b[0m │ max_pooling1d_35… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_128 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m3,904\u001b[0m │ input_layer_17[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_18 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m384\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│                     │                   │            │ conv1d_121[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_37    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_128[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_20       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m384\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ add_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_129 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m41,088\u001b[0m │ max_pooling1d_37… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_36    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m384\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ activation_20[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_38    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_129[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m384\u001b[0m)  │    \u001b[38;5;34m394,368\u001b[0m │ max_pooling1d_36… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ max_pooling1d_36… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m131,968\u001b[0m │ max_pooling1d_38… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ max_pooling1d_38… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m384\u001b[0m)  │        \u001b[38;5;34m768\u001b[0m │ multi_head_atten… │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ multi_head_atten… │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_31      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ concatenate_31[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_26 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_27 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_34          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_28 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m645\u001b[0m │ dropout_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_16      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │ input_layer_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_106[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_17       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">77,888</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">159,808</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_25      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_108[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_109[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                     │                   │            │ conv1d_110[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ concatenate_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">110,656</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_112 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">233,536</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_113 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">479,296</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_26      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_111[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_112[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                     │                   │            │ conv1d_113[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ concatenate_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,480</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│                     │                   │            │ conv1d_107[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_18       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_34    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_115 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">165,984</span> │ max_pooling1d_34… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_116 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">350,304</span> │ max_pooling1d_34… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_117 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">718,944</span> │ max_pooling1d_34… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_27      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_115[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_116[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                     │                   │            │ conv1d_117[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ concatenate_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_118 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">248,928</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_119 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,408</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_120 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,078,368</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_28      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_118[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_119[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                     │                   │            │ conv1d_120[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ concatenate_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_114 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,584</span> │ max_pooling1d_34… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│                     │                   │            │ conv1d_114[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_19       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_35    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,904</span> │ max_pooling1d_35… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">700,544</span> │ max_pooling1d_35… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,437,824</span> │ max_pooling1d_35… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_29      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_122[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_123[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                     │                   │            │ conv1d_124[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ concatenate_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">442,496</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">934,016</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_127 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,917,056</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_30      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_125[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_126[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                     │                   │            │ conv1d_127[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_17      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ concatenate_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">110,976</span> │ max_pooling1d_35… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,904</span> │ input_layer_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│                     │                   │            │ conv1d_121[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_37    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_128[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_20       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_129 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ max_pooling1d_37… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_36    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling1d_38    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_129[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,368</span> │ max_pooling1d_36… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ max_pooling1d_36… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,968</span> │ max_pooling1d_38… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ max_pooling1d_38… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ multi_head_atten… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ multi_head_atten… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_31      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ concatenate_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_34          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dropout_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,876,197\u001b[0m (41.49 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,876,197</span> (41.49 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,871,589\u001b[0m (41.47 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,871,589</span> (41.47 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,608\u001b[0m (18.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> (18.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Starting InceptionTime Training...\nEpoch 1/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.5231 - loss: 1.3238\nEpoch 1: val_loss improved from inf to 0.95329, saving model to best_inception_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 619ms/step - accuracy: 0.5232 - loss: 1.3235 - val_accuracy: 0.6282 - val_loss: 0.9533 - learning_rate: 1.0000e-04\nEpoch 2/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567ms/step - accuracy: 0.6569 - loss: 0.9751\nEpoch 2: val_loss improved from 0.95329 to 0.79862, saving model to best_inception_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 585ms/step - accuracy: 0.6569 - loss: 0.9751 - val_accuracy: 0.6981 - val_loss: 0.7986 - learning_rate: 1.0000e-04\nEpoch 3/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.6803 - loss: 0.8870\nEpoch 3: val_loss improved from 0.79862 to 0.75788, saving model to best_inception_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 582ms/step - accuracy: 0.6803 - loss: 0.8870 - val_accuracy: 0.7328 - val_loss: 0.7579 - learning_rate: 1.0000e-04\nEpoch 4/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.7048 - loss: 0.8187\nEpoch 4: val_loss improved from 0.75788 to 0.65879, saving model to best_inception_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 583ms/step - accuracy: 0.7048 - loss: 0.8187 - val_accuracy: 0.7516 - val_loss: 0.6588 - learning_rate: 1.0000e-04\nEpoch 5/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.7245 - loss: 0.7657\nEpoch 5: val_loss did not improve from 0.65879\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 581ms/step - accuracy: 0.7245 - loss: 0.7657 - val_accuracy: 0.6637 - val_loss: 0.8732 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.7352 - loss: 0.7195\nEpoch 6: val_loss did not improve from 0.65879\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 581ms/step - accuracy: 0.7352 - loss: 0.7195 - val_accuracy: 0.7534 - val_loss: 0.6659 - learning_rate: 1.0000e-04\nEpoch 7/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.7479 - loss: 0.6546\nEpoch 7: val_loss did not improve from 0.65879\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 581ms/step - accuracy: 0.7479 - loss: 0.6546 - val_accuracy: 0.7180 - val_loss: 0.7356 - learning_rate: 1.0000e-04\nEpoch 8/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.7764 - loss: 0.5827\nEpoch 8: val_loss did not improve from 0.65879\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 581ms/step - accuracy: 0.7764 - loss: 0.5827 - val_accuracy: 0.6424 - val_loss: 0.8840 - learning_rate: 1.0000e-04\nEpoch 9/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.7978 - loss: 0.5036\nEpoch 9: val_loss did not improve from 0.65879\n\nEpoch 9: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 580ms/step - accuracy: 0.7978 - loss: 0.5037 - val_accuracy: 0.7238 - val_loss: 0.6958 - learning_rate: 1.0000e-04\nEpoch 10/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.8536 - loss: 0.3494\nEpoch 10: val_loss improved from 0.65879 to 0.48835, saving model to best_inception_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 582ms/step - accuracy: 0.8536 - loss: 0.3493 - val_accuracy: 0.8337 - val_loss: 0.4883 - learning_rate: 3.0000e-05\nEpoch 11/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.9058 - loss: 0.2117\nEpoch 11: val_loss improved from 0.48835 to 0.47749, saving model to best_inception_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 581ms/step - accuracy: 0.9058 - loss: 0.2117 - val_accuracy: 0.8478 - val_loss: 0.4775 - learning_rate: 3.0000e-05\nEpoch 12/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.9268 - loss: 0.1540\nEpoch 12: val_loss improved from 0.47749 to 0.45370, saving model to best_inception_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 580ms/step - accuracy: 0.9268 - loss: 0.1540 - val_accuracy: 0.8652 - val_loss: 0.4537 - learning_rate: 3.0000e-05\nEpoch 13/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.9436 - loss: 0.1211\nEpoch 13: val_loss did not improve from 0.45370\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 580ms/step - accuracy: 0.9436 - loss: 0.1211 - val_accuracy: 0.8566 - val_loss: 0.5008 - learning_rate: 3.0000e-05\nEpoch 14/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step - accuracy: 0.9554 - loss: 0.0922\nEpoch 14: val_loss did not improve from 0.45370\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 579ms/step - accuracy: 0.9554 - loss: 0.0922 - val_accuracy: 0.8795 - val_loss: 0.4557 - learning_rate: 3.0000e-05\nEpoch 15/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.9664 - loss: 0.0703\nEpoch 15: val_loss did not improve from 0.45370\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 581ms/step - accuracy: 0.9664 - loss: 0.0703 - val_accuracy: 0.8665 - val_loss: 0.5414 - learning_rate: 3.0000e-05\nEpoch 16/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.9747 - loss: 0.0586\nEpoch 16: val_loss did not improve from 0.45370\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 579ms/step - accuracy: 0.9747 - loss: 0.0586 - val_accuracy: 0.8710 - val_loss: 0.5274 - learning_rate: 3.0000e-05\nEpoch 17/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.9753 - loss: 0.0544\nEpoch 17: val_loss did not improve from 0.45370\n\nEpoch 17: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 580ms/step - accuracy: 0.9753 - loss: 0.0544 - val_accuracy: 0.8953 - val_loss: 0.4978 - learning_rate: 3.0000e-05\nEpoch 18/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.9879 - loss: 0.0289\nEpoch 18: val_loss improved from 0.45370 to 0.41166, saving model to best_inception_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 581ms/step - accuracy: 0.9879 - loss: 0.0289 - val_accuracy: 0.9198 - val_loss: 0.4117 - learning_rate: 9.0000e-06\nEpoch 19/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.9945 - loss: 0.0135\nEpoch 19: val_loss did not improve from 0.41166\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 579ms/step - accuracy: 0.9945 - loss: 0.0135 - val_accuracy: 0.9226 - val_loss: 0.4280 - learning_rate: 9.0000e-06\nEpoch 20/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.9946 - loss: 0.0107\nEpoch 20: val_loss did not improve from 0.41166\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 579ms/step - accuracy: 0.9946 - loss: 0.0107 - val_accuracy: 0.9261 - val_loss: 0.4396 - learning_rate: 9.0000e-06\nEpoch 21/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.9967 - loss: 0.0082\nEpoch 21: val_loss did not improve from 0.41166\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 580ms/step - accuracy: 0.9967 - loss: 0.0082 - val_accuracy: 0.9266 - val_loss: 0.4598 - learning_rate: 9.0000e-06\nEpoch 22/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.9965 - loss: 0.0081\nEpoch 22: val_loss did not improve from 0.41166\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 578ms/step - accuracy: 0.9965 - loss: 0.0081 - val_accuracy: 0.9224 - val_loss: 0.4752 - learning_rate: 9.0000e-06\nEpoch 23/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.9971 - loss: 0.0079\nEpoch 23: val_loss did not improve from 0.41166\n\nEpoch 23: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 580ms/step - accuracy: 0.9971 - loss: 0.0079 - val_accuracy: 0.9220 - val_loss: 0.5026 - learning_rate: 9.0000e-06\nEpoch 24/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.9974 - loss: 0.0069\nEpoch 24: val_loss did not improve from 0.41166\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 580ms/step - accuracy: 0.9974 - loss: 0.0069 - val_accuracy: 0.9263 - val_loss: 0.4739 - learning_rate: 2.7000e-06\nEpoch 25/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.9986 - loss: 0.0041\nEpoch 25: val_loss did not improve from 0.41166\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 581ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9306 - val_loss: 0.4736 - learning_rate: 2.7000e-06\nEpoch 26/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.9983 - loss: 0.0037\nEpoch 26: val_loss did not improve from 0.41166\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 581ms/step - accuracy: 0.9983 - loss: 0.0037 - val_accuracy: 0.9331 - val_loss: 0.4722 - learning_rate: 2.7000e-06\nEpoch 27/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.9988 - loss: 0.0033\nEpoch 27: val_loss did not improve from 0.41166\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 579ms/step - accuracy: 0.9988 - loss: 0.0033 - val_accuracy: 0.9294 - val_loss: 0.4810 - learning_rate: 2.7000e-06\nEpoch 28/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.9984 - loss: 0.0041\nEpoch 28: val_loss did not improve from 0.41166\n\nEpoch 28: ReduceLROnPlateau reducing learning rate to 8.099999604382901e-07.\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 579ms/step - accuracy: 0.9984 - loss: 0.0041 - val_accuracy: 0.9331 - val_loss: 0.4800 - learning_rate: 2.7000e-06\nEpoch 29/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.9995 - loss: 0.0020\nEpoch 29: val_loss did not improve from 0.41166\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 581ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9330 - val_loss: 0.4838 - learning_rate: 8.1000e-07\nEpoch 30/30\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.9990 - loss: 0.0035\nEpoch 30: val_loss did not improve from 0.41166\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 580ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 0.9337 - val_loss: 0.4811 - learning_rate: 8.1000e-07\nEpoch 30: early stopping\nRestoring model weights from the end of the best epoch: 18.\nTraining completed!\n\nEvaluating model...\n\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.94      0.95      0.94      3806\n           1       0.93      0.91      0.92      2170\n           2       0.87      0.87      0.87      1127\n           3       0.88      0.82      0.85       523\n           4       0.89      0.94      0.91       930\n\n    accuracy                           0.92      8556\n   macro avg       0.90      0.90      0.90      8556\nweighted avg       0.92      0.92      0.92      8556\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 700x600 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAlAAAAIjCAYAAADMVCUqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABxJklEQVR4nO3deVxNeR8H8M8tdds37aISIruQ7NsUYuzL2EIYJgZZM3ZGxp6dsWTfB2Of1MQY2SISsovRpijtqfv80ePO3Cl07rjd6n7ez+s+j/s7v3Pu95znVt/7/f3O74okEokERERERFRkasoOgIiIiKi0YQJFREREJBATKCIiIiKBmEARERERCcQEioiIiEggJlBEREREAjGBIiIiIhKICRQRERGRQEygiIiIiARiAkVUCjx8+BBubm4wNDSESCTC0aNHv+jxnz17BpFIhICAgC963NKsdevWaN26tbLDIKISigkUURE9fvwY3377LSpXrgwtLS0YGBigWbNm8Pf3R0ZGhkJf29PTExEREfjxxx+xc+dONGzYUKGvV5yGDBkCkUgEAwODQq/jw4cPIRKJIBKJsHTpUsHHf/XqFebMmYPw8PAvEC0RUb5yyg6AqDQ4efIkevfuDbFYjMGDB6NWrVrIzs7GxYsXMXnyZERGRmLTpk0Kee2MjAyEhobihx9+wJgxYxTyGra2tsjIyICGhoZCjv855cqVQ3p6Oo4fP44+ffrIbNu9eze0tLSQmZkp17FfvXqFuXPnws7ODvXq1Svyfr/99ptcr0dEqoEJFNFnPH36FP369YOtrS2Cg4NhZWUl3ebt7Y1Hjx7h5MmTCnv9hIQEAICRkZHCXkMkEkFLS0thx/8csViMZs2aYe/evQUSqD179sDDwwOHDx8ulljS09Oho6MDTU3NYnk9IiqdOIRH9BmLFy9GamoqtmzZIpM8fVClShWMGzdO+vz9+/eYP38+HBwcIBaLYWdnh+nTpyMrK0tmPzs7O3Tu3BkXL15E48aNoaWlhcqVK2PHjh3SPnPmzIGtrS0AYPLkyRCJRLCzswOQP/T14d//NGfOHIhEIpm2wMBANG/eHEZGRtDT04OjoyOmT58u3f6xOVDBwcFo0aIFdHV1YWRkhK5du+LevXuFvt6jR48wZMgQGBkZwdDQEEOHDkV6evrHL+y/9O/fH6dPn8bbt2+lbdeuXcPDhw/Rv3//Av2TkpIwadIk1K5dG3p6ejAwMEDHjh1x69YtaZ+QkBA0atQIADB06FDpUOCH82zdujVq1aqFsLAwtGzZEjo6OtLr8u85UJ6entDS0ipw/u7u7jA2NsarV6+KfK5EVPoxgSL6jOPHj6Ny5cpo2rRpkfoPHz4cs2bNQoMGDbBixQq0atUKfn5+6NevX4G+jx49Qq9evfDVV19h2bJlMDY2xpAhQxAZGQkA6NGjB1asWAEA+Oabb7Bz506sXLlSUPyRkZHo3LkzsrKyMG/ePCxbtgxff/01/vzzz0/ud+7cObi7uyM+Ph5z5syBj48PLl26hGbNmuHZs2cF+vfp0wfv3r2Dn58f+vTpg4CAAMydO7fIcfbo0QMikQi//PKLtG3Pnj2oXr06GjRoUKD/kydPcPToUXTu3BnLly/H5MmTERERgVatWkmTmRo1amDevHkAgJEjR2Lnzp3YuXMnWrZsKT1OYmIiOnbsiHr16mHlypVo06ZNofH5+/vDzMwMnp6eyM3NBQBs3LgRv/32G1avXg1ra+sinysRlQESIvqo5ORkCQBJ165di9Q/PDxcAkAyfPhwmfZJkyZJAEiCg4Olbba2thIAkgsXLkjb4uPjJWKxWDJx4kRp29OnTyUAJEuWLJE5pqenp8TW1rZADLNnz5b880d7xYoVEgCShISEj8b94TW2bdsmbatXr57E3NxckpiYKG27deuWRE1NTTJ48OACrzds2DCZY3bv3l1Svnz5j77mP89DV1dXIpFIJL169ZK0a9dOIpFIJLm5uRJLS0vJ3LlzC70GmZmZktzc3ALnIRaLJfPmzZO2Xbt2rcC5fdCqVSsJAMmGDRsK3daqVSuZtrNnz0oASBYsWCB58uSJRE9PT9KtW7fPniMRlT2sQBF9QkpKCgBAX1+/SP1PnToFAPDx8ZFpnzhxIgAUmCvl5OSEFi1aSJ+bmZnB0dERT548kTvmf/swd+rYsWPIy8sr0j4xMTEIDw/HkCFDYGJiIm2vU6cOvvrqK+l5/tOoUaNknrdo0QKJiYnSa1gU/fv3R0hICGJjYxEcHIzY2NhCh++A/HlTamr5v8Jyc3ORmJgoHZ68ceNGkV9TLBZj6NChRerr5uaGb7/9FvPmzUOPHj2gpaWFjRs3Fvm1iKjsYAJF9AkGBgYAgHfv3hWp//Pnz6GmpoYqVarItFtaWsLIyAjPnz+Xaa9UqVKBYxgbG+PNmzdyRlxQ37590axZMwwfPhwWFhbo168fDhw48Mlk6kOcjo6OBbbVqFEDr1+/Rlpamkz7v8/F2NgYAASdS6dOnaCvr4/9+/dj9+7daNSoUYFr+UFeXh5WrFiBqlWrQiwWw9TUFGZmZrh9+zaSk5OL/JoVKlQQNGF86dKlMDExQXh4OFatWgVzc/Mi70tEZQcTKKJPMDAwgLW1Ne7cuSNov39P4v4YdXX1QtslEoncr/Fhfs4H2trauHDhAs6dO4dBgwbh9u3b6Nu3L7766qsCff+L/3IuH4jFYvTo0QPbt2/HkSNHPlp9AoCFCxfCx8cHLVu2xK5du3D27FkEBgaiZs2aRa60AfnXR4ibN28iPj4eABARESFoXyIqO5hAEX1G586d8fjxY4SGhn62r62tLfLy8vDw4UOZ9ri4OLx9+1Z6R92XYGxsLHPH2gf/rnIBgJqaGtq1a4fly5fj7t27+PHHHxEcHIzff/+90GN/iDMqKqrAtvv378PU1BS6urr/7QQ+on///rh58ybevXtX6MT7Dw4dOoQ2bdpgy5Yt6NevH9zc3NC+ffsC16SoyWxRpKWlYejQoXBycsLIkSOxePFiXLt27Ysdn4hKDyZQRJ8xZcoU6OrqYvjw4YiLiyuw/fHjx/D39weQPwQFoMCdcsuXLwcAeHh4fLG4HBwckJycjNu3b0vbYmJicOTIEZl+SUlJBfb9sKDkv5dW+MDKygr16tXD9u3bZRKSO3fu4LfffpOepyK0adMG8+fPx5o1a2BpafnRfurq6gWqWwcPHsRff/0l0/Yh0Sss2RRq6tSpiI6Oxvbt27F8+XLY2dnB09Pzo9eRiMouLqRJ9BkODg7Ys2cP+vbtixo1asisRH7p0iUcPHgQQ4YMAQDUrVsXnp6e2LRpE96+fYtWrVrh6tWr2L59O7p16/bRW+Tl0a9fP0ydOhXdu3fH999/j/T0dKxfvx7VqlWTmUQ9b948XLhwAR4eHrC1tUV8fDzWrVsHGxsbNG/e/KPHX7JkCTp27AhXV1d4eXkhIyMDq1evhqGhIebMmfPFzuPf1NTUMGPGjM/269y5M+bNm4ehQ4eiadOmiIiIwO7du1G5cmWZfg4ODjAyMsKGDRugr68PXV1duLi4wN7eXlBcwcHBWLduHWbPni1dVmHbtm1o3bo1Zs6cicWLFws6HhGVckq+C5Co1Hjw4IFkxIgREjs7O4mmpqZEX19f0qxZM8nq1aslmZmZ0n45OTmSuXPnSuzt7SUaGhqSihUrSnx9fWX6SCT5yxh4eHgUeJ1/3z7/sWUMJBKJ5LfffpPUqlVLoqmpKXF0dJTs2rWrwDIGQUFBkq5du0qsra0lmpqaEmtra8k333wjefDgQYHX+Pet/ufOnZM0a9ZMoq2tLTEwMJB06dJFcvfuXZk+H17v38skbNu2TQJA8vTp049eU4lEdhmDj/nYMgYTJ06UWFlZSbS1tSXNmjWThIaGFrr8wLFjxyROTk6ScuXKyZxnq1atJDVr1iz0Nf95nJSUFImtra2kQYMGkpycHJl+EyZMkKipqUlCQ0M/eQ5EVLaIJBIBMzyJiIiIiHOgiIiIiIRiAkVEREQkEBMoIiIiIoGYQBEREREJxASKiIiISCAmUEREREQCMYEiIiIiEqhMrkSuXX+MskMos15fWa3sEMqsL/eNbVQAL65icBVBhdHRLL43raL/ZmbcXKPQ4ysLK1BEREREApXJChQREREVkYi1FHkwgSIiIlJlIo5xy4NpJxEREZFArEARERGpMg7hyYVXjYiIiEggVqCIiIhUGedAyYUVKCIiIiKBWIEiIiJSZZwDJRdeNSIiIiKBmEARERGpMpFIsY8iWr9+PerUqQMDAwMYGBjA1dUVp0+flm5v3bo1RCKRzGPUqFEyx4iOjoaHhwd0dHRgbm6OyZMn4/379zJ9QkJC0KBBA4jFYlSpUgUBAQFyXTYO4REREamyEjKEZ2Njg0WLFqFq1aqQSCTYvn07unbtips3b6JmzZoAgBEjRmDevHnSfXR0dKT/zs3NhYeHBywtLXHp0iXExMRg8ODB0NDQwMKFCwEAT58+hYeHB0aNGoXdu3cjKCgIw4cPh5WVFdzd3QXFK5JIJGXu6yD5ZcKKwy8TVhzeB6NAvLiKUeb+epQcxfplwk2mKvT4GZd/kntfExMTLFmyBF5eXmjdujXq1auHlStXFtr39OnT6Ny5M169egULCwsAwIYNGzB16lQkJCRAU1MTU6dOxcmTJ3Hnzh3pfv369cPbt29x5swZQbGVjLSTiIiIlEPBQ3hZWVlISUmReWRlZX0ypNzcXOzbtw9paWlwdXWVtu/evRumpqaoVasWfH19kZ6eLt0WGhqK2rVrS5MnAHB3d0dKSgoiIyOlfdq3by/zWu7u7ggNDRV82ZhAERERkcL4+fnB0NBQ5uHn51do34iICOjp6UEsFmPUqFE4cuQInJycAAD9+/fHrl278Pvvv8PX1xc7d+7EwIEDpfvGxsbKJE8ApM9jY2M/2SclJQUZGRmCzotzoIiIiFSZgudA+fr6wsfHR6ZNLBYX2tfR0RHh4eFITk7GoUOH4OnpifPnz8PJyQkjR46U9qtduzasrKzQrl07PH78GA4ODgo9h8IwgSIiIiKFEYvFH02Y/k1TUxNVqlQBADg7O+PatWvw9/fHxo0bC/R1cXEBADx69AgODg6wtLTE1atXZfrExcUBACwtLaX/+6Htn30MDAygra0t6Lw4hEdERKTKSsgyBoXJy8v76Hyp8PBwAICVlRUAwNXVFREREYiPj5f2CQwMhIGBgXQY0NXVFUFBQTLHCQwMlJlnVVSsQBEREZHS+fr6omPHjqhUqRLevXuHPXv2ICQkBGfPnsXjx4+xZ88edOrUCeXLl8ft27cxYcIEtGzZEnXq1AEAuLm5wcnJCYMGDcLixYsRGxuLGTNmwNvbW1oBGzVqFNasWYMpU6Zg2LBhCA4OxoEDB3Dy5EnB8TKBIiIiUmUlZB2o+Ph4DB48GDExMTA0NESdOnVw9uxZfPXVV3jx4gXOnTuHlStXIi0tDRUrVkTPnj0xY8YM6f7q6uo4ceIERo8eDVdXV+jq6sLT01Nm3Sh7e3ucPHkSEyZMgL+/P2xsbLB582bBa0ABXAeKBOI6UIrDpYoUiBdXMcrcX4+So1jXgWoxS6HHz/hj3uc7lUIlI+0kIiIiKkU4hEdERKTKSsgQXmnDq0ZEREQkECtQREREqowVKLnwqhEREREJxAoUERGRKlPjbaryYAWKiIiISCBWoIiIiFQZ50DJhQkUERGRKvuP31enqph2EhEREQnEChQREZEq4xCeXHjViIiIiARiBYqIiEiVcQ6UXFiBIiIiIhKIFSgiIiJVxjlQcuFVIyIiIhKIFSgiIiJVxjlQcmECRUREpMo4hCcXXjUiIiIigZhA/UcjejfH1f2+iPtjCeL+WIKQ7RPh1sxJpo9LHXuc3jgWry8tQ9wfSxC4ZTy0xBrS7VO83PF7gA8SLy1HzIXFH32tgV1ccHW/L95cXoHnQX5YMa2Pws6rNImPi8MP0yajTXMXuDasiz7du+BuZIRMnydPHmP82NFo6doQTRvXx8B+vRAT80pJEZc+WzdvQv3a1bHkp4UFtkkkEniPGoH6tavj96BzSoiudDmwby/6dP8azV2c0dzFGYMH9MXFPy5Itw8fMgj1a1WXeSyYO1uJEZdehb1vhw8dhPq1q8s8FsxT8esrEin2UUZxCO8/+ivuLWauPoZH0QkQQYSBXVxwcMVINOm3CPeexMKljj2OrfkOS7f9Bp+fDuJ9bh7qVKuAvDyJ9BiaGur4JfAmrtx+Cs9uroW+zvcD22LcoLaYvuIort55Bl1tTdhaly+u0yyxUpKTMXTwN2jYyAWr1/8MY2MTREc/g76BobTPixfR8BrcH1179MKo78ZCV08PTx49glhTrMTIS4/IOxE4fGg/qlZzLHT77p3bISrDvyS/NAtLC4ydMBGVbG0BiQTHjx3FhLHe2HfoFzhUqQoA6NGrN0aP+V66j5aWtrLCLbU+9b7t0ZPXl/47JlD/0akLd2Sez1l7HCN6N0fjOva49yQWiyf2wLp9IVi6LVDa5+HzeJl9Fmw4BSC/wlQYI31tzP6uM3qO34CQqw+k7XcesoISsHUzLCytMHeBn7Stgo2NTJ+1q1aiWYtWGO8zWdpWsWKlYouxNEtPT8P0aZMwc/Z8bN60vsD2qPv3sHP7NuzefwhftWmhhAhLn1at28o8HzNuAg7u34fbt25JEygtLW2YmpopI7wy4XPvWy1tXl8ZnAMlF6VetdevX2Px4sXo3r07XF1d4erqiu7du2PJkiVISEhQZmhyUVMTobe7M3S1NXHl9lOYGeuhcR17JCSl4vcAHzw7txC/bR6HpvUqCzpuuybVoaYmgrW5EW4enoFHZ+Zj10/DYGNhpJgTKUXOhwTDyakWpviMQ7tWTfFN7+745dAB6fa8vDxcvBACW1s7fPetF9q1aorB/ftwqKmI/H6chxYtWqOJa9MC2zIyMuA7dRKm/TCLf4zklJubizOnTiIjIx116tWTtp86eRxtmjdBr25dsGrFMmRkZCgvyFLoU+9b4P/Xt0UT9OreBatW8vqSfJRWgbp27Rrc3d2ho6OD9u3bo1q1agCAuLg4rFq1CosWLcLZs2fRsGHDTx4nKysLWVlZMm2SvFyI1NQVFvu/1axijZDtE6GlWQ6pGVnoO/Fn3H8Si8a17QAAP3zbCb4rjuB21EsM6NwYpzaOhXPvhXgcXbQk0d7GFGpqIkwZ5oZJSw4jJTUDs70748T6MWjUxw8573MVeHYl218vX+DQgb0YMHgIho34FpF3IrBk0Y/Q0NBAl67dkZSUiPT0dGzb+jO+GzMO4yZMwqWLf2DShLHYtGU7nBs1VvYplFhnTp/E/bt3sWvfoUK3L1vsh7r16qNN23bFHFnp9/BBFDwHfIPs7Cxo6+hgmf8aODhUAQB09OgMK2trmJmZ4+GDB/BfsRTPnz3DMv/VSo66dPjc+7Zjp49c35UqfH05BC8XpSVQY8eORe/evbFhw4YC8yckEglGjRqFsWPHIjQ09JPH8fPzw9y5c2Xa1C0aQcOq+P4wPngWB5d+fjDU00b39vXx87xBcBvuDzW1/PPacvgidv56GQBwK+olWjd2hGdXV8xa/WuRji8SiaCpUQ4TFx9C0OX7AABP3wA8C1yIVo2q4VzoPcWcWCmQlyeBU82aGDvOBwBQvYYTHj96iEMH9qFL1+6Q5OUBAFq3bouBg4cAAByr18CtWzdx6OA+JlAfERsbgyWLFmL9pq0QiwvOFQv5PRhXr17BvoO/KCG60s/O3h77Dh9B6rt3OPfbWcz6YRo2B+yEg0MV9OzdV9qvajVHmJqZ4VuvIXgRHY2KlTj0/Cmfe98CKPz6Dh+CFy+iObRPgigtgbp16xYCAgIKnXwqEokwYcIE1K9f/7PH8fX1hY+Pj0ybeYupXyzOosh5n4snL14DAG7eewHnmpXg/U1r6byne09iZfpHPY1FRUvjIh8/9nUKAOD+P47z+k0qXr9NFXScssjUzAyV///J/QP7yg4IOvcbAMDI2BjlypUr2MfeAeE3w4otztLmXmQkkpIS0b9vD2lbbm4uboRdx/69u9GrTz+8fBGNlk1lE9BJPt+jfgNnbN62s7hDLlU0NDRRqZItAMCpZi1ERt7B3l07MGP2vAJ9a9euAwB48eI5E6jP+Nz79krYbairy45OSK9v9HPVTaA4B0ouSkugLC0tcfXqVVSvXr3Q7VevXoWFhcVnjyMWiwt80ijO4bvCqIlEEGuWw/NXiXgV/xbV7MxltlexNcdvf94t8vFCw58AAKrameOv+LcAAGMDHZga6SE6JumLxV0a1atXH8+ePZVpe/7sGaysrAHk/6FyqlmrQJ/o53/3oYIaN2mCg7/IVkhnz5wOe/vKGDJsOIyMjdHrH5/kAaB3j68xcco0tGolO0maPk+Sl4fs7OxCt0Xdz686m5qaF7qd/va59+2/kycAiIri9WUCJR+lJVCTJk3CyJEjERYWhnbt2kmTpbi4OAQFBeHnn3/G0qVLlRVekc0b+zXO/hmJFzFvoK+rhb4dG6Jlw6ro8t06AMCK7ecwY5QHIh78hVtRLzGwiwsc7SzQf/IW6TEqWhrD2EAHFa2Moa6mhjrVKgAAHr9IQFpGNh5Fx+P477ewdHIvjFmwFympmZg39mtEPYvD+esPCo1LVQwYPARDB32DLT9vwFfuHREZcRu/HD6AGbP+/iQ/eKgXpk3yQQPnhmjY2AWXLv6BC+d/x6atO5QYecmmq6uHKlWrybRpa2vD0MhI2l7YxHErS+sCd0GSrFUrlqFZi5awsrJCWloaTp88gevXrmLdxs14ER2N06dOoHmLljAyMsKDBw+w7Cc/NGjYENUcC19Ggv72ufftixfROH3yX9d3sR8aOPP6knBKS6C8vb1hamqKFStWYN26dcjNzZ8Ira6uDmdnZwQEBKBPn5K/UKSZiR62zB8MS1MDJKdm4s7Dv9Dlu3UIvpL/qWbNnhBoiTWweGJPGBvqIOLBX+g8eg2evnwtPcbM0R4Y9HUT6fMr+30BAG7D/fFH2EMAgNfMnVg8qQd+WTUaeXkSXAx7iK7ea/H+fV4xnm3JU7NWbSxduRprVi7HzxvWwbqCDSZN8UWnzl2kfdq2+wrTZ83Bts2bsGTRj7C1s8eS5atQv4GzEiMnVZWUlISZ06fidUIC9PT1UbWaI9Zt3IwmTZshNiYGVy5fwp6d25GRkQELSyu0+8oNw78dreywywQNDY3867vrX9d3pIpfX04il4tIIpFIPt9NsXJycvD6dX5CYWpqCg0Njc/s8Wna9cd8ibCoEK+vqPCdKgrGX2EKxIurGEr/61F26WgW35tW++uCa2V9SRm/ls0EtUQspKmhoQErKytlh0FERKR6OAdKLrxqRERERAKViAoUERERKQnnQMmFFSgiIiIigViBIiIiUmWcAyUXJlBERESqjEN4cmHaSURERCQQK1BEREQqrLDvpKXPYwWKiIiISCBWoIiIiFQYK1DyYQWKiIiISCBWoIiIiFQZC1ByYQWKiIiISCBWoIiIiFQY50DJhwkUERGRCmMCJR8O4REREREJxAoUERGRCmMFSj6sQBEREREJxAoUERGRCmMFSj6sQBEREREJxAoUERGRKmMBSi6sQBEREREJxAoUERGRCuMcKPmwAkVERERKt379etSpUwcGBgYwMDCAq6srTp8+Ld2emZkJb29vlC9fHnp6eujZsyfi4uJkjhEdHQ0PDw/o6OjA3NwckydPxvv372X6hISEoEGDBhCLxahSpQoCAgLkipcJFBERkQoTiUQKfRSVjY0NFi1ahLCwMFy/fh1t27ZF165dERkZCQCYMGECjh8/joMHD+L8+fN49eoVevToId0/NzcXHh4eyM7OxqVLl7B9+3YEBARg1qxZ0j5Pnz6Fh4cH2rRpg/DwcIwfPx7Dhw/H2bNnhV83iUQiEbxXCaddf4yyQyizXl9ZrewQyiwW0RWIF1cxytxfj5JDR7P43rQmg/Yo9Pgxm3siKytLpk0sFkMsFn92XxMTEyxZsgS9evWCmZkZ9uzZg169egEA7t+/jxo1aiA0NBRNmjTB6dOn0blzZ7x69QoWFhYAgA0bNmDq1KlISEiApqYmpk6dipMnT+LOnTvS1+jXrx/evn2LM2fOCDovVqCIiIhIYfz8/GBoaCjz8PPz++Q+ubm52LdvH9LS0uDq6oqwsDDk5OSgffv20j7Vq1dHpUqVEBoaCgAIDQ1F7dq1pckTALi7uyMlJUVaxQoNDZU5xoc+H44hBCeRExERqTBFTyL39fWFj4+PTNvHqk8RERFwdXVFZmYm9PT0cOTIETg5OSE8PByampowMjKS6W9hYYHY2FgAQGxsrEzy9GH7h22f6pOSkoKMjAxoa2sX+byYQBEREZHCFHW4DgAcHR0RHh6O5ORkHDp0CJ6enjh//ryCI5QPEygiIiJVVoLmCGpqaqJKlSoAAGdnZ1y7dg3+/v7o27cvsrOz8fbtW5kqVFxcHCwtLQEAlpaWuHr1qszxPtyl988+/75zLy4uDgYGBoKqTwDnQBEREVEJlZeXh6ysLDg7O0NDQwNBQUHSbVFRUYiOjoarqysAwNXVFREREYiPj5f2CQwMhIGBAZycnKR9/nmMD30+HEMIVqCIiIhUWElZSNPX1xcdO3ZEpUqV8O7dO+zZswchISE4e/YsDA0N4eXlBR8fH5iYmMDAwABjx46Fq6srmjRpAgBwc3ODk5MTBg0ahMWLFyM2NhYzZsyAt7e3dAhx1KhRWLNmDaZMmYJhw4YhODgYBw4cwMmTJwXHywSKiIiIlC4+Ph6DBw9GTEwMDA0NUadOHZw9exZfffUVAGDFihVQU1NDz575yyK4u7tj3bp10v3V1dVx4sQJjB49Gq6urtDV1YWnpyfmzZsn7WNvb4+TJ09iwoQJ8Pf3h42NDTZv3gx3d3fB8XIdKBKE60ApTsn4DFhG8eIqRpn761FyFOc6UGZD9yv0+Anb+ir0+MrCChQREZEKKylDeKUNJ5ETERERCcQKFBERkSpjAUourEARERERCcQKFBERkQrjHCj5sAJFREREJFCZrEDFX16l7BDKrFEHbys7hDJrQ+86yg6hzFLnJ2yFyCt7q+CoJFag5MMKFBEREZFAZbICRUREREXDCpR8mEARERGpMCZQ8uEQHhEREZFArEARERGpMhag5MIKFBEREZFArEARERGpMM6Bkg8rUEREREQCsQJFRESkwliBkg8rUEREREQCsQJFRESkwliBkg8TKCIiIlXG/EkuHMIjIiIiEogVKCIiIhXGITz5sAJFREREJBArUERERCqMFSj5sAJFREREJBArUERERCqMFSj5sAJFREREJBArUERERCqMFSj5MIEiIiJSZcyf5MIhPCIiIiKBWIEiIiJSYRzCkw8rUEREREQCsQJFRESkwliBkg8rUEREREQCsQJFRESkwliAkg8rUEREREQCsQJFRESkwjgHSj5MoIiIiFQY8yf5cAiPiIiISCBWoIiIiFQYh/DkwwoUERERkUCsQBEREakwFqDkwwoUERERkUCsQBEREakwNTWWoOTBChQRERGRQKxAERERqTDOgZIPEygiIiIVxmUM5MMhPCIiIiKBWIEqBrm5udi0fg1OnziOxMTXMDUzR5eu3eA1crRM5v/0yWOsWrEMN8KuIfd9Lio7OGDxcn9YWlkrMXrlcTTXhUcNM9iZ6MBYRwMrzz9F2MsU6XYDrXLoV88Ktaz0oaOpjqj4VOy4/hfi3mXLHKeKqQ5617WEg6kO8iTA8zcZWBz8BDm5Emmfutb66F7bAhWNtJGTm4f78WlYeeFZcZ1qiRQfFwf/FUtx6eIFZGZmomLFSpizYCGcatZGTk4O1q32x59/nMfLv15CT08PLk2a4vvxPjAzt1B26CVe2PVrCNi6Bffu3kFCQgJWrFqLtu3aS7dLJBKsW7MKvxw6iHfvUlCvfgP8MGsObG3tlBd0KbR18yas9l+O/gMHY/LU6dL2W+E3sXb1SkRE3Ia6mhqqOdbAuo2boaWlpcRolYcFKPkwgSoG27duxqED+zB3gR8qO1TF3cg7mDdrOvT09NFvwCAAwMsX0RjuOQBfd++Jb78bAz09PTx+9AiammIlR6884nJqiH6bifOPkzC+lX2B7eNb2iFXIsGK80+RkZOHjjXMMK2dA6Ydj0JWbh6A/ORpcpvKOB4Zjx3X/0JuHlDJWAuSv3MnNKxoCC8XGxy8FYu7sdFQE4lgY6Sav0g/SElOxtDB36BhIxesXv8zjI1NEB39DPoGhgCAzMxM3L93F8O//Q7VHB2RkpKCpT8txPix32H3/sNKjr7ky8hIh6OjI7r16AmfcWMKbN+25Wfs3b0T8xcuQoUKNli72h+jR3rhyK+nIBar7u8EISLvRODwof2oWs1Rpv1W+E2MGT0CQ71GYqrvDKirq+NBVBTU1DggQ8IwgSoGt2/dRKs2bdG8ZWsAgHWFCjh7+iQi70RI+6xdvRJNW7TEOJ/J0jabipWKO9QS5fard7j96l2h2yz1NVHVTBfTTtzHX8lZAICAqy+xpqcTmtgZ4fzjJADAAGdr/Bb1Gifuxkv3jX2XJf23mggY1NAa+27GSPcBgFcpf/dRRQFbN8PC0gpzF/hJ2yrY2Ej/ra+vj/U/b5XZZ+r0mRj0TW/ExLyClYpWTYuqeYtWaN6iVaHbJBIJdu/cgRHfjkabtvlVqQV+i9G2ZVMEB51Dx04exRlqqZSenobp0yZh5uz52Lxpvcy2ZUsWoV//QRg2fKS0zc6+cnGHWKJwDpR8mHIXgzp16+Palct4/uwpAOBB1H3cunkDTZu3AADk5eXhzwvnYWtrhzGjhuOrVs3g2b8vQoLPKTPsEq2cev5b95/DcJL/P3c00wUAGIjLoYqpLlIy32OWWxWs6eGEH9o7oNr/twOAnYk2THQ0kSeRYH7HaljdwwmT2tjDxlC1K1DnQ4Lh5FQLU3zGoV2rpvimd3f8cujAJ/dJffcOIpEI+voGxRRl2fTXy5d4/ToBLk2aStv09fVRu05d3L51U4mRlR5+P85Dixat0cS1qUx7UmIiIm7fgomJCTwH9kO7Vs3gNWQgbt4IU1KkVJqV6ATqxYsXGDZs2Cf7ZGVlISUlReaRlVWyqgdDvEbArUMn9OrqAZcGtTGgTw98M3AwOnp0AQAkJSUiPT0dAVs2w7VZc6zZuBlt2rXH5AnfI+z6VSVHXzLFJGfidVo2+tSzgo6mOtTVRPBwMkN5XU0YamsAAMz0NAEA3etY4PdHiVjy+1M8S8rAtHaVYaGfv81cL384pEcdSxy7E4dlIU+Rlp2L6e0doKuprpyTKwH+evkChw7sRUVbW6zdsBm9+vTDkkU/4vixI4X2z8rKgv+KpejQ0QN6enrFHG3Z8vp1AgCgvGl5mfby5cvj9evXygipVDlz+iTu372LseN9Cmx7+fIFAGDj+jXo0bM31m74GTVq1MS3w4fg+fNnxRxpySESiRT6KKtKdAKVlJSE7du3f7KPn58fDA0NZR7LFi8qpgiLJvDsaZw5eQILFi3B7n2HMWeBH3Zt34oTx44CACR5+VWUVm3aYsCgIXCsXgNDvEagecvWOHxgvxIjL7lyJYD/hWew1BdjY+9a2NK3Npws9HDrrxRIkH89Pyyu+/vDRPzx5A2ev8nA7huvEJOShVYOJgD+njz56504XH+RjGdJGfg59AUkABpXMlTCmZUMeXkSVK/hhLHjfFC9hhN69u6L7j1749CBfQX65uTkYOqk8QAA35lzijdQon+IjY3BkkUL8eOipYXOFcuT5M+N7Nm7L7p274nqNZwwaaov7OzscewI5+4pm5+fHxo1agR9fX2Ym5ujW7duiIqKkunTunXrAgnaqFGjZPpER0fDw8MDOjo6MDc3x+TJk/H+/XuZPiEhIWjQoAHEYjGqVKmCgIAAwfEqdQ7Ur7/++sntT548+ewxfH194eMj+0kjGxr/Ka4vbdXypfD0Gg73jvlzF6pUq4aYmFfYtmUTOnftBiNjI6iXKwd7BweZ/ewrV0b4zRvKCLlUeJaUgRmnH0BbQw3l1ER4l5WLOe5V8DQpAwDwNiP/B+av5EyZ/V6lZKG8jub/++T8v8/fVcv3eRIkpGahvK5mcZxGiWRqZobKDlVk2uwrOyDo3G8ybTk5OZg2aQJiXr3Cxi0BrD59AaamZgCAxNeJMDMzl7YnJibCsXp1ZYVVKtyLjERSUiL69+0hbcvNzcWNsOvYv3c3jhw/DQCoXLngezs2JqZYYy1JSkqR6Pz58/D29kajRo3w/v17TJ8+HW5ubrh79y50df+eejFixAjMmzdP+lxHR0f679zcXHh4eMDS0hKXLl1CTEwMBg8eDA0NDSxcuBAA8PTpU3h4eGDUqFHYvXs3goKCMHz4cFhZWcHd3b3I8So1gerWrRtEIhEk/7wl6l8+V/4Ti8UFPmm8y8r7IvF9KZmZGVATyRb71NXUIfn/pyENDU3UrFlLOkfqg+jnzzgZtwgycvKvo4W+JuxNdHDoViwAICEtG0npObAykJ3PZKkvxu1X+cshPE3MQHZuHqwMxHiQkAYAUBcBprqaSEyTXQ5BldSrVx/P/vV+fP5M9v34IXmKjn6OTVu2w8jIuLjDLJMq2NjA1NQMV66EonqNGgCA1NRURNy+hd59v1FydCVb4yZNcPAX2Q/ms2dOh719ZQwZNhw2NhVhZm5e8L39/Bma/X9OqioqKcNsZ86ckXkeEBAAc3NzhIWFoWXLltJ2HR0dWFpaFnqM3377DXfv3sW5c+dgYWGBevXqYf78+Zg6dSrmzJkDTU1NbNiwAfb29li2bBkAoEaNGrh48SJWrFghKIFS6hCelZUVfvnlF+Tl5RX6uHGjbFRfWrRqg60/b8TFCyF49ddf+D0oELt3BqB127/XfRk0ZBgCz5zBkUMH8CL6Ofbv3Y0/zoeo9C9McTk1VDLWQiXj/ATITE8TlYy1UF4nv8LYuJIhqpvrwkxPEw1sDDC1rQPCXibjTmyq9Bin7sbDzdEUjSoawlxPEz3rWMLaQCy94y7zfR6CHyaiRx0L1LLUg6W+GEMa599tdiU6uZjPuOQYMHgI7ty+hS0/b0B09HOcPnkcvxw+gD79BgDIT56m+IzD3cg7+HHREuTm5eL16wS8fp2AnBzVTTyLKj0tDffv3cP9e/cA5E8cv3/vHmJevYJIJMKAQYPx88b1CAkOwsMHUZjhOwVm5uYya0VRQbq6eqhStZrMQ1tbG4ZGRqhStRpEIhE8h3hh356dCPztDKKjn2Ptan88e/oE3Xr0Unb4ZZa8c5WTk/N/B5uYmMi07969G6ampqhVqxZ8fX2Rnp4u3RYaGoratWvDwuLv9ejc3d2RkpKCyMhIaZ/27WV/ltzd3REaGirovJRagXJ2dkZYWBi6du1a6PbPVadKi8m+M7BhjT8W/TgPb5KSYGpmjh69+mDEqO+kfdq0+wq+M2cjYMsmLP1pIWzt7PHTcn/Ua+CsxMiVy95EGz989XepfYBzBQDAH4+TsOnyCxhpa6B/A2sYapXD28z3uPjkDY7eiZM5xtmo19BQV8MAZ2voidUR/SYTPwU/QXzq33/k9914hbw8CUY1rQTNcmp4/DodfkGPkZ6dWzwnWgLVrFUbS1euxpqVy/HzhnWwrmCDSVN80alz/o0PCfFxOB8SDADo16ubzL6btm5Hw0YuxR1yqRIZeQfDhw6WPl+6OH+5iK+7dsf8hYsw1GsEMjIyMG/OLLx7l4L6DZyxbuNmrgH1BQwY5ImsrCwsW7wIySnJqFbNEes3bUVFFV42RtEFKD8/P8ydO1embfbs2ZgzZ85H98nLy8P48ePRrFkz1KpVS9rev39/2NrawtraGrdv38bUqVMRFRWFX375BQAQGxsrkzwBkD6PjY39ZJ+UlBRkZGRAW1u7SOclkigxQ/njjz+QlpaGDh06FLo9LS0N169fR6tWha+X8jElbQivLPnuUMTnO5FcNvSuo+wQyix1tZIxRFHW5OWV/g+4JZWOZvG9ZxvMC1bo8UOnNitQcSps+s0/jR49GqdPn8bFixdh84816P4tODgY7dq1w6NHj+Dg4ICRI0fi+fPnOHv2rLRPeno6dHV1cerUKXTs2BHVqlXD0KFD4evrK+1z6tQpeHh4ID09vcgJlFIrUC1afHrMWVdXV3DyREREREWn6DlQn0uW/m3MmDE4ceIELly48MnkCQBcXPKr3R8SKEtLS1y9Krv8T1xc/sjEh3lTlpaW0rZ/9jEwMChy8gSU8GUMiIiISDVIJBKMGTMGR44cQXBwMOztC36F17+Fh4cDyJ9TDQCurq6IiIhAfPzf3z4RGBgIAwMDODk5SfsEBQXJHCcwMBCurq6C4mUCRUREpMJEIsU+isrb2xu7du3Cnj17oK+vj9jYWMTGxiIjI39pmsePH2P+/PkICwvDs2fP8Ouvv2Lw4MFo2bIl6tTJnwLh5uYGJycnDBo0CLdu3cLZs2cxY8YMeHt7S6tgo0aNwpMnTzBlyhTcv38f69atw4EDBzBhwgRB140JFBERESnd+vXrkZycjNatW8PKykr62L8/f0FpTU1NnDt3Dm5ubqhevTomTpyInj174vjx49JjqKur48SJE1BXV4erqysGDhyIwYMHy6wbZW9vj5MnTyIwMBB169bFsmXLsHnzZkFLGAD8MmEiIiKVVlLWgfrcPW0VK1bE+fPnP3scW1tbnDp16pN9WrdujZs3/9t3S7ICRURERCQQK1BEREQqrIQUoEodJlBEREQqrKQM4ZU2HMIjIiIiEogVKCIiIhXGApR8WIEiIiIiEogVKCIiIhXGOVDyYQWKiIiISCBWoIiIiFQYC1DyYQWKiIiISCBWoIiIiFQY50DJhwkUERGRCmP+JB8O4REREREJxAoUERGRCuMQnnxYgSIiIiISiBUoIiIiFcYKlHxYgSIiIiISiBUoIiIiFcYClHxYgSIiIiISiBUoIiIiFcY5UPJhAkVERKTCmD/Jh0N4RERERAKxAkVERKTCOIQnH1agiIiIiARiBYqIiEiFsQAlH1agiIiIiARiBYqIiEiFqbEEJRdWoIiIiIgEYgWKiIhIhbEAJR8mUERERCqMyxjIh0N4RERERAKxAkVERKTC1FiAkgsrUEREREQCsQJFRESkwjgHSj6sQBEREREJxAoUERGRCmMBSj5lMoESge8GRdnYu46yQyizrj59o+wQyqwmDibKDqFMUuPsY1JhZTKBIiIioqJh0UE+TKCIiIhUGAuJ8uEkciIiIiKBWIEiIiJSYVzGQD6sQBEREREJxAoUERGRCmMBSj6sQBEREREJxAoUERGRClNjCUourEARERERCcQKFBERkQpjAUo+TKCIiIhUGJcxkA+H8IiIiIgEYgWKiIhIhbEAJR9WoIiIiIgEYgWKiIhIhXEZA/mwAkVEREQkEBMoIiIiFSZS8KOo/Pz80KhRI+jr68Pc3BzdunVDVFSUTJ/MzEx4e3ujfPny0NPTQ8+ePREXFyfTJzo6Gh4eHtDR0YG5uTkmT56M9+/fy/QJCQlBgwYNIBaLUaVKFQQEBAiINB8TKCIiIlK68+fPw9vbG5cvX0ZgYCBycnLg5uaGtLQ0aZ8JEybg+PHjOHjwIM6fP49Xr16hR48e0u25ubnw8PBAdnY2Ll26hO3btyMgIACzZs2S9nn69Ck8PDzQpk0bhIeHY/z48Rg+fDjOnj0rKF6RRCKR/PfTLllSs8rcKZUYahwqV5irT98oO4Qyq4mDibJDIBJEqxhnKH+zI1yhx987uJ5c+yUkJMDc3Bznz59Hy5YtkZycDDMzM+zZswe9evUCANy/fx81atRAaGgomjRpgtOnT6Nz58549eoVLCwsAAAbNmzA1KlTkZCQAE1NTUydOhUnT57EnTt3pK/Vr18/vH37FmfOnClyfKxAERERqTA1kWIfWVlZSElJkXlkZWV9Nq7k5GQAgIlJ/gegsLAw5OTkoH379tI+1atXR6VKlRAaGgoACA0NRe3ataXJEwC4u7sjJSUFkZGR0j7/PMaHPh+OUeTrJqg3ERERkQB+fn4wNDSUefj5+X1yn7y8PIwfPx7NmjVDrVq1AACxsbHQ1NSEkZGRTF8LCwvExsZK+/wzefqw/cO2T/VJSUlBRkZGkc+LyxgQERGpMEV/lYuvry98fHxk2sRi8Sf38fb2xp07d3Dx4kVFhvafMIEiIiIihRGLxZ9NmP5pzJgxOHHiBC5cuAAbGxtpu6WlJbKzs/H27VuZKlRcXBwsLS2lfa5evSpzvA936f2zz7/v3IuLi4OBgQG0tbWLHCeH8IiIiFSYSKTYR1FJJBKMGTMGR44cQXBwMOzt7WW2Ozs7Q0NDA0FBQdK2qKgoREdHw9XVFQDg6uqKiIgIxMfHS/sEBgbCwMAATk5O0j7/PMaHPh+OUVSsQBEREZHSeXt7Y8+ePTh27Bj09fWlc5YMDQ2hra0NQ0NDeHl5wcfHByYmJjAwMMDYsWPh6uqKJk2aAADc3Nzg5OSEQYMGYfHixYiNjcWMGTPg7e0trYKNGjUKa9aswZQpUzBs2DAEBwfjwIEDOHnypKB4mUARERGpMEXPgSqq9evXAwBat24t075t2zYMGTIEALBixQqoqamhZ8+eyMrKgru7O9atWyftq66ujhMnTmD06NFwdXWFrq4uPD09MW/ePGkfe3t7nDx5EhMmTIC/vz9sbGywefNmuLu7C4qX60CRIFwHSnG4DpTicB0oKm2Kcx2owXtuK/T4O/rXUejxlYUVKCIiIhXGD8byYQJFRESkwkrKEF5pw7vwiIiIiARiBYqIiEiFsf4kH1agiIiIiASSK4H6448/MHDgQLi6uuKvv/4CAOzcubNEL7lOREREBamJRAp9lFWCE6jDhw/D3d0d2trauHnzpvQblZOTk7Fw4cIvHiARERFRSSM4gVqwYAE2bNiAn3/+GRoaGtL2Zs2a4caNG180OCIiIlKskvJVLqWN4AQqKioKLVu2LNBuaGiIt2/ffomYiIiIiEo0wQmUpaUlHj16VKD94sWLqFy58hcJioiIiIqHSCRS6KOsEpxAjRgxAuPGjcOVK1cgEonw6tUr7N69G5MmTcLo0aMVESMRERFRiSJ4Hahp06YhLy8P7dq1Q3p6Olq2bAmxWIxJkyZh7NixioiRiIiIFKQMF4kUSnACJRKJ8MMPP2Dy5Ml49OgRUlNT4eTkBD09PUXEVyZ07tAWMa9eFWjv3bc/pv0wS/pcIpHg++9G4tKff2DpyjVo07Z9cYZZ6m3dvAmr/Zej/8DBmDx1OgBgwdxZuHI5FAkJ8dDW0UHduvUxbsIk2HO4uYDM9DQc270J4Zcv4F1yEipWroa+IybArqpT/vaMdBzZvg7hVy4g7V0yTC2s0aZzb7Tq2EPmOI/vR+DYzo14+iASampqsLGvhnFzV0BTrKWM0yqRwq5fQ8DWLbh39w4SEhKwYtVatG2X//Oek5ODNatW4uIfF/Dy5Qvo6+nBxbUpxk2YCHNzCyVHXvLx2gpXlpcaUCS5VyLX1NSEk5PTl4ylzNq55xBy83Klzx8/eojvRg5Dezd3mX57dm0v0+PFihR5JwKHD+1H1WqOMu01nGqio0cXWFlZITk5GRvWr8F333rhxJlzUFdXV1K0JdOONX549fwJhk6YBSMTU1wJOYsVM7/HnLV7YFzeHAe3rELU7esY5jMH5c2tcPfmFezdsBRGJmao69ICQH7ytGrOBHTsNRj9vvWBmpo6Xj57CJEa1+z9p4yMdDg6OqJbj57wGTdGZltmZibu37uLkaNGw9GxOlJSUvCT348YN2Y09h74RUkRlx68tlRcBCdQbdq0+eQf+eDg4P8UUFlkbGIi8zxgy8+wqVgJzg0bS9ui7t/Dru3bsHPfIbi3bVHcIZZq6elpmD5tEmbOno/Nm9bLbOvZu6/039YVbOA9Zjz69uqKV6/+QsWKlYo71BIrOysTNy+F4LsffkK1WvUBAF36D8ftaxdx/vQRdBv4LZ7cj4Br205wrN0AANCyQzf8cfYonj68K02gDm72R9vOvdGh12DpsS1tbIv/hEq45i1aoXmLVoVu09fXx8bN22TafH+YiQH9eiPm1StYWVsXR4ilFq+tcPzcLh/BHwvr1auHunXrSh9OTk7Izs7GjRs3ULt2bUXEWKbk5GTj1Mlf0bVbD2kimpGRgR+mTcLUH2bB1NRMyRGWPn4/zkOLFq3RxLXpJ/tlpKfj16O/oEIFG1haWhZTdKVDXm4u8vJyUU5TU6ZdQ1OMx3dvAQAqV6+NW1cv4k1iPCQSCaJuhyHu1Qs41cv/IJDyNglPH0RC38gEP00ZgUmDOmGp72g8+v/+JL/U1FSIRCLoGxgoO5Qyh9eW5CW4ArVixYpC2+fMmYPU1NT/HFBZ93twEFLfvUOXrt2lbcuX+KFO3fpo3aadEiMrnc6cPon7d+9i175DH+1zYN8erFy+FBkZ6bCzs8f6n7dCQ0Pzo/1VkZaOLipXr4VT+7fBysYOBkYmuHohEE+i7sDcygYA0O9bH+xaswjThnaFmro61ERqGDhmmrRi9To2f57fib2b0XPoWFS0r4rLv5/GihljMWvNblhYV1Ta+ZVmWVlZWLl8KTp28uBc0y+M1zYfp47I54tNTBg4cCC2bt0qeL+MjAxcvHgRd+/eLbAtMzMTO3bs+OT+WVlZSElJkXl8+HqZkujYkUNo2qwFzP4/YfH878G4dvUKJk31VXJkpU9sbAyWLFqIHxcthVgs/mi/jh5dsPfgL9i8bScq2dlh6sTxJfo9oizDJsyGRCLB1KFfw7tnK/x+4gAatfhK+sv19xMH8fRBJL6bsRg/LA9Ar2FjsXfjMtwLvwoAkEjyAAAt3LuhWfvOqOTgiD7Dx8OiQiVcCjyutPMqzXJycjDZZxwkEgl+mDVX2eGUKby29F99sQQqNDQUWlrC7rJ58OABatSogZYtW6J27dpo1aoVYmJipNuTk5MxdOjQTx7Dz88PhoaGMo9li/3kOgdFi3n1F65eDkW3nr2lbdeuXsbLF9Fo3awxGtevicb1awIApvh8j5HDBikr1FLhXmQkkpIS0b9vDzSsVxMN69VE2PVr2Lt7JxrWq4nc3PyJ+/r6+rC1tYNzw0ZYutwfT589RXBQoJKjL3nMrGwwyW89Vh0IxqKtR+G7bCtyc9/D1LICsrMycXTnBvQe9j3qNm4BG/sqaNO5Nxo2b4ffjuwBABgamwIArCrayxzXsqIdkl7HFfv5lHY5OTmYPHE8Yl69wsbNW1W6QvKl8drKUlPwo6wSPITXo4fsLcsSiQQxMTG4fv06Zs6cKehYU6dORa1atXD9+nW8ffsW48ePR7NmzRASEoJKlYo2wdfX1xc+Pj4ybTkomcMzvx79BcYm5WUmOA7xGoFuPXrJ9Ovb82v4TJ6Glq3aFneIpUrjJk1w8JdfZdpmz5wOe/vKGDJseKF32Ukk+f+Vk51dTFGWPmItbYi1tJGWmoK7N6+gh6c3cnNzkfv+fYG76dTU1CCRSAAA5S2sYGRiiri/nsv0if8rGjWdXYst/rLgwx/46OfPsXnbDhgZGSs7pDKD15a+FMEJlKGhocxzNTU1ODo6Yt68eXBzcxN0rEuXLuHcuXMwNTWFqakpjh8/ju+++w4tWrTA77//Dl1d3c8eQywWFxi+Sc2SCIqjOOTl5eHXY0fQ+etuKFfu78tuampW6MRxSytrVLCxKc4QSx1dXT1UqVpNpk1bWxuGRkaoUrUaXr54gbNnT8HVtRmMTUwQFxeLbVt+hlgs/uhdOqos8sZlSCQSWFawRXzMSxwOWAPLCrZo1r4z1MuVQ7Va9XF42xpoaIpR3swSDyJv4vLvp9F72DgA+fMovuo+AMf3boaNfVVUtK+K0OBTiP3rOb6dtlDJZ1eypKelITo6Wvr8r5cvcf/ePRgaGsLUzAyTJnyPe/fuYvXajcjLzcXrhAQA+b9/NTRL5gfEkoLXVjjOgZKPoAQqNzcXQ4cORe3atWFs/N+z9oyMDJlkQiQSYf369RgzZgxatWqFPXv2/OfXKCmuXL6E2JhX6Nqtx+c70xehKdbEzbAw7Nm5AykpKShfvjwaODdEwM69MClfXtnhlTgZ6ak4smMD3r6Oh46+ARq4tka3QaOg/v+f0eGT5+PIjvXYumw20lJTYGJmia4DR6Flx79viGjftR/e52Tj4BZ/pL1LgY19FYyftwpmVvww8E+RkXcwfOjfSz0s/f+0g6+7dsco7zEI+T1/OZg+PbvK7Ld52w40auxSfIGWQry2wqkxf5KLSPKh/l5EWlpauHfvHuzt7T/f+TMaN26MsWPHYtCggnN9xowZg927dyMlJUU6l6WoSmIFqqzgD5riXH36RtkhlFlNHEw+34moBNGSe5lr4cYfu6/Q46/sWl2hx1cWwfO7atWqhSdPnnyRF+/evTv27t1b6LY1a9bgm2++gcD8joiIiARQEyn2UVYJrkCdOXMGvr6+mD9/PpydnQvMUzIoAYuRsQKlOGX5h0HZWIFSHFagqLQpzgqUz6+KrUAt/7psVqCK/H/RvHnzMHHiRHTq1AkA8PXXX8tMPJNIJBCJRIKH24iIiEh5OIlcPkVOoObOnYtRo0bh999/V2Q8RERERCVekROoDyN9rVrx9m8iIqKyglMz5CNoEjnLfEREREQC14GqVq3aZ5OopKSk/xQQERERFR/WRuQjKIGaO3dugZXIiYiIqPRSYwYlF0EJVL9+/WBubq6oWIiIiIhKhSInUJz/REREVPYIXlGbAAi4blwRnIiIiChfkStQeXl5ioyDiIiIlIADTPJh5Y6IiIhIoGL8th0iIiIqaXgXnnxYgSIiIiISiBUoIiIiFcYClHyYQBEREakwfheefDiER0RERCQQK1BEREQqjJPI5cMKFBEREZFArEARERGpMBag5MMKFBEREZFArEARERGpMN6FJx9WoIiIiIgEYgWKiIhIhYnAEpQ8mEARERGpMA7hyYdDeEREREQCsQJFRESkwliBkg8rUEREREQCsQJFRESkwkRcSVMurEARERFRiXDhwgV06dIF1tbWEIlEOHr0qMz2IUOGQCQSyTw6dOgg0ycpKQkDBgyAgYEBjIyM4OXlhdTUVJk+t2/fRosWLaClpYWKFSti8eLFgmNlAkVERKTC1ESKfQiRlpaGunXrYu3atR/t06FDB8TExEgfe/fuldk+YMAAREZGIjAwECdOnMCFCxcwcuRI6faUlBS4ubnB1tYWYWFhWLJkCebMmYNNmzYJipVDeERERFQidOzYER07dvxkH7FYDEtLy0K33bt3D2fOnMG1a9fQsGFDAMDq1avRqVMnLF26FNbW1ti9ezeys7OxdetWaGpqombNmggPD8fy5ctlEq3PYQWKiIhIhYlEin1kZWUhJSVF5pGVlSV3vCEhITA3N4ejoyNGjx6NxMRE6bbQ0FAYGRlJkycAaN++PdTU1HDlyhVpn5YtW0JTU1Pax93dHVFRUXjz5k2R42ACRUREpMLURCKFPvz8/GBoaCjz8PPzkyvWDh06YMeOHQgKCsJPP/2E8+fPo2PHjsjNzQUAxMbGwtzcXGafcuXKwcTEBLGxsdI+FhYWMn0+PP/Qpyg4hEdEREQK4+vrCx8fH5k2sVgs17H69esn/Xft2rVRp04dODg4ICQkBO3atftPcQrFBIqIiEiFKXohTbFYLHfC9DmVK1eGqakpHj16hHbt2sHS0hLx8fEyfd6/f4+kpCTpvClLS0vExcXJ9Pnw/GNzqwrDITwiIiIqlV6+fInExERYWVkBAFxdXfH27VuEhYVJ+wQHByMvLw8uLi7SPhcuXEBOTo60T2BgIBwdHWFsbFzk12YCRUREpMIUPYlciNTUVISHhyM8PBwA8PTpU4SHhyM6OhqpqamYPHkyLl++jGfPniEoKAhdu3ZFlSpV4O7uDgCoUaMGOnTogBEjRuDq1av4888/MWbMGPTr1w/W1tYAgP79+0NTUxNeXl6IjIzE/v374e/vX2CY8XOYQBEREVGJcP36ddSvXx/169cHAPj4+KB+/fqYNWsW1NXVcfv2bXz99deoVq0avLy84OzsjD/++ENmiHD37t2oXr062rVrh06dOqF58+YyazwZGhrit99+w9OnT+Hs7IyJEydi1qxZgpYwAACRRCKRfJnTLjlSs8rcKZUY/NJJxbn6tOi3z5IwTRxMlB0CkSBaxThDee2fzxR6fO9mdgo9vrKUyUnk/COvOGq8uArTuHLRx95JmNjkTGWHUCZZGmopOwQipSmTCRQREREVDb9LWD5MoIiIiFQYBxbkw0nkRERERAKxAkVERKTC1DiGJxdWoIiIiIgEYgWKiIhIhbEAJR9WoIiIiIgEYgWKiIhIhXEOlHxYgSIiIiISiBUoIiIiFcYClHyYQBEREakwDkXJh9eNiIiISCBWoIiIiFSYiGN4cmEFioiIiEggVqCIiIhUGOtP8mEFioiIiEggVqCIiIhUGBfSlA8rUEREREQCsQJFRESkwlh/kg8TKCIiIhXGETz5cAiPiIiISCBWoIiIiFQYF9KUDytQRERERAKxAkVERKTCWEmRD68bERERkUCsQBEREakwzoGSDytQRERERAKxAkVERKTCWH+SDytQRERERAKxAkVERKTCOAdKPkygiIiIVBiHouTD60ZEREQkECtQREREKoxDePJhBYqIiIhIIFagiIiIVBjrT/JhBYqIiIhIIFagiIiIVBinQMmHFSgiIiIigViBIiIiUmFqnAUlFyZQREREKoxDePLhEJ4SbN28CfVrV8eSnxbKtN8Kv4mRXp5wbVwfzZs4Y5jnQGRmZiopytIh7Po1jP1uFNq3bo66NR0RHHROZrtEIsHa1f5o16o5Gjeog5FeQ/D8+TPlBFvKHNi3F326f43mLs5o7uKMwQP64uIfFwAAyclvsWjhfHTr3AFNnOuiY/s2+GnhArx7907JUZd8+3dsgXvTuli/crG0zf+neRjSywNdWjdGn06tMXvKOEQ/eyqzX3xsDGZOHIOv27igT6fW+HnNcuS+f1/c4Zc669euRt2ajjKPrp07KDssKgNYgSpmkXcicPjQflSt5ijTfiv8JsaMHoGhXiMx1XcG1NXV8SAqCmpqzHE/JSMjHY6OjujWoyd8xo0psH3blp+xd/dOzF+4CBUq2GDtan+MHumFI7+eglgsVkLEpYeFpQXGTpiISra2gESC48eOYsJYb+w79AskEgkS4uMxYdIUVK5cBTExr/DjvNlISIjH0hWrlB16iRV19w5OHjsE+yrVZNqrOjqhrZsHzCwt8S4lBbu2rMf0CaOw/dApqKurIzc3FzMnjYFxeVOs2LgdSYmvsWT+DKiXK4dho75X0tmUHg5VqmLT5m3S5+rl1JUYTckj4hCeXJhAFaP09DRMnzYJM2fPx+ZN62W2LVuyCP36D8Kw4SOlbXb2lYs7xFKneYtWaN6iVaHbJBIJdu/cgRHfjkabtu0BAAv8FqNty6YIDjqHjp08ijPUUqdV67Yyz8eMm4CD+/fh9q1b6N6zF5atXC3dVrFSJYz5fgJ+mDYZ79+/R7ly/NXybxnp6fhpri/GT5uNvQE/y2zr1K2X9N+WVhXgOXIMRg/ujbiYV7C2qYgbV0MR/ewJFq3aBGOT8nAAMHjEd9iyzh+DvEZDQ0OjmM+mdCmnrg5TMzNlh0FlDMsbxcjvx3lo0aI1mrg2lWlPSkxExO1bMDExgefAfmjXqhm8hgzEzRthSoq0bPjr5Uu8fp0AlyZ/X299fX3UrlMXt2/dVGJkpU9ubi7OnDqJjIx01KlXr9A+7969g66eHpOnj1izbCEaN22JBo2afLJfZkY6fjt5DJbWFWBmYQkAuHvnFuwcqsLYpLy0X0OXpkhPS8XzJ48UGndZ8Dz6Odq3bo5O7u3gO2UiYl69UnZIJYpIpNhHWaX033T37t3D5cuX4erqiurVq+P+/fvw9/dHVlYWBg4ciLZt235y/6ysLGRlZcm05Yo0S9zwzJnTJ3H/7l3s2neowLaXL18AADauX4MJE6fAsXoNnPj1GL4dPgQHjxyHra1dMUdbNrx+nQAAKG9aXqa9fPnyeP36tTJCKnUePoiC54BvkJ2dBW0dHSzzXwMHhyoF+r158wY/b1yPnr36KCHKki8k8DQeRd3D6i17Ptrn+OH92LxuBTIzMmBTyQ5+KzdKK0tvEhNhbGwi09/o/8nUm6RExQVeBtSuUwfzf/SDnZ09EhISsHH9WgwdPACHjx2Hrq6essOjUkypFagzZ86gXr16mDRpEurXr48zZ86gZcuWePToEZ4/fw43NzcEBwd/8hh+fn4wNDSUeSxd7FdMZ1A0sbExWLJoIX5ctLTQxC5PkgcA6Nm7L7p274nqNZwwaaov7OzscezI4eIOl0jKzt4e+w4fwY49+9G7Tz/M+mEaHj+WrXikpqbi++++RWUHB3z7XcF5aKouPi4W61cuxtQ5ftD8xAe7tu6dsC5gP5au3QqbSrb4ceZkZP/rwyEJ17xFK7i5d0Q1x+po1rwF1qzfhHfvUnD2zGllh1ZiqEGk0EdZpdQK1Lx58zB58mQsWLAA+/btQ//+/TF69Gj8+OOPAABfX18sWrTok1UoX19f+Pj4yLTlijQVGrdQ9yIjkZSUiP59e0jbcnNzcSPsOvbv3Y0jx/N/kCtXlv1kb1/ZAbExMcUaa1liapo/5yHxdSLMzMyl7YmJiXCsXl1ZYZUqGhqaqFTJFgDgVLMWIiPvYO+uHZgxex4AIC0tFd7fDoeOri6W+6/hXJxCPLp/F2/fJMF7aD9pW15uLiLCw/Dr4X04EXIN6urq0NXTh66ePipUtEX1WnXQ0705/jwfjDZuHWFcvjyi7t2ROe7b/1ee/jmsR59nYGAAW1s7vIiOVnYoVMopNYGKjIzEjh07AAB9+vTBoEGD0KvX35MpBwwYgG3btn1sdwCAWCwuUNVJz5Z8+WD/g8ZNmuDgL7/KtM2eOR329pUxZNhw2NhUhJm5OZ7967bl58+foVnzFsUZaplSwcYGpqZmuHIlFNVr1ACQXy2JuH0Lvft+o+ToSidJXh6ys7MB5F/L7771gqaGJlauXlfihs1LinoNXbBxp+zQ/bIfZ6OirR36DBwKdfWCd4RJJBJAAuTk5F9rp1p1sW/7ZrxNSpQO3d24ehk6unqoZO+g+JMoQ9LT0vDixQt4fM1J5R+U5XlKiqT0OVCi//8/p6amBi0tLRgaGkq36evrIzk5WVmhfTG6unqoUlX2tmVtbW0YGhlJ2z2HeGHDutWo5ugIx+o1cPzYUTx7+gRLlvsrI+RSIz0tDdH/+CT518uXuH/vHgwNDWFlbY0Bgwbj543rYVvJFhVs8pcxMDM3R9t27ZUYdemwasUyNGvRElZWVkhLS8Ppkydw/dpVrNu4OT95GumFzIwM/Oi/BGlpqUhLSwUAGBubFJoUqCodXV3YOVSVadPS1oa+oRHsHKoi5q+XOB90Fs6NXWFoZIyEhDgc2LkVmmIxGrs2BwA0aOyKSnaVsXjeD/DynoA3ia8RsGkNuvTsC03NklVxL2mWLfkJrVq3gZW1NRLi47F+7Wqoq6uhY6fOyg6txGACJR+lJlB2dnZ4+PAhHBzyP0GFhoaiUqVK0u3R0dGwsrJSVnjFasAgT2RlZWHZ4kVITklGtWqOWL9pKypWrPT5nVVYZOQdDB86WPr8w/y3r7t2x/yFizDUawQyMjIwb84svHuXgvoNnLFu42ZWS4ogKSkJM6dPxeuEBOjp66NqNUes27gZTZo2w/WrVxBx+xYA4OtObjL7nTx7DtYVbJQRcqmkqamJO7du4Mj+XUh9lwIjk/KoXc8ZKzbukFab1NXVMW/Jaqxe+iMmjBwMLW1ttO/YBZ7Dv1Ny9CVfXFwspk32wdu3b2FsYoL6DZyxc88BmJiYfH5nok8QSSQSpY13bdiwARUrVoSHR+Hr8UyfPh3x8fHYvHmzoOOWtCG8skRNjR9VFCVPeT+KZV58CidjK4KloZayQyiztIqxvBF4T7F3JX9Vw1Shx1cWpSZQisIESnGYQCkOEyjFYQKlGEygFIcJVMnHhTSJiIhUmJpIsQ8hLly4gC5dusDa2hoikQhHjx6V2S6RSDBr1ixYWVlBW1sb7du3x8OHD2X6JCUlYcCAATAwMICRkRG8vLyQmpoq0+f27dto0aIFtLS0ULFiRSxevBhCMYEiIiKiEiEtLQ1169bF2rVrC92+ePFirFq1Chs2bMCVK1egq6sLd3d3ZGZmSvsMGDAAkZGRCAwMxIkTJ3DhwgWMHPn316SlpKTAzc0Ntra2CAsLw5IlSzBnzhxs2rRJUKwcwiNBOISnOBzCUxwO4SkGh/AUpziH8ILvK3Y1+7bV5VurTCQS4ciRI+jWrRuA/OqTtbU1Jk6ciEmTJgEAkpOTYWFhgYCAAPTr1w/37t2Dk5MTrl27hoYNGwLIX7S7U6dOePnyJaytrbF+/Xr88MMPiI2Nld7FOm3aNBw9ehT3798vcnysQBEREZHCZGVlISUlRebx769gK4qnT58iNjYW7dv/vQyNoaEhXFxcEBoaCiD/bn4jIyNp8gQA7du3h5qaGq5cuSLt07JlS5klQNzd3REVFYU3b94UOR4mUERERCpM0V8mXNhXrvn5Cf/KtdjYWACAhYWFTLuFhYV0W2xsLMzNzWW2lytXDiYmJjJ9CjvGP1+jKJS+kCYREREpj0jB31dX2FeulYW1+JhAERERkcIU9pVr8rC0tAQAxMXFySyyHRcXh3r16kn7xMfHy+z3/v17JCUlSfe3tLREXFycTJ8Pzz/0KQoO4REREamwkrSMwafY29vD0tISQUFB0raUlBRcuXIFrq6uAABXV1e8ffsWYWFh0j7BwcHIy8uDi4uLtM+FCxeQk5Mj7RMYGAhHR0cYGxsXOR4mUERERFQipKamIjw8HOHh4QDyJ46Hh4cjOjoaIpEI48ePx4IFC/Drr78iIiICgwcPhrW1tfROvRo1aqBDhw4YMWIErl69ij///BNjxoxBv379YG1tDQDo378/NDU14eXlhcjISOzfvx/+/v4Fhhk/h8sYkCBcxkBxuIyB4nAZA8XgMgaKU5zLGPzxoOh3nsmjRbWiV3VCQkLQpk2bAu2enp4ICAiARCLB7NmzsWnTJrx9+xbNmzfHunXrUK1aNWnfpKQkjBkzBsePH4eamhp69uyJVatWQU9PT9rn9u3b8Pb2xrVr12BqaoqxY8di6tSpgs6LCRQJwgRKcZhAKQ4TKMVgAqU4qppAlSacRE5ERKTCRPxcLBfOgSIiIiISiBUoIiIiFcYClHyYQBEREakwNY7hyYVDeEREREQCsQJFRESkwlh/kg8rUEREREQCsQJFRESkyliCkgsrUEREREQCsQJFRESkwkQsQcmFFSgiIiIigViBIiIiUmFcBko+TKCIiIhUGPMn+XAIj4iIiEggVqCIiIhUGUtQcmEFioiIiEggVqCIiIhUGJcxkA8rUEREREQCsQJFRESkwriMgXxYgSIiIiISiBUoIiIiFcYClHyYQBEREakyZlBy4RAeERERkUCsQBEREakwLmMgH1agiIiIiARiBYqIiEiFcRkD+bACRURERCQQK1BEREQqjAUo+ZTJBErEeqTCSCTKjqDsUuP7VmEsDbWUHUKZdOt5srJDKLNcHAyVHQJ9RplMoIiIiKiI+NlNLkygiIiIVBiXMZAPJ5ETERERCcQKFBERkQrj9Ev5sAJFREREJBArUERERCqMBSj5sAJFREREJBArUERERKqMJSi5sAJFREREJBArUERERCqM60DJhxUoIiIiIoFYgSIiIlJhXAdKPkygiIiIVBjzJ/lwCI+IiIhIIFagiIiIVBlLUHJhBYqIiIhIIFagiIiIVBiXMZAPK1BEREREArECRUREpMK4jIF8WIEiIiIiEogVKCIiIhXGApR8mEARERGpMmZQcuEQHhEREZFArEARERGpMC5jIB9WoIiIiEjp5syZA5FIJPOoXr26dHtmZia8vb1Rvnx56OnpoWfPnoiLi5M5RnR0NDw8PKCjowNzc3NMnjwZ79+/V0i8rEARERGpsJK0jEHNmjVx7tw56fNy5f5OUyZMmICTJ0/i4MGDMDQ0xJgxY9CjRw/8+eefAIDc3Fx4eHjA0tISly5dQkxMDAYPHgwNDQ0sXLjwi8fKBIqIiIhKhHLlysHS0rJAe3JyMrZs2YI9e/agbdu2AIBt27ahRo0auHz5Mpo0aYLffvsNd+/exblz52BhYYF69eph/vz5mDp1KubMmQNNTc0vGiuH8IiIiFSYSMGPrKwspKSkyDyysrIKjeXhw4ewtrZG5cqVMWDAAERHRwMAwsLCkJOTg/bt20v7Vq9eHZUqVUJoaCgAIDQ0FLVr14aFhYW0j7u7O1JSUhAZGfkFrpQsJlBERESkMH5+fjA0NJR5+Pn5Fejn4uKCgIAAnDlzBuvXr8fTp0/RokULvHv3DrGxsdDU1ISRkZHMPhYWFoiNjQUAxMbGyiRPH7Z/2PalcQiPiIhIlSl4DpSvry98fHxk2sRicYF+HTt2lP67Tp06cHFxga2tLQ4cOABtbW3FBikHVqCIiIhUmEjB/xGLxTAwMJB5FJZA/ZuRkRGqVauGR48ewdLSEtnZ2Xj79q1Mn7i4OOmcKUtLywJ35X14Xti8qv+KCRQRERGVOKmpqXj8+DGsrKzg7OwMDQ0NBAUFSbdHRUUhOjoarq6uAABXV1dEREQgPj5e2icwMBAGBgZwcnL64vFxCI+IiEiFlZRlDCZNmoQuXbrA1tYWr169wuzZs6Guro5vvvkGhoaG8PLygo+PD0xMTGBgYICxY8fC1dUVTZo0AQC4ubnByckJgwYNwuLFixEbG4sZM2bA29u7SBUvoZhAERERkdK9fPkS33zzDRITE2FmZobmzZvj8uXLMDMzAwCsWLECampq6NmzJ7KysuDu7o5169ZJ91dXV8eJEycwevRouLq6QldXF56enpg3b55C4hVJJBKJQo6sRBk5yo6ASLiS8imQqKhuPU9WdghllouDYbG91rPXmQo9vp2plkKPryycA0VEREQkEIfwiIiIVBmr33JhBYqIiIhIIFagiIiIVJiIJSi5MIEiIiJSYbyBRT5MoIrBlp83Iujcb3j29AnEWlqoW68+xk+YBDv7yjL9boXfxJpVKxARcRvqampwrF4D6zZugZZW2byD4UsIu34N27dtwb27d5CQkIDl/mvRtt3fXzaZ+Po1Vq5YisuXLuLdu3do4NwQU6fPhK2tnfKCLiXCrl9DwNa/r+2KVbLXdv3a1Thz+iRiY2OhoaEBJ6eaGDNuAurUqavEqEu3fXt2Y/u2LXj9OgHVHKtj2vSZqF2njrLDKrHycnPxy+6fcen300h+kwRjE1M0b98ZXb8ZBtH/s4LBnRoXum/fYWPh0WsQEuJe4djeLbh767r0GE3bdsTXfYeinIZGcZ4OlTJMoIpB2PWr6PvNANSsVRu573Ox2n85Ro/0wi/HTkJbRwdAfvLkPWo4hg3/FlOnz0Q5dXVERd2HmhqnqX1KRkY6qjk6olv3nvAZP0Zmm0QiwYRx3ihXrhxWrFoHPT097NwRgFHDh8pceypcRkY6HB0d0a1HT/iMG1Ngu62tHXx/mAUbm4rIzMrErh0BGD1iGI6fDoSJiYkSIi7dzpw+haWL/TBj9lzUrl0Xu3dux+hvvXDsxBmUL19e2eGVSCcO7UDwqcMY6TMbFWwr4+nDe9i8Yj50dPXg1rUvAGDVrlMy+9y+Hoot/gvQqFlbAEDMi+eQ5EkwdKwvLKwq4uXzx9i6aiGyMjPwzfBxxX5OysAClHy4DpQSJCUloW1LV2wJ2AXnho0AAIP690ET16bwHjteucGVYvVqOcpUoJ4/e4qunTvg0NETqFKlKgAgLy8P7Vo3w9jvfdCjV29lhltASS6j163pWKAC9W+pqalo5uKMTVsC4NLEtRijKxsG9OuNmrVqY/qMWQDy36tu7Vrhm/6D4DVipJKjK5yy14FaNnsCDI1NMHz8TGnbqgVToSkWY9TkwhdPXDlvEjIz0jHNb12h2wHg5KGdCD51GMu2Hv3SIRdZca4D9SIpS6HHr2jy5VcBLwlKXHmjDOZzBaSmvgMAGBrm/4AkJSYi4vYtmJiUx+AB/dC2ZVN4DRmImzeuKzPMUi87OxsAINb8+4dXTU0NmhqauHkzTFlhlUk52dk4fHA/9PX1Uc3RUdnhlDo52dm4dzcSTVybStvU1NTQpElT3L51U4mRlWxVnergbvh1xLx8DgCIfvIAD+7eQp2GTQvtn/wmEbeu/YmWbl9/8rgZaanQ1TP44vGWVCKRYh9lVYlLoMRiMe7du6fsMBQmLy8PSxYtRL36DVClajUAwMuXLwAAG9atQY9evbFu42ZUr+GEkV5D8Pz5MyVGW7rZ2VeGlZU1VvkvQ0pyMnJysrFtyybExcXidUKCssMrE86H/I4mDeujUYM62LkjABt+3gpjYw7fCfXm7Rvk5uYWGKorX748Xr9+raSoSr7OvT3h0uorTPu2D4Z2ccXMsYPg3rUfmrbpUGj/i+dOQktbFw2btfnoMeNevUDg8QNo06mHosKmMkJpc6B8fHwKbc/NzcWiRYukv0iWL1/+yeNkZWUhK0u2/JinJlbIFwd+CX4L5uLRo4cI2LFH2paXlwcA6Nm7L7p17wkAqF7DCVcvh+LYL4fx/YSJSom1tNPQ0MCylasxZ9YPaNmsMdTV1eHSxBXNWrQEVKDSWRwaNXbBgcNH8fbtGxw+dACTJ47Hrr0HOWeHisXVP84h9PczGD1lPipUqozoJw+wa9NyGJU3RYv2nQv0vxB4HK5t3KGpWfjfh6TX8VgycxwaN2+HNh26KTj6kqQMl4kUSGkJ1MqVK1G3bl0YGRnJtEskEty7dw+6urrSuyg+xc/PD3PnzpVpmz5jNmbMmvMFo/0y/H6chwvnQ7B1+y5YWFpK2z98UaKDg4NMf/vKDoiJfVWsMZY1TjVr4cDhY3j37h1ycnJgYmKCgd/0hlPNWsoOrUzQ0dFBJVtbVLK1RZ269dCloxuO/nIIXiO+VXZopYqxkTHU1dWRmJgo056YmAhTU1MlRVXy7duyCp17e6JJKzcAQEX7KngdH4MTB7YXSKCi7txEzMvn8J72Y6HHepOYAL9po1G1Rm0M/X66wmOn0k9pCdTChQuxadMmLFu2DG3btpW2a2hoICAgAE5OTkU6jq+vb4FqVp5ayao+SSQSLFo4H8FBgdi8bScq2FSU2W5dwQZm5uZ49uypTPvz58/QrHnL4gy1zNLX1weQf03vRt7Bd2NU4+6a4pYnyZPOPaOi09DURA2nmrhyOVQ6UT8vLw9XroSi3zcDlRxdyZWVlQmRmuwHbTU1dWlV/5/O//Yr7KpUR6XK1QpsS3odD79po2FftQZGTJilcnc/l+V5SoqktARq2rRpaNeuHQYOHIguXbrAz88PGnKsuSEWFxyuK2l34S1cMBenT53AylXroKuri9ev8+ff6OnpQ0tLCyKRCJ5DvbBh7WpUc6wOx+o1cPzYETx7+gRLl69ScvQlW3p6GqKjo6XP//rrJe7fvwdDQ0NYWVnjt7OnYWxsAisrazx8GIXFixaiTdv2aNqsuRKjLh3S0/51bV++xP17+dfW0MgImzdtQOs2bWFqZoa3b95g397diI+Lw1fuhc8/oU8b5DkUM6dPRc2atVCrdh3s2rkdGRkZ6Nadc3E+pr5LC/y6LwDlzSxRwbYynj+Owpkje9DSrYtMv4z0VFz9Iwj9C1mW4EPyVN7cEv28vkdK8hvpNiMT1aj+MX+Sj9KXMUhNTYW3tzfCw8Oxe/duNGjQAOHh4UWuQBWmpCVQ9WoVflfS3AV+6Nrt71+OWzdvwv69u5Gckoxq1apjwsRJqN+gYXGFWSpdu3oFI4YNLtDepWt3zP9xEfbs2oHt27YgMTERZmZm6Px1V4wc9R00NDSVEO2nlbRPgdeuXsHwoQWv7dddu2PG7LmYNmUiIm7fwts3b2BkZISatWpjxLejUas2F36U197du6QLaTpWr4Gp02eU6IVJlb2MQUZ6Gg7v3IiwSyFISX4DYxNTNGnlhm79h8ssgvn76SPYvWk5Vu06DR1dPZlj/BF4Aj+vKHzJgx2nrio0/k8pzmUMXr1VbNXY2qjk/b79EpSeQH2wb98+jB8/HgkJCYiIiChTCRRRUZS0BIroc5SdQJVlxZlAxSQrNoGyMiybCVSJWYm8X79+aN68OcLCwmBra6vscIiIiIg+qsQkUABgY2MDGxsbZYdBRESkMkScBSUX1brVgIiIiOgLKFEVKCIiIipmLEDJhRUoIiIiIoFYgSIiIlJhLEDJhwkUERGRCuMSKvLhEB4RERGRQKxAERERqTAuYyAfVqCIiIiIBGIFioiISJWxACUXVqCIiIiIBGIFioiISIWxACUfVqCIiIiIBGIFioiISIVxHSj5MIEiIiJSYVzGQD4cwiMiIiISiBUoIiIiFcYhPPmwAkVEREQkEBMoIiIiIoGYQBEREREJxDlQREREKoxzoOTDChQRERGRQKxAERERqTCuAyUfJlBEREQqjEN48uEQHhEREZFArEARERGpMBag5MMKFBEREZFArEARERGpMpag5MIKFBEREZFArEARERGpMC5jIB9WoIiIiIgEYgWKiIhIhXEdKPmwAkVEREQkECtQREREKowFKPkwgSIiIlJlzKDkwiE8IiIiIoGYQBEREakwkYL/I9TatWthZ2cHLS0tuLi44OrVqwo46/+OCRQRERGVCPv374ePjw9mz56NGzduoG7dunB3d0d8fLyyQytAJJFIJMoO4kvLyFF2BETC8VZiKm1uPU9WdghllouDYbG9VuZ7xR5fS8BsaxcXFzRq1Ahr1qwBAOTl5aFixYoYO3Yspk2bpqAI5cMKFBERESlMVlYWUlJSZB5ZWVkF+mVnZyMsLAzt27eXtqmpqaF9+/YIDQ0tzpCLpEzehaetoewIii4rKwt+fn7w9fWFWCxWdjhlBq+r4vDaKk5pu7bFWSX5r0rbtS1OQipE8pizwA9z586VaZs9ezbmzJkj0/b69Wvk5ubCwsJCpt3CwgL3799XbJByKJNDeKVJSkoKDA0NkZycDAMDA2WHU2bwuioOr63i8NoqDq+t8mRlZRWoOInF4gKJ7KtXr1ChQgVcunQJrq6u0vYpU6bg/PnzuHLlSrHEW1RlsgJFREREJUNhyVJhTE1Noa6ujri4OJn2uLg4WFpaKio8uXEOFBERESmdpqYmnJ2dERQUJG3Ly8tDUFCQTEWqpGAFioiIiEoEHx8feHp6omHDhmjcuDFWrlyJtLQ0DB06VNmhFcAESsnEYjFmz57NSY1fGK+r4vDaKg6vreLw2pYOffv2RUJCAmbNmoXY2FjUq1cPZ86cKTCxvCTgJHIiIiIigTgHioiIiEggJlBEREREAjGBIiIiIhKICRQRERGRQEyglGjt2rWws7ODlpYWXFxccPXqVWWHVCZcuHABXbp0gbW1NUQiEY4eParskMoEPz8/NGrUCPr6+jA3N0e3bt0QFRWl7LDKhPXr16NOnTowMDCAgYEBXF1dcfr0aWWHVeYsWrQIIpEI48ePV3YoVAYwgVKS/fv3w8fHB7Nnz8aNGzdQt25duLu7Iz4+XtmhlXppaWmoW7cu1q5dq+xQypTz58/D29sbly9fRmBgIHJycuDm5oa0tDRlh1bq2djYYNGiRQgLC8P169fRtm1bdO3aFZGRkcoOrcy4du0aNm7ciDp16ig7FCojuIyBkri4uKBRo0ZYs2YNgPzVVitWrIixY8di2rRpSo6u7BCJRDhy5Ai6deum7FDKnISEBJibm+P8+fNo2bKlssMpc0xMTLBkyRJ4eXkpO5RSLzU1FQ0aNMC6deuwYMEC1KtXDytXrlR2WFTKsQKlBNnZ2QgLC0P79u2lbWpqamjfvj1CQ0OVGBlR0SUnJwPI/0NPX05ubi727duHtLS0Evn1FaWRt7c3PDw8ZH7nEv1XXIlcCV6/fo3c3NwCK6taWFjg/v37SoqKqOjy8vIwfvx4NGvWDLVq1VJ2OGVCREQEXF1dkZmZCT09PRw5cgROTk7KDqvU27dvH27cuIFr164pOxQqY5hAEZFg3t7euHPnDi5evKjsUMoMR0dHhIeHIzk5GYcOHYKnpyfOnz/PJOo/ePHiBcaNG4fAwEBoaWkpOxwqY5hAKYGpqSnU1dURFxcn0x4XFwdLS0slRUVUNGPGjMGJEydw4cIF2NjYKDucMkNTUxNVqlQBADg7O+PatWvw9/fHxo0blRxZ6RUWFob4+Hg0aNBA2pabm4sLFy5gzZo1yMrKgrq6uhIjpNKMc6CUQFNTE87OzggKCpK25eXlISgoiHMeqMSSSCQYM2YMjhw5guDgYNjb2ys7pDItLy8PWVlZyg6jVGvXrh0iIiIQHh4ufTRs2BADBgxAeHg4kyf6T1iBUhIfHx94enqiYcOGaNy4MVauXIm0tDQMHTpU2aGVeqmpqXj06JH0+dOnTxEeHg4TExNUqlRJiZGVbt7e3tizZw+OHTsGfX19xMbGAgAMDQ2hra2t5OhKN19fX3Ts2BGVKlXCu3fvsGfPHoSEhODs2bPKDq1U09fXLzBHT1dXF+XLl+fcPfrPmEApSd++fZGQkIBZs2YhNjYW9erVw5kzZwpMLCfhrl+/jjZt2kif+/j4AAA8PT0REBCgpKhKv/Xr1wMAWrduLdO+bds2DBkypPgDKkPi4+MxePBgxMTEwNDQEHXq1MHZs2fx1VdfKTs0IvoIrgNFREREJBDnQBEREREJxASKiIiISCAmUEREREQCMYEiIiIiEogJFBEREZFATKCIiIiIBGICRURERCQQEygiIiIigZhAEdEnDRkyBN26dZM+b926NcaPH1/scYSEhEAkEuHt27fF/tpERP/GBIqolBoyZAhEIhFEIhE0NTVRpUoVzJs3D+/fv1fo6/7yyy+YP39+kfoy6SGisorfhUdUinXo0AHbtm1DVlYWTp06BW9vb2hoaMDX11emX3Z2NjQ1Nb/Ia5qYmHyR4xARlWasQBGVYmKxGJaWlrC1tcXo0aPRvn17/Prrr9Jhtx9//BHW1tZwdHQEALx48QJ9+vSBkZERTExM0LVrVzx79kx6vNzcXPj4+MDIyAjly5fHlClT8O+vy/z3EF5WVhamTp2KihUrQiwWo0qVKtiyZQuePXsm/VJnY2NjiEQi6ZcO5+Xlwc/PD/b29tDW1kbdunVx6NAhmdc5deoUqlWrBm1tbbRp00YmTiIiZWMCRVSGaGtrIzs7GwAQFBSEqKgoBAYG4sSJE8jJyYG7uzv09fXxxx9/4M8//4Senh46dOgg3WfZsmUICAjA1q1bcfHiRSQlJeHIkSOffM3Bgwdj7969WLVqFe7du4eNGzdCT08PFStWxOHDhwEAUVFRiImJgb+/PwDAz88PO3bswIYNGxAZGYkJEyZg4MCBOH/+PID8RK9Hjx7o0qULwsPDMXz4cEybNk1Rl42ISDAO4RGVARKJBEFBQTh79izGjh2LhIQE6OrqYvPmzdKhu127diEvLw+bN2+GSCQCAGzbtg1GRkYICQmBm5sbVq5cCV9fX/To0QMAsGHDBpw9e/ajr/vgwQMcOHAAgYGBaN++PQCgcuXK0u0fhvvMzc1hZGQEIL9itXDhQpw7dw6urq7SfS5evIiNGzeiVatWWL9+PRwcHLBs2TIAgKOjIyIiIvDTTz99watGRCQ/JlBEpdiJEyegp6eHnJwc5OXloX///pgzZw68vb1Ru3ZtmXlPt27dwqNHj6Cvry9zjMzMTDx+/BjJycmIiYmBi4uLdFu5cuXQsGHDAsN4H4SHh0NdXR2tWrUqcsyPHj1Ceno6vvrqK5n27Oxs1K9fHwBw7949mTgASJMtIqKSgAkUUSnWpk0brF+/HpqamrC2tka5cn//SOvq6sr0TU1NhbOzM3bv3l3gOGZmZnK9vra2tuB9UlNTAQAnT55EhQoVZLaJxWK54iAiKm5MoIhKMV1dXVSpUqVIfRs0aID9+/fD3NwcBgYGhfaxsrLClStX0LJlSwDA+/fvERYWhgYNGhTav3bt2sjLy8P58+elQ3j/9KEClpubK21zcnKCWCxGdHT0RytXNWrUwK+//irTdvny5c+fJBFRMeEkciIVMWDAAJiamqJr1674448/8PTpU4SEhOD777/Hy5cvAQDjxo3DokWLcPToUdy/fx/ffffdJ9dwsrOzg6enJ4YNG4ajR49Kj3ngwAEAgK2tLUQiEU6cOIGEhASkpqZCX18fkyZNwoQJE7B9+3Y8fvwYN27cwOrVq7F9+3YAwKhRo/Dw4UNMnjwZUVFR2LNnDwICAhR9iYiIiowJFJGK0NHRwYULF1CpUiX06NEDNWrUgJeXFzIzM6UVqYkTJ2LQoEHw9PSEq6sr9PX10b17908ed/369ejVqxe+++47VK9eHSNGjEBaWhoAoEKFCpg7dy6mTZsGCwsLjBkzBgAwf/58zJw5E35+fqhRowY6dOiAkydPwt7eHgBQqVIlHD58GEePHkXdunWxYcMGLFy4UIFXh4hIGJHkY7NDiYiIiKhQrEARERERCcQEioiIiEggJlBEREREAjGBIiIiIhKICRQRERGRQEygiIiIiARiAkVEREQkEBMoIiIiIoGYQBEREREJxASKiIiISCAmUEREREQC/Q9X97+HeBYkjwAAAABJRU5ErkJggg==\n"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}